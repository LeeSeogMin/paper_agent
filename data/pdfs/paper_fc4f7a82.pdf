<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    
    <title>Topic2features: a novel framework to classify noisy and sparse textual data using LDA topic distributions [PeerJ]</title>

    
        <link rel="dns-prefetch" href="https://d2pdyyx74uypu5.cloudfront.net/">
    <link rel="dns-prefetch" href="http://static.peerj.com/">
<link rel="dns-prefetch" href="https://doi.org">

        
            <meta name="citation_title" content="Topic2features: a novel framework to classify noisy and sparse textual data using LDA topic distributions"><meta name="citation_date" content="2021-08-11"><meta name="citation_doi" content="10.7717/peerj-cs.677"><meta name="citation_language" content="en"><meta name="citation_pdf_url" content="https://peerj.com/articles/cs-677.pdf"><meta name="citation_fulltext_html_url" content="https://peerj.com/articles/cs-677"><meta name="citation_volume" content="7"><meta name="citation_firstpage" content="e677"><meta name="citation_keywords" content="Classification; Machine learning; Topic analysis; Text analysis; Natural language processing; Sparse Data; Social media"><meta name="citation_journal_title" content="PeerJ Computer Science"><meta name="citation_journal_abbrev" content="PeerJ Comput. Sci."><meta name="citation_publisher" content="PeerJ Inc."><meta name="citation_issn" content="2376-5992"><meta name="citation_author" content="Junaid Abdul Wahid"><meta name="citation_author_institution" content="School of Information Engineering, Zhengzhou University, Zhengzhou, Henan, China"><meta name="citation_author" content="Lei Shi"><meta name="citation_author_institution" content="School of Software, Zhengzhou University, Zhengzhou, Henan, China"><meta name="citation_author_email" content="shilei@zzu.edu.cn"><meta name="citation_author" content="Yufei Gao"><meta name="citation_author_institution" content="School of Software, Zhengzhou University, Zhengzhou, Henan, China"><meta name="citation_author_email" content="yfgao@zzu.edu.cn"><meta name="citation_author" content="Bei Yang"><meta name="citation_author_institution" content="School of Information Engineering, Zhengzhou University, Zhengzhou, Henan, China"><meta name="citation_author" content="Yongcai Tao"><meta name="citation_author_institution" content="School of Information Engineering, Zhengzhou University, Zhengzhou, Henan, China"><meta name="citation_author" content="Lin Wei"><meta name="citation_author_institution" content="School of Software, Zhengzhou University, Zhengzhou, Henan, China"><meta name="citation_author" content="Shabir Hussain"><meta name="citation_author_institution" content="School of Information Engineering, Zhengzhou University, Zhengzhou, Henan, China">
        <meta name="description" content="In supervised machine learning, specifically in classification tasks, selecting and analyzing the feature vector to achieve better results is one of the most important tasks. Traditional methods such as comparing the features’ cosine similarity and exploring the datasets manually to check which feature vector is suitable is relatively time consuming. Many classification tasks failed to achieve better classification results because of poor feature vector selection and sparseness of data. In this paper, we proposed a novel framework, topic2features (T2F), to deal with short and sparse data using the topic distributions of hidden topics gathered from dataset and converting into feature vectors to build supervised classifier. For this we leveraged the unsupervised topic modelling LDA (latent dirichlet allocation) approach to retrieve the topic distributions employed in supervised learning algorithms. We made use of labelled data and topic distributions of hidden topics that were generated from that data. We explored how the representation based on topics affect the classification performance by applying supervised classification algorithms. Additionally, we did careful evaluation on two types of datasets and compared them with baseline approaches without topic distributions and other comparable methods. The results show that our framework performs significantly better in terms of classification performance compared to the baseline(without T2F) approaches and also yields improvement in terms of F1 score compared to other compared approaches.">

        
                                                    <meta property="og:image" content="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-1-1x.jpg">
                <meta name="twitter:image" content="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-1-1x.jpg">
                    
        <meta name="twitter:card" content="summary_large_image">
        <meta name="twitter:url" content="https://peerj.com/articles/cs-677">
        <meta name="twitter:site" content="@thePeerJ">
        <meta name="twitter:title" content="Topic2features: a novel framework to classify noisy and sparse textual data using LDA topic distributions">
        <meta name="twitter:description" content="In supervised machine learning, specifically in classification tasks, selecting and analyzing the feature vector to achieve better results is one of the most important tasks. Traditional methods such as comparing the features’ cosine similarity and exploring the datasets manually to check which feature vector is suitable is relatively time consuming. Many classification tasks failed to achieve better classification results because of poor feature vector selection and sparseness of data. In this paper, we proposed a novel framework, topic2features (T2F), to deal with short and sparse data using the topic distributions of hidden topics gathered from dataset and converting into feature vectors to build supervised classifier. For this we leveraged the unsupervised topic modelling LDA (latent dirichlet allocation) approach to retrieve the topic distributions employed in supervised learning algorithms. We made use of labelled data and topic distributions of hidden topics that were generated from that data. We explored how the representation based on topics affect the classification performance by applying supervised classification algorithms. Additionally, we did careful evaluation on two types of datasets and compared them with baseline approaches without topic distributions and other comparable methods. The results show that our framework performs significantly better in terms of classification performance compared to the baseline(without T2F) approaches and also yields improvement in terms of F1 score compared to other compared approaches.">

        <meta property="og:type" content="article">
        <meta property="og:title" content="Topic2features: a novel framework to classify noisy and sparse textual data using LDA topic distributions">
        <meta property="og:url" content="https://peerj.com/articles/cs-677">
        <meta property="og:site_name" content="PeerJ Computer Science">

    
    <link rel="alternate" type="application/pdf" href="/articles/cs-677.pdf">
    <link rel="alternate" type="application/rdf+xml" href="/articles/cs-677.rdf">
    <link rel="alternate" type="application/json" href="/articles/cs-677.json">
    <link rel="alternate" type="application/xml" href="/articles/cs-677.xml">
    <link rel="alternate" type="application/unixref+xml" href="/articles/cs-677.unixref">
    <link rel="alternate" type="application/vnd.citationstyles.csl+json" href="/articles/cs-677.citeproc">
    <link rel="alternate" type="application/bibjson+json" href="/articles/cs-677.bibjson">
    <link rel="alternate" type="text/html" href="/articles/cs-677.html">

    <link rel="canonical" href="https://peerj.com/articles/cs-677/">

    <meta name="viewport" content="width=device-width,initial-scale=1">
    <meta property="fb:app_id" content="534542813234464">

                    <style>
    .legacy-b2-wrap {
        margin: 0;
        font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
        font-size: 14px;
        line-height: 20px;
        color: #333333;
        /*background-color: #ffffff;*/
        box-sizing: unset;
    }

    .legacy-b2-wrap .row {
        margin: unset;
        display: inherit;
    }
</style>
    <link rel="stylesheet" href="/css/01fda25-1d2419f.css" media="screen">

<!--[if lt IE 9]>
    <link rel="stylesheet" href="/assets/css/ie8.css" media="screen">
<![endif]-->

<!--[if lt IE 10]>
    <link rel="stylesheet" href="/assets/css/ie9.css" media="screen">
<![endif]-->

    <style media="screen">html, body { height: 100%; }</style>
                <link rel="stylesheet" href="https://cdn.peerj.com/4a8db25/webpack/310.ca1cc354.css"><link rel="stylesheet" href="https://cdn.peerj.com/4a8db25/webpack/peerj-app.4cd527b8.css">
    

    <link rel="stylesheet" href="/css/a0c1a2c-9eb2d9a.css" media="screen">

    <link rel="stylesheet" href="/css/be477b9-1aea71d.css" media="screen">
        <link rel="stylesheet" href="/css/3e4ba6d-8ea718c.css" media="print">
    <script src="/js/f67db00-8264f27.js"></script>
<script src="/assets/js/mixpanel.js" defer></script>


<script src="/assets/js/polyfills/includes.js"></script>
<script src="/assets/js/polyfills/startsWith.js"></script><!--[if lt IE 9]>
<script src="/assets/js/html5shiv.js"></script>

<![endif]-->

<!--[if lt IE 8]>
<script src="/assets/js/json2.js"></script>
<![endif]-->

<script>
    var PeerJ = {
        Article: {},
        User: {
            anonymous: true        },
        Publication: {},
        Production: {},
        Event: {},
        Com: {},
        Payment: {},
        Annotation: {},
        Search: {},
        Home: {},
        Subjects: {},
        Advocacy: {},
        Job: {},
        ContentAlert: {},
        Tools: {}
    };
</script>

    
<script>
    var campaign_keywords = ['utm_source', 'utm_medium', 'utm_campaign', 'utm_content', 'utm_term'];
    var kw = '';
    var lastUtms = {};
    var firstUtms = {};
    var allUtms = {};

    function campaignParams() {
        var index;
        for (index = 0; index < campaign_keywords.length; ++index) {
            kw = getQueryParam(document.URL, campaign_keywords[index]);
            if (kw.length) {
                lastUtms[campaign_keywords[index] + '-last'] = kw;
                firstUtms[campaign_keywords[index] + '-first'] = kw;
                allUtms[campaign_keywords[index] + '-all'] = kw;
            }
        }
    }

    function updatePreregCookie(preregCookie, firstUtmKey) {
        var utmVal = firstUtms[firstUtmKey];
        if (utmVal) {
            var existingPreregCampaign = $.cookie(preregCookie);
            var appendPreregCampaign;
            if (!existingPreregCampaign) {
                appendPreregCampaign = utmVal;
            } else {
                appendPreregCampaign = existingPreregCampaign + ',' + utmVal;

            }
            $.cookie(preregCookie, appendPreregCampaign, {expires: 365, path: "/"});
        }
    }

    function getQueryParam(url, param) {
        // Expects a raw URL
        param = param.replace(/[[]/, "\[").replace(/[]]/, "\]");
        var regexS = "[\?&]" + param + "=([^&#]*)",
                regex = new RegExp( regexS ),
                results = regex.exec(url);
        if (results === null || (results && typeof(results[1]) !== 'string' && results[1].length)) {
            return '';
        } else {
            return decodeURIComponent(results[1]).replace(/\W/gi, ' ');
        }
    }

    function articlePageEvent() {
        var articleContainer = $('.publication-jsondata');
        if (articleContainer.length) {
            var data = articleContainer.data('publication-meta');

            // Must be public
            if (data.publicationSubjects.length) {

                var eventName = 'Viewed-article';
                var preprint = data.preprint;
                if (preprint) {
                    eventName = 'Viewed-preprint';
                }

                data['ip-hash'] = '46b3b519802980a971d78dcb2cc6b015';
                mixpanel.track(eventName, data);
            }
        }
    }

    function sectionListViewEvent() {
            }
</script>










    <script>(function(p,u,s,h,x){p.pushpad=p.pushpad||function(){(p.pushpad.q=p.pushpad.q||[]).push(arguments)};h=u.getElementsByTagName('head')[0];x=u.createElement('script');x.async=1;x.src=s;h.appendChild(x);})(window,document,'https://pushpad.xyz/pushpad.js');
pushpad('init', 5977, {hostname: 'peerj.com'});
</script>
    
    <link rel="search" type="application/opensearchdescription+xml" href="https://peerj.com/articles/osd.xml" title="PeerJ">

            <script>
    PeerJ.Com.GoogleTagManager = {
        init: function(){

            var tagManagerAccount = 'GTM-KGDWL2J';

                                        
            (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
                    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
                j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
                'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
            })(window,document,'script','dataLayer',tagManagerAccount);

        }
    }
</script>        


                    
    
    <script>
        // Run through cookieConsent only
        PeerJ.Com.GA = new function() {
            this.disabletracking = function() {
                window['ga-disable-' + 'UA-31208920-1'] = true;
            };

            this.runGA = function() {
                                (function (i, s, o, g, r, a, m) {
                    i['GoogleAnalyticsObject'] = r;
                    i[r] = i[r] || function () {
                        (i[r].q = i[r].q || []).push(arguments)
                    }, i[r].l = 1 * new Date();
                    a = s.createElement(o),
                        m = s.getElementsByTagName(o)[0];
                    a.async = 1;
                    a.src = g;
                    m.parentNode.insertBefore(a, m)
                })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');

                                ga('create', 'UA\u002D31208920\u002D1', 'auto');

                // Removes last octet
                ga('set', 'anonymizeIp', true);

                
                
                                                ga('set', 'dimension4', ';Artificial\u0020Intelligence\u003BData\u0020Mining\u0020and\u0020Machine\u0020Learning\u003BData\u0020Science;');
                
                                ga('require', 'displayfeatures');

                                ga('send', 'pageview');

                                                window.setTimeout(function () {
                    ga('send', 'event', 'adjusted bounce rate', 'page visit 15 seconds or more');
                }, 15000);
                
                                
                                            }
        };
    </script>
    
    <script src="/js/8548491-6e0bf01.js"></script>        
<link rel="apple-touch-icon" sizes="57x57" href="https://d2pdyyx74uypu5.cloudfront.net/images/favicon/peerj/apple-icon-57x57.png">
<link rel="apple-touch-icon" sizes="60x60" href="https://d2pdyyx74uypu5.cloudfront.net/images/favicon/peerj/apple-icon-60x60.png">
<link rel="apple-touch-icon" sizes="72x72" href="https://d2pdyyx74uypu5.cloudfront.net/images/favicon/peerj/apple-icon-72x72.png">
<link rel="apple-touch-icon" sizes="76x76" href="https://d2pdyyx74uypu5.cloudfront.net/images/favicon/peerj/apple-icon-76x76.png">
<link rel="apple-touch-icon" sizes="114x114" href="https://d2pdyyx74uypu5.cloudfront.net/images/favicon/peerj/apple-icon-114x114.png">
<link rel="apple-touch-icon" sizes="120x120" href="https://d2pdyyx74uypu5.cloudfront.net/images/favicon/peerj/apple-icon-120x120.png">
<link rel="apple-touch-icon" sizes="144x144" href="https://d2pdyyx74uypu5.cloudfront.net/images/favicon/peerj/apple-icon-144x144.png">
<link rel="apple-touch-icon" sizes="152x152" href="https://d2pdyyx74uypu5.cloudfront.net/images/favicon/peerj/apple-icon-152x152.png">
<link rel="apple-touch-icon" sizes="180x180" href="https://d2pdyyx74uypu5.cloudfront.net/images/favicon/peerj/apple-icon-180x180.png">
<link rel="icon" type="image/png" sizes="192x192"  href="https://d2pdyyx74uypu5.cloudfront.net/images/favicon/peerj/android-icon-192x192.png">
<link rel="shortcut icon" href="https://d2pdyyx74uypu5.cloudfront.net/images/favicon/peerj/favicon.ico">
<link rel="icon" type="image/png" sizes="32x32" href="https://d2pdyyx74uypu5.cloudfront.net/images/favicon/peerj/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="96x96" href="https://d2pdyyx74uypu5.cloudfront.net/images/favicon/peerj/favicon-96x96.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://d2pdyyx74uypu5.cloudfront.net/images/favicon/peerj/favicon-16x16.png">
<link rel="manifest" href="https://d2pdyyx74uypu5.cloudfront.net/images/favicon/peerj/manifest.json">
<meta name="msapplication-TileColor" content="#ffffff">
<meta name="msapplication-TileImage" content="https://d2pdyyx74uypu5.cloudfront.net/images/favicon/peerj/ms-icon-144x144.png">
<meta name="msapplication-config" content="https://d2pdyyx74uypu5.cloudfront.net/images/favicon/peerj/browserconfig.xml">
<meta name="theme-color" content="#ffffff">
        <noscript>
        <style type="text/css">
            #wrap {
                display: block;
                padding-left: 0;
                margin-top: 17px;
            }
        </style>
    </noscript>
</head>

<body         class=""
        data-mp="776a79e14e8f05a81ca92536c83f08b4"
        data-mp-debug=""
        data-controllerVars=""
        data-symfony-route="publication"
>


<div
        class="legacy-b2-wrap"
        style="background: none"
>
    <div
            id="wrap"
            style="background: none"
                >
        
        
        <div id="nav-pad"></div>

        
        <div class="container">

            <noscript class="js-disabled-warning">
                <div class="alert alert-danger">
                    <i class="icon icon-warning-sign"></i> Javascript is disabled in your browser. Please <a
                            href="https://www.enable-javascript.com" target="_blank">enable Javascript</a> to view
                    PeerJ.
                </div>
            </noscript>

            
    <div class="row publication-jsondata" data-publication-meta="{&quot;publicationId&quot;:&quot;cs-677&quot;,&quot;Article-section&quot;:&quot;NA&quot;,&quot;journal&quot;:&quot;PeerJ Computer Science&quot;,&quot;published&quot;:&quot;2021-08-11 07:53:47&quot;,&quot;preprint&quot;:false,&quot;publicationSubjects&quot;:[&quot;Artificial Intelligence&quot;,&quot;Data Mining and Machine Learning&quot;,&quot;Data Science&quot;],&quot;publicationInstitutions&quot;:null,&quot;publicationTop20Institution&quot;:false,&quot;publicationInstitutionPlan&quot;:false}">
        <!-- Left sidebar -->
        <div class="span1 article-sidebar">
            <div class="article-sidebar-left">
                <div class="sidebar-box sidebar-box--journal">
                    <a href="/computer-science/" class="sidebar-box--journal-mask"></a>
                    <img src="https://d2pdyyx74uypu5.cloudfront.net/images/article/logos/article-logo-cs.png">
                </div>

                <div id="btn-view-tweets" class="sidebar-box sidebar-box--tweet" style="display:none;">
                    <div class="text-center"><span id="tweet-count-container"></span> <img src="/assets/images/landing-pages/social/twitter-x.svg"></div>
                </div>

                <a href="#related-research" class="sidebar-box sidebar-box--related text-center">
                    Related research
                    <i class="icon-angle-down"></i>
                </a>

                <!-- mobile only -->
                <div class="item-leftside-actions">
                     <div class="sidebar-box sidebar-box--action js-download-modal-trigger">Download</div>


                     
  
                        
<div class="sidebar-box sidebar-box--social visible-desktop">
    <div class="sidebar-box--social-title">Share</div>
    <div class="d-flex">
        <a class="pj-socialism tw-soc" href="http://twitter.com/share?url&#x3D;https&#x25;3A&#x25;2F&#x25;2Fpeerj.com&#x25;2Farticles&#x25;2Fcs-677&#x25;2F&amp;via&#x3D;PeerJCompSci&amp;text&#x3D;Topics&#x25;20vectors&#x25;20for&#x25;20classification&amp;related&#x3D;" target="_blank" onclick="window.open(this.href, 'popupwindow', 'width=500,height=500,scrollbars,resizable'); return false;">X</a>
        <a class="pj-socialism fb-soc" href="http://www.facebook.com/sharer.php?u&#x3D;https&#x25;3A&#x25;2F&#x25;2Fpeerj.com&#x25;2Farticles&#x25;2Fcs-677&#x25;2F" target="_blank" onclick="window.open(this.href, 'popupwindow', 'width=500,height=500,scrollbars,resizable'); return false;">Facebook</a>
        <a class="pj-socialism em-soc" href="mailto:?Subject&#x3D;Relevant&#x25;20research&#x25;20paper&#x25;20in&#x25;20PeerJ&#x25;20Computer&#x25;20Science&amp;Body&#x3D;Topic2features&#x25;3A&#x25;20a&#x25;20novel&#x25;20framework&#x25;20to&#x25;20classify&#x25;20noisy&#x25;20and&#x25;20sparse&#x25;20textual&#x25;20data&#x25;20using&#x25;20LDA&#x25;20topic&#x25;20distributions&#x25;20https&#x25;3A&#x25;2F&#x25;2Fpeerj.com&#x25;2Farticles&#x25;2Fcs-677&#x25;2F" target="_blank" onclick="window.open(this.href, 'popupwindow', 'width=500,height=500,scrollbars,resizable'); return false;">Email</a>
    </div>
</div>

<div class="hidden-desktop sidebar-box--action-container btn-group">
    <a href="#" style="color: #7a7a7a !important;" class="sidebar-box sidebar-box--action btn-share dropdown-toggle" data-toggle="dropdown">Share</a>

    <ul class="dropdown-menu">
        <li>
            <a href="http://twitter.com/share?url&#x3D;https&#x25;3A&#x25;2F&#x25;2Fpeerj.com&#x25;2Farticles&#x25;2Fcs-677&#x25;2F&amp;via&#x3D;PeerJCompSci&amp;text&#x3D;Topics&#x25;20vectors&#x25;20for&#x25;20classification&amp;related&#x3D;" target="_blank" onclick="window.open(this.href, 'popupwindow', 'width=500,height=500,scrollbars,resizable'); return false;">X</a>
        </li>
        <li>
            <a href="http://www.facebook.com/sharer.php?u&#x3D;https&#x25;3A&#x25;2F&#x25;2Fpeerj.com&#x25;2Farticles&#x25;2Fcs-677&#x25;2F" target="_blank" onclick="window.open(this.href, 'popupwindow', 'width=500,height=500,scrollbars,resizable'); return false;">Facebook</a>
        </li>
        <li>
            <a href="mailto:?Subject&#x3D;Relevant&#x25;20research&#x25;20paper&#x25;20in&#x25;20PeerJ&#x25;20Computer&#x25;20Science&amp;Body&#x3D;Topic2features&#x25;3A&#x25;20a&#x25;20novel&#x25;20framework&#x25;20to&#x25;20classify&#x25;20noisy&#x25;20and&#x25;20sparse&#x25;20textual&#x25;20data&#x25;20using&#x25;20LDA&#x25;20topic&#x25;20distributions&#x25;20https&#x25;3A&#x25;2F&#x25;2Fpeerj.com&#x25;2Farticles&#x25;2Fcs-677&#x25;2F" target="_blank" onclick="window.open(this.href, 'popupwindow', 'width=500,height=500,scrollbars,resizable'); return false;">Email</a>
        </li>
    </ul>
</div>

                                    </div>

            </div>

                            <div class="peer-reviewed visible-phone">
                    <i class="icon-ok"></i> PEER-REVIEWED
                </div>
            
        </div>

        <div id="annotations-sidebar" class="span5"></div>

        <!-- Middle col -->
        <div id="article-item-middle" class="span7"
             data-ms-type-entity="articles" data-ms-type-id="research-article" data-ms-type-text="Research-article" data-ms-type-name="Research Article">
            
            <div id="article-tweets-container">
    <div class="row-fluid article-tweets-header">
        <div class="span9">
            <h2><em>Topic2features: a novel framework to classify noisy and sparse textual data using LDA topic distributions</em></h2>
        </div>
        <div class="span3">
                            <div class="btn btn-inverse pull-right" id="btn-view-article"><span class="icon-file"></span> View article</div>
                    </div>
    </div>

    <div class="tweet-items">
            </div>


</div>

            <div id="article-main-container" data-group="" data-groupId="" data-groupName="">
                
                <style>
                .editorial-article-notice {
                    color: #686868;
                    font-size: 15px;
                    padding: 12px 18px 11px;
                }
                </style>

                
                <div class="article-section-breadcrumb">
                                            <span class="icon-angle-left"></span>
                        <span><a href="/computer-science/"><em>PeerJ Computer Science</em></a></span>
                                    </div>


                <div class="hidden-print">
                    
                                                                                                </div>

                <!-- Main article -->
                <article itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><header class="article-meta front"><h1 class="article-title" itemprop="name headline">Topic2features: a novel framework to classify noisy and sparse textual data using LDA topic distributions</h1>
<div class="article-authors">
<span class="contrib" itemscope="itemscope" itemtype="http://schema.org/Person" id="author-1" data-jats-contrib-type="author" itemprop="author"><a href="author-1" rel="author" itemprop="url"><span class="name" itemprop="name"><span class="given-names" itemprop="givenName">Junaid Abdul</span> <span class="surname" itemprop="familyName">Wahid</span></span></a><sup class="contrib-xref-group"><a class="aff xref" href="#aff-1" itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" itemref="aff-1">1</a></sup></span>, <span class="contrib" itemscope="itemscope" itemtype="http://schema.org/Person" id="author-2" data-jats-contrib-type="author" data-jats-corresp="yes" itemprop="author"><a href="author-2" rel="author" itemprop="url"><span class="name" itemprop="name"><span class="given-names" itemprop="givenName">Lei</span> <span class="surname" itemprop="familyName">Shi</span></span></a><a class="corresp" href="mailto:shilei@zzu.edu.cn" target="_blank" title="email the corresponding author" data-toggle="tooltip" itemprop="email"><i class="icon-envelope">​</i></a><sup class="contrib-xref-group"><a class="aff xref" href="#aff-2" itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" itemref="aff-2">2</a></sup></span>, <span class="contrib" itemscope="itemscope" itemtype="http://schema.org/Person" id="author-3" data-jats-contrib-type="author" data-jats-corresp="yes" itemprop="author"><a href="author-3" rel="author" itemprop="url"><span class="name" itemprop="name"><span class="given-names" itemprop="givenName">Yufei</span> <span class="surname" itemprop="familyName">Gao</span></span></a><a class="corresp" href="mailto:yfgao@zzu.edu.cn" target="_blank" title="email the corresponding author" data-toggle="tooltip" itemprop="email"><i class="icon-envelope">​</i></a><sup class="contrib-xref-group"><a class="aff xref" href="#aff-2" itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" itemref="aff-2">2</a></sup></span>, <span class="contrib" itemscope="itemscope" itemtype="http://schema.org/Person" id="author-4" data-jats-contrib-type="author" itemprop="author"><a href="author-4" rel="author" itemprop="url"><span class="name" itemprop="name"><span class="given-names" itemprop="givenName">Bei</span> <span class="surname" itemprop="familyName">Yang</span></span></a><sup class="contrib-xref-group"><a class="aff xref" href="#aff-1" itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" itemref="aff-1">1</a></sup></span>, <span class="contrib" itemscope="itemscope" itemtype="http://schema.org/Person" id="author-5" data-jats-contrib-type="author" itemprop="author"><a href="author-5" rel="author" itemprop="url"><span class="name" itemprop="name"><span class="given-names" itemprop="givenName">Yongcai</span> <span class="surname" itemprop="familyName">Tao</span></span></a><sup class="contrib-xref-group"><a class="aff xref" href="#aff-1" itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" itemref="aff-1">1</a></sup></span>, <span class="contrib" itemscope="itemscope" itemtype="http://schema.org/Person" id="author-6" data-jats-contrib-type="author" itemprop="author"><a href="author-6" rel="author" itemprop="url"><span class="name" itemprop="name"><span class="given-names" itemprop="givenName">Lin</span> <span class="surname" itemprop="familyName">Wei</span></span></a><sup class="contrib-xref-group"><a class="aff xref" href="#aff-2" itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" itemref="aff-2">2</a></sup></span>, <span class="contrib" itemscope="itemscope" itemtype="http://schema.org/Person" id="author-7" data-jats-contrib-type="author" itemprop="author"><a href="author-7" rel="author" itemprop="url"><span class="name" itemprop="name"><span class="given-names" itemprop="givenName">Shabir</span> <span class="surname" itemprop="familyName">Hussain</span></span></a><sup class="contrib-xref-group"><a class="aff xref" href="#aff-1" itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" itemref="aff-1">1</a></sup></span>
</div>
<div id="article-information">
<div class="article-notes">
<div itemscope="itemscope" itemtype="http://schema.org/Organization" id="aff-1">
<span class="article-label-container"><a class="article-label">1</a></span><span itemprop="address"><span class="institution">School of Information Engineering, Zhengzhou University</span>, <span class="city">Zhengzhou</span>, <span class="state">Henan</span>, <span class="country">China</span></span>
</div>
<div itemscope="itemscope" itemtype="http://schema.org/Organization" id="aff-2">
<span class="article-label-container"><a class="article-label">2</a></span><span itemprop="address"><span class="institution">School of Software, Zhengzhou University</span>, <span class="city">Zhengzhou</span>, <span class="state">Henan</span>, <span class="country">China</span></span>
</div>
</div>
<dl class="article-identifiers">
<dt> DOI</dt>
<dd>
<a href="https://doi.org/10.7717/peerj-cs.677" itemprop="sameAs">10.7717/peerj-cs.677</a><meta itemprop="sameAs" content="info:doi/10.7717/peerj-cs.677">
</dd>
</dl>
<dl class="article-dates">
<dt>Published</dt>
<dd><time itemprop="datePublished">2021-08-11</time></dd>
<dt>Accepted</dt>
<dd><time data-itemprop="dateAccepted">2021-07-23</time></dd>
<dt>Received</dt>
<dd><time itemprop="dateCreated">2021-03-24</time></dd>
</dl>
<dl class="article-editors">
<dt>Academic Editor</dt>
<dd itemprop="editor" itemscope="itemscope" itemtype="http://schema.org/Person"><a itemprop="url" href="editor-1" class="contrib" data-jats-contrib-type="editor"><span class="name" itemprop="name"><span class="given-names" itemprop="givenName">Khalid</span> <span class="surname" itemprop="familyName">Raza</span></span></a></dd>
</dl>
<dl class="article-subjects">
<dt>Subject Areas</dt>
<dd>
<a class="subject" itemprop="about" href="/subjects/?filter=Artificial%20Intelligence">Artificial Intelligence</a>, <a class="subject" itemprop="about" href="/subjects/?filter=Data%20Mining%20and%20Machine%20Learning">Data Mining and Machine Learning</a>, <a class="subject" itemprop="about" href="/subjects/?filter=Data%20Science">Data Science</a>
</dd>
<dt>Keywords</dt>
<dd>
<span class="kwd" itemprop="keywords">Classification</span>, <span class="kwd" itemprop="keywords">Machine learning</span>, <span class="kwd" itemprop="keywords">Topic analysis</span>, <span class="kwd" itemprop="keywords">Text analysis</span>, <span class="kwd" itemprop="keywords">Natural language processing</span>, <span class="kwd" itemprop="keywords">Sparse Data</span>, <span class="kwd" itemprop="keywords">Social media</span>
</dd>
</dl>
<dl class="article-license">
<dt>Copyright</dt>
<dd>© <span itemprop="copyrightYear">2021</span> <span itemprop="copyrightHolder">Wahid et al.</span>
</dd>
<dt>Licence</dt>
<dd>
               <span class="license-p">This is an open access article distributed under the terms of the <a class="ext-link" href="https://creativecommons.org/licenses/by/4.0/" rel="license" data-jats-ext-link-type="uri">Creative Commons Attribution License</a>, which permits unrestricted use, distribution, reproduction and adaptation in any medium and for any purpose provided that it is properly attributed. For attribution, the original author(s), title, publication source (PeerJ Computer Science) and either DOI or URL of the article must be cited.</span>
            </dd>
</dl>
<dl class="self-citation">
<dt>Cite this article</dt>
<dd>
<span class="self-citation-authors">Wahid JA, Shi L, Gao Y, Yang B, Tao Y, Wei L, Hussain S.</span> <span class="self-citation-year">2021</span>. <span class="self-citation-title">Topic2features: a novel framework to classify noisy and sparse textual data using LDA topic distributions</span>. <span itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/PublicationVolume"><span class="self-citation-journal" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/Periodical"><span itemprop="name">PeerJ Computer Science</span></span> <span class="self-citation-volume" itemprop="volumeNumber">7</span></span>:<span class="self-citation-elocation" itemprop="pageStart">e677</span> <a href="https://doi.org/10.7717/peerj-cs.677" itemprop="url">https://doi.org/10.7717/peerj-cs.677</a>
</dd>
</dl>
<div class="alert alert-success view-public-reviews">The authors have chosen to make <a href="/articles/cs-677/reviews/">the review history of this article</a> public.</div>
</div>
<div>
<h2>Abstract</h2>
<div class="abstract" itemprop="description">
            <p> In supervised machine learning, specifically in classification tasks, selecting and analyzing the feature vector to achieve better results is one of the most important tasks. Traditional methods such as comparing the features’ cosine similarity and exploring the datasets manually to check which feature vector is suitable is relatively time consuming. Many classification tasks failed to achieve better classification results because of poor feature vector selection and sparseness of data. In this paper, we proposed a novel framework, topic2features (T2F), to deal with short and sparse data using the topic distributions of hidden topics gathered from dataset and converting into feature vectors to build supervised classifier. For this we leveraged the unsupervised topic modelling LDA (latent dirichlet allocation) approach to retrieve the topic distributions employed in supervised learning algorithms. We made use of labelled data and topic distributions of hidden topics that were generated from that data. We explored how the representation based on topics affect the classification performance by applying supervised classification algorithms. Additionally, we did careful evaluation on two types of datasets and compared them with baseline approaches without topic distributions and other comparable methods. The results show that our framework performs significantly better in terms of classification performance compared to the baseline(without T2F) approaches and also yields improvement in terms of F1 score compared to other compared approaches.</p>
         </div>
</div></header><main><div class="body" lang="en">
      <section class="sec" id="intro">
         <h2 class="heading">Introduction</h2>
         <p id="p-1">Learning to classify short text, social media data, and large web collections has been extensively studied in the past decade. Many text classification methods with a different set of features have been developed to improve the performance of classifiers and achieved satisfactory results (<a class="xref xref-bibr" href="https://doi.org/10.1016%2Fj.csl.2020.101104" title="tax2vec: constructing interpretable features from taxonomies for short text classification" data-jats-ref-type="bibr" data-jats-rid="ref-49">Škrlj et al., 2021</a>). With the rapid growth of online businesses, communication, and publishing applications, textual data is available in a variety of forms, such as customer reviews, movie reviews, chats, and news feeds, etc. Dissimilar from normal documents, these type of texts have noisy data, much shorter, and consists of few sentences, therefore it poses a lot of challenges in classifying and clustering. Text classification methods typically fail to achieve desirable performance due to sparseness in the data. Generally, text classification is a task to classify the document into one or more categories based on content and some features (<a class="xref xref-bibr" href="https://doi.org/10.3390%2Fapp8091589" title="Understanding citizen issues through reviews: a step towards data informed planning in smart cities" data-jats-ref-type="bibr" data-jats-rid="ref-8">Dilawar et al., 2018</a>). Given a set of documents, a classifier is expected to learn a pattern of words that are appeared in the documents to classify the document into different categories. Many deep learning techniques achieve the state of art results and have become a norm in text classification tasks (<a class="xref xref-bibr" href="http://arxiv.org/abs/1810.04805" title="Bert: pre-training of deep bidirectional transformers for language understanding" data-jats-ref-type="bibr" data-jats-rid="ref-6">Devlin et al., 2018</a>), showing good results on a variety of tasks including the classification of social media data (<a class="xref xref-bibr" href="https://scholar.google.com/scholar_lookup?title=Hubness-Aware%20classification&amp;author=Toma%C5%A1ev&amp;publication_year=2015" title="Hubness-Aware classification" data-jats-ref-type="bibr" data-jats-rid="ref-42">Tomašev et al., 2015</a>) and news data categorization (<a class="xref xref-bibr" href="https://scholar.google.com/scholar_lookup?title=From%20word%20embeddings%20to%20document%20distances&amp;author=Kusner&amp;publication_year=2015" title="From word embeddings to document distances" data-jats-ref-type="bibr" data-jats-rid="ref-20">Kusner et al., 2015</a>). Despite achieving satisfactory results on various classification tasks, deep learning is not yet optimized for different contexts such as where the number of documents in the training data is low, or document contains very short and noisy text (<a class="xref xref-bibr" href="https://scholar.google.com/scholar_lookup?title=Overview%20of%20the%204th%20author%20profiling%20task%20at%20pan%202016:%20cross-genre%20evaluations&amp;author=Rangel&amp;publication_year=2016" title="Overview of the 4th author profiling task at pan 2016: cross-genre evaluations" data-jats-ref-type="bibr" data-jats-rid="ref-36">Rangel et al., 2016</a>). To classify the data, we need a different set of features along with the data so that better classification performance can be achieved. For the classification to be successful, enough data with different features must be available to train a successful classifier (<a class="xref xref-bibr" href="https://doi.org/10.1016%2Fj.eswa.2017.03.020" title="Text classification method based on self-training and lda topic models" data-jats-ref-type="bibr" data-jats-rid="ref-35">Pavlinek &amp; Podgorelec, 2017</a>). Large datasets with multiple features and labeled data do not just assure better generalization of an algorithm, but also provide satisfactory performance. However, in reality, we do not have a large number of features along with the content, and sometimes we also have few labeled instances. This norm is typical in many fields such as speech recognition, classical text mining, social media data classification (<a class="xref xref-bibr" href="https://doi.org/10.3390%2Fapp11031294" title="Automated classification of evidence of respect in the communication through twitter" data-jats-ref-type="bibr" data-jats-rid="ref-10">Fiok et al., 2021</a>). Of course, we can do feature engineering and labeling manually but labeling is considered to be difficult and time-consuming and selection of features is unavailable when you do not have a lot of features associated with datasets (<a class="xref xref-bibr" href="http://arxiv.org/abs/2010.07245" title="Text classification using label names only: a language model self-training approach" data-jats-ref-type="bibr" data-jats-rid="ref-29">Meng et al., 2020</a>). Many semi-supervised learning methods of text classification are based on less labeled data and important feature selection and focus on similarities between dependent and independent variables. Since many methods are based on analyzing the similarity measures of a label and unlabeled data, the representation of content and its features is important (<a class="xref xref-bibr" href="https://doi.org/10.1016%2Fj.eswa.2017.03.020" title="Text classification method based on self-training and lda topic models" data-jats-ref-type="bibr" data-jats-rid="ref-35">Pavlinek &amp; Podgorelec, 2017</a>). The representation of unstructured content and features is more important than choosing the right machine learning algorithm (<a class="xref xref-bibr" href="https://doi.org/10.30534%2Fijatcse%2F2020%2F90912020" title="Classification of user comment using word2vec and svm classifier" data-jats-ref-type="bibr" data-jats-rid="ref-19">Kurnia, Tangkuman &amp; Girsang, 2020</a>). While you can represent the structured content uniformly with feature vectors, unstructured content can represent in various ways. In the text classification, some researchers leveraged vector space models representation, where features are based on words as independent units and values extracted from different vector weighting schemes such as term frequency, inverse document frequency (TF-IDF) (<a class="xref xref-bibr" href="https://doi.org/10.1016%2Fj.eswa.2017.03.020" title="Text classification method based on self-training and lda topic models" data-jats-ref-type="bibr" data-jats-rid="ref-35">Pavlinek &amp; Podgorelec, 2017</a>). But in these representations, word orders and semantic meanings are ignored (<a class="xref xref-bibr" href="https://scholar.google.com/scholar_lookup?title=Improving%20text%20categorization%20by%20using%20a%20topic%20model&amp;author=Sriurai&amp;publication_year=2011" title="Improving text categorization by using a topic model" data-jats-ref-type="bibr" data-jats-rid="ref-41">Sriurai, 2011</a>) that ultimately impact the classifier performance. In addition, these word vectors are sparse and high dimensional, so it is impossible to use just any machine learning algorithm on them seamlessly (<a class="xref xref-bibr" href="http://arxiv.org/abs/1806.09823" title="Approximate nearest neighbor search in high dimensions" data-jats-ref-type="bibr" data-jats-rid="ref-2">Andoni, Indyk &amp; Razenshteyn, 2018</a>). For features vector representations, different techniques, such as the most common ones are TF-IDF, a bag of words, and word embeddings are utilized to fine-tune their classifiers, but sparseness remains in the representation. In this situation, we can use topic models. When we have a low number of features, topic models consider context and compact the representation of content (<a class="xref xref-bibr" href="https://doi.org/10.1016%2Fj.chb.2013.07.043" title="Text classification using a few labeled examples" data-jats-ref-type="bibr" data-jats-rid="ref-5">Colace et al., 2014</a>). In this way, we can represent each document in latent topic distribution space instead of word space or document space. So inspired by the idea of, contexts in which we do not have many features, in which we have sparseness and noisiness in data, and also the semi-supervised approaches in which we have less labeled data, we present a novel framework for text classification of various datasets of relatively same nature with hidden topics distributions retrieved from those datasets that can deal successfully with large, short, sparse and noisy social media and customer reviews datasets. The underlying approach is that we have collected datasets of different natures and then trained a classification algorithm based on a labeled training dataset and discovered topics retrieved from those datasets. The framework is mainly based on combining the unsupervised LDA topic modeling approach and powerful machine learning text classification classifiers such as MaxEnt (MaxEntropy) and SVM (Support Vector machine). This research has the following contributions:</p>
         <ol class="list" id="list-1" data-jats-list-type="order">
            <li class="list-item">
<p id="p-2">We propose a novel T2F model that leverages LDA topics distributions to represent features instead of using traditional features to build classifiers. The proposed model represents features in a way to captures the context of data.</p>
            </li>
            <li class="list-item">
<p id="p-3">We have reached promising results and give a new way to solve the feature selection problem to achieve the best classification results.</p>
            </li>
            <li class="list-item">
<p id="p-4">Every aspect of model variation with different parameters analyzed in results and discussion section.</p>
            </li>
         </ol>
      </section>
      <section class="sec">
         <h2 class="heading">Related Work</h2>
         <p id="p-5">Different studies applied various feature engineering techniques to improve the performance of classifiers. <a class="xref xref-bibr" href="https://doi.org/10.1016%2Fj.joi.2020.101121" title="Using graph embedding and machine learning to identify rebels on twitter" data-jats-ref-type="bibr" data-jats-rid="ref-26">Masood &amp; Abbasi (2021)</a> used graph embeddings to classify the Twitter users into different categories of rebel users, <a class="xref xref-bibr" href="https://scholar.google.com/scholar_lookup?title=Twitter%20sentiment%20classification%20using%20distant%20supervision&amp;author=Go&amp;publication_year=2009" title="Twitter sentiment classification using distant supervision" data-jats-ref-type="bibr" data-jats-rid="ref-12">Go, Bhayani &amp; Huang (2009)</a> used emoticons along with pos, unigram and bigram features to classify the tweet sentiments and <a class="xref xref-bibr" href="https://doi.org/10.1371%2Fjournal.pone.0144296" title="Sentiment of emojis" data-jats-ref-type="bibr" data-jats-rid="ref-18">Kralj Novak et al. (2015)</a> computed the emojis sentiments, while when you see the famous topic modeling technique people have leveraged this for a variety of tasks such as event detection during disasters (<a class="xref xref-bibr" href="http://arxiv.org/abs/1608.02519" title="Topic modelling and event identification from Twitter textual data" data-jats-ref-type="bibr" data-jats-rid="ref-39">Sokolova et al., 2016</a>). To extract high-quality topics from short and sparse text, researchers proposed VAETM (Variational autoencoder topic model) approach (<a class="xref xref-bibr" href="https://doi.org/10.1016%2Fj.ipm.2020.102455" title="A neural topic model with word vectors and entity vectors for short texts" data-jats-ref-type="bibr" data-jats-rid="ref-48">Zhao et al., 2021</a>) by combining the word vectors and entity vectors representations. <a class="xref xref-bibr" href="https://doi.org/10.1016%2Fj.cie.2020.106636" title="Automated classification of patents: a topic modeling approach" data-jats-ref-type="bibr" data-jats-rid="ref-47">Yun &amp; Geum (2020)</a> used LDA-based text feature representation as an input to support vector machine classifier to classify the patent. Most of the time, topic modeling is mostly used to extract topics and analyze those topics to aid the organization in decision making (<a class="xref xref-bibr" href="https://scholar.google.com/scholar_lookup?title=Tweeting%20on%20covid-19%20pandemic%20in%20south%20africa:%20Lda-based%20topic%20modelling%20approach&amp;author=Mutanga&amp;publication_year=2020" title="Tweeting on covid-19 pandemic in south africa: Lda-based topic modelling approach" data-jats-ref-type="bibr" data-jats-rid="ref-31">Mutanga &amp; Abayomi, 2020</a>). A recent study by <a class="xref xref-bibr" href="https://doi.org/10.1016%2Fj.knosys.2020.105918" title="Document-level multi-topic sentiment classification of email data with bilstm and data augmentation" data-jats-ref-type="bibr" data-jats-rid="ref-24">Liu, Lee &amp; Lee (2020)</a> explored the topic embeddings generated from LDA to classify the email data, specifically they improved the email text classification with LDA topic modeling by converting email text into topic features. In the medical domain, <a class="xref xref-bibr" href="https://doi.org/10.1016%2Fj.compbiomed.2021.104322" title="Nighttime features derived from topic models for classification of patients with COPD" data-jats-ref-type="bibr" data-jats-rid="ref-40">Spina et al. (2021)</a> proposed a method that extracts nigh time features from multisensory data by using LDA and classify COPD (chronic obstructive and pulmonary disease) disease patients, they regard LDA topic distributions as powerful predictors in classifying the data. In another approach, <a class="xref xref-bibr" href="https://doi.org/10.1016%2Fj.ipm.2021.102592" title="Adaptive and hybrid context-aware fine-grained word sense disambiguation in topic modeling based document representation" data-jats-ref-type="bibr" data-jats-rid="ref-23">Li &amp; Suzuki (2021)</a> used LDA-based topic modeling document representation to fine-grained the word sense disambiguation, they proposed a Bag of sense model in which a document is a multiset of word senses and LDA topics word distributions mapped into senses. Using the text summarization techniques to label the topics generated from LDA topic distributions is also one of the attempts made by researchers (<a class="xref xref-bibr" href="https://scholar.google.com/scholar_lookup?title=Automatic%20labelling%20of%20topic%20models%20learned%20from%20Twitter%20by%20summarisation&amp;author=Cano%C2%A0Basave&amp;publication_year=2014" title="Automatic labelling of topic models learned from Twitter by summarisation" data-jats-ref-type="bibr" data-jats-rid="ref-4">Cano Basave, He &amp; Xu, 2014</a>). Recent work has applied summarization methods to generate topic labels. <a class="xref xref-bibr" href="https://scholar.google.com/scholar_lookup?title=Automatic%20labeling%20of%20topic%20models%20using%20text%20summaries&amp;author=Wan&amp;publication_year=2016" title="Automatic labeling of topic models using text summaries" data-jats-ref-type="bibr" data-jats-rid="ref-44">Wan &amp; Wang (2016)</a> proposed a novel method for topic labeling that runs summarization algorithms over documents relating to a topic. Four summarization algorithms are tested: TopicLexRank, MEAD, Submodular, and Summary label. Some various vector-based methods have been also applied to label the topics. <a class="xref xref-bibr" href="https://scholar.google.com/scholar_lookup?title=Automatic%20generation%20of%20topic%20labels&amp;author=Alokaili&amp;publication_year=2020" title="Automatic generation of topic labels" data-jats-ref-type="bibr" data-jats-rid="ref-1">Alokaili, Aletras &amp; Stevenson (2020)</a> developed a tool to measure the semantic distance between a phrase and a topic model. They proposed a sequence-to-sequence neural-based approach to name topics using distant supervision. It represents phrase labels as word distributions and approaches the label problem as an optimization problem. Recent studies have shown that similarity measures of features are more efficient when based on topic models techniques than they are based on bag of words and TF-IDF (<a class="xref xref-bibr" href="http://arxiv.org/abs/1309.6874" title="Integrating document clustering and topic modeling" data-jats-ref-type="bibr" data-jats-rid="ref-46">Xie &amp; Xing, 2013</a>). In this context, the semantic similarity between two documents was also investigated (<a class="xref xref-bibr" href="https://doi.org/10.1007%2F978-3-642-39593-2_17" title="Experiments with Semantic Similarity Measures Based on LDA and LSA" data-jats-ref-type="bibr" data-jats-rid="ref-33">Niraula et al., 2013</a>). The most related work to our context is probably the use of topic modeling features to improve the word sense disambiguation by <a class="xref xref-bibr" href="https://doi.org/10.1016%2Fj.ipm.2021.102592" title="Adaptive and hybrid context-aware fine-grained word sense disambiguation in topic modeling based document representation" data-jats-ref-type="bibr" data-jats-rid="ref-23">Li &amp; Suzuki (2021)</a> and also the work in <a class="xref xref-bibr" href="https://doi.org/10.1016%2Fj.eswa.2017.03.020" title="Text classification method based on self-training and lda topic models" data-jats-ref-type="bibr" data-jats-rid="ref-35">Pavlinek &amp; Podgorelec (2017)</a> in which they present features representation with a semi-supervised approach using self-training learning. As our ultimate motivation is to classify the text with good performance, so for the classification of text a lot of methods and frameworks have been developed. If we look at the aspect of feature engineering techniques, then there are a lot of mechanisms used in different studies to tune the feature for better text classification. In this way, <a class="xref xref-bibr" href="https://doi.org/10.9717%2Fkmms.2015.18.11.1391" title="A method for user sentiment classification using instagram hashtags" data-jats-ref-type="bibr" data-jats-rid="ref-32">Nam, Lee &amp; Shin (2015)</a> used the social media hashtags for sentiment classification of texts; they collected the data with the hashtags and make use of hashtags to classify the sentiments in positive and negative categories. Before the topic modeling techniques, graph embeddings were also used with n-gram features to better classify the text; <a class="xref xref-bibr" href="https://scholar.google.com/scholar_lookup?title=Text%20categorization%20as%20a%20graph%20classification%20problem&amp;author=Rousseau&amp;publication_year=2015" title="Text categorization as a graph classification problem" data-jats-ref-type="bibr" data-jats-rid="ref-37">Rousseau, Kiagias &amp; Vazirgiannis (2015)</a> analyzed the text categorization problem as a graph classification problem, and they represent the textual documents as a graph of words. They used a combination of n-grams and graph word representation to increase the performance of text classifiers. <a class="xref xref-bibr" href="https://doi.org/10.1016%2Fj.aej.2021.02.009" title="Efficient english text classification using selected machine learning techniques" data-jats-ref-type="bibr" data-jats-rid="ref-25">Luo (2021</a>) leveraged the word frequency, question marks, full stops, initial word, and final word of the document. While the use of word taxonomies as means for constructing new semantic features that may improve the performance of the learned classifiers was explored by <a class="xref xref-bibr" href="https://doi.org/10.1016%2Fj.csl.2020.101104" title="tax2vec: constructing interpretable features from taxonomies for short text classification" data-jats-ref-type="bibr" data-jats-rid="ref-49">Škrlj et al. (2021)</a>. In-text mining, <a class="xref xref-bibr" href="https://scholar.google.com/scholar_lookup?title=A%20novel%20approach%20for%20ontology-based%20feature%20vector%20generation%20for%20web%20text%20document%20classification&amp;author=Elhadad&amp;publication_year=2018" title="A novel approach for ontology-based feature vector generation for web text document classification" data-jats-ref-type="bibr" data-jats-rid="ref-9">Elhadad, Badran &amp; Salama (2018)</a> present an ontology-based web document classifier, while <a class="xref xref-bibr" href="https://scholar.google.com/scholar_lookup?title=Multimodal%20biological%20analysis%20using%20nlp%20and%20expression%20profile&amp;author=Kim&amp;publication_year=2018" title="Multimodal biological analysis using nlp and expression profile" data-jats-ref-type="bibr" data-jats-rid="ref-16">Kim et al. (2018)</a> propose a clustering-based algorithm for document classification that also benefits from knowledge stored in the underlying ontologies.</p>
         <section class="sec">
            <h3 class="heading">Topic modelling</h3>
            <p id="p-6">Latent Dirichlet Allocation (LDA) first introduced by <a class="xref xref-bibr" href="https://scholar.google.com/scholar_lookup?title=Latent%20dirichlet%20allocation&amp;author=Blei&amp;publication_year=2003" title="Latent dirichlet allocation" data-jats-ref-type="bibr" data-jats-rid="ref-3">Blei, Ng &amp; Jordan (2003)</a>, is a probabilistic generative model that can be used to estimate the multinomial observations by an unsupervised learning approach. To model the topics, it is a method to perform latent semantic analysis (LSA). The main idea behind LSA is to extract the latent structure of topics or concepts from the given documents. The term latent semantic was coined by <a class="xref xref-bibr" href="https://doi.org/10.1016%2Fj.eswa.2020.113401" title="Word2vec-based latent semantic analysis (w2v-lsa) for topic modeling: a study on blockchain technology trend analysis" data-jats-ref-type="bibr" data-jats-rid="ref-17">Kim, Park &amp; Lee (2020)</a> who showed that the co-occurrence of words in the documents can be used to show the semantic structure of the document and ultimately find the concept or topic. With LDA each document is represented as a multinomial distribution of topics where the topic can be seen as high-level concepts to documents. The assumption on which it is based is that document is a collection created from topics, where each topic is presented with a mixture of words. Each variable and parameter of the LDA model is defined in the <a class="xref xref-table" href="#table-1" data-jats-ref-type="table" data-jats-rid="table-1">Table 1</a>.</p>
            <figure class="table-wrap" id="table-1"><div class="caption">
<span class="caption-label">Table 1: </span>
                  <div class="title">Latent Dirichlet Allocation (LDA) generalization process model.</div>
               </div>
               
               <div class="table-container"><table class="table table-bordered table-condensed table-hover">
                     <colgroup>
                        <col>
                     </colgroup>
                     <thead>
                        <tr>
                           <th>For each document sample m<i>ϵ</i>M topic proportions <i>θ</i>m from the alpha dirichlet distribution, Then for each word placeholder n in the document m, we:</th>
                        </tr>
                     </thead>
                     <tbody>
                        <tr>
                           <td>
                              <ol class="list" id="list-10" data-jats-list-type="order">
                                 <li class="list-item">
<p id="p-7">We randomly choose a topic Z<sup>m</sup>,n in accordance with proportions of sample topic</p>
                                 </li>
                                 <li class="list-item">
<p id="p-8">We randomly choose a word W<sup>m</sup>,n from the set of multinomial distributions <i>ϕ</i>k of already chosen topic.</p>
                                 </li>
                              </ol>
                           </td>
                        </tr>
                        <tr>
                           <td>In the generalization process of LDA, the <i>α</i> and <i>β</i> are hyper vector parameters that determine the dirichlet prior on <i>θ</i>m is a collection of topic distributions for all the documents and on parameter <i>ϕ</i>, they determine the word distributions per topic (<a class="xref xref-bibr" href="https://doi.org/10.1016%2Fj.eswa.2017.03.020" title="Text classification method based on self-training and lda topic models" data-jats-ref-type="bibr" data-jats-rid="ref-35">Pavlinek &amp; Podgorelec, 2017</a>).</td>
                        </tr>
                        <tr>
                           <td><i>Parameters and variables:</i></td>
                        </tr>
                        <tr>
                           <td>M: total no. of documents</td>
                        </tr>
                        <tr>
                           <td>N: total no. of words</td>
                        </tr>
                        <tr>
                           <td>K: number of topics</td>
                        </tr>
                        <tr>
                           <td>
<i>ϕ</i>k: word distributions of topic K</td>
                        </tr>
                        <tr>
                           <td>Z<sup>m</sup>,n: a document topic over words</td>
                        </tr>
                        <tr>
                           <td>W<sup>m</sup>,n: topic words of specific document</td>
                        </tr>
                        <tr>
                           <td>
<i>α</i>: hyper vector parameter</td>
                        </tr>
                        <tr>
                           <td>
<i>β</i>: hyper vector parameter</td>
                        </tr>
                        <tr>
                           <td>
<i>θ</i>m: topic distribution of document</td>
                        </tr>
                     </tbody>
                  </table></div>
<div class="object-id article-component-doi">DOI: <a href="https://doi.org/10.7717/peerjcs.677/table-1" data-toggle="tooltip" title="Cite this object using this DOI">10.7717/peerjcs.677/table-1</a>
</div>
            </figure>
            <p id="p-9">From the above model depicted in <a class="xref xref-fig" href="#fig-1" data-jats-ref-type="fig" data-jats-rid="fig-1">Fig. 1</a>, the generalization of LDA is described as follows:</p>
            <figure class="fig" itemprop="image" itemscope="itemscope" itemtype="https://schema.org/ImageObject" id="fig-1"><div class="image-container"><a href="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-1-2x.jpg" title="View the full image" class="fresco" data-fresco-caption="Figure 1: Generalization of the LDA topic modelling model." data-fresco-group="figure" data-fresco-options="fit: 'width', ui: 'outside', thumbnails: false, loop: true, position: true, overflow: true, preload: false"><img class="graphic" src="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-1-1x.jpg" itemprop="contentUrl" sizes="(min-width: 1200px) 581px, (max-width: 1199px) and (min-width: 980px) 462px, (max-width: 979px) and (min-width: 768px) 347px, (max-width: 767px) calc(100vw - 50px)" srcset="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-1-2x.jpg 1200w, https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-1-1x.jpg 600w, https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-1-small.jpg 355w" data-image-id="fig-1" alt="Generalization of the LDA topic modelling model." data-full="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-1-full.png" data-thumb="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-1-thumb.jpg" data-original="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-1.png" data-image-type="figure" data-jats-mimetype="image" data-jats-mime-subtype="png" width="600" height="253"></a></div>
<figcaption itemprop="description">
                  <h4 class="heading">
<span class="caption-label">Figure 1: </span>Generalization of the LDA topic modelling model.</h4>
               <div class="figcaption-footer">
<div class="article-image-download"><a href="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-1-full.png" class="btn btn-mini" download="peerj-cs-677-fig-1.png" itemprop="url"><i class="icon-large icon-picture"> </i> Download full-size image</a></div>
<div class="object-id article-component-doi">DOI: <a href="https://doi.org/10.7717/peerjcs.677/fig-1" data-toggle="tooltip" title="Cite this object using this DOI">10.7717/peerjcs.677/fig-1</a>
</div>
</div></figcaption></figure>
         </section>
      </section>
      <section class="sec">
         <h2 class="heading">Proposed Framework</h2>
         <p id="p-10"><a class="xref xref-fig" href="#fig-2" data-jats-ref-type="fig" data-jats-rid="fig-2">Figure 2</a> shows the abstract model, which depicts the generic framework, and the detailed framework in the <a class="xref xref-fig" href="#fig-3" data-jats-ref-type="fig" data-jats-rid="fig-3">Fig. 3</a> depicted that we aim to build and train text classifiers with the use of hidden semantic topics.</p>
         <figure class="fig" itemprop="image" itemscope="itemscope" itemtype="https://schema.org/ImageObject" id="fig-2"><div class="image-container"><a href="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-2-2x.jpg" title="View the full image" class="fresco" data-fresco-caption="Figure 2: Abstract model explanation of proposed framework." data-fresco-group="figure" data-fresco-options="fit: 'width', ui: 'outside', thumbnails: false, loop: true, position: true, overflow: true, preload: false"><img class="graphic" src="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-2-1x.jpg" itemprop="contentUrl" sizes="(min-width: 1200px) 581px, (max-width: 1199px) and (min-width: 980px) 462px, (max-width: 979px) and (min-width: 768px) 347px, (max-width: 767px) calc(100vw - 50px)" srcset="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-2-2x.jpg 1200w, https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-2-1x.jpg 600w, https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-2-small.jpg 355w" data-image-id="fig-2" alt="Abstract model explanation of proposed framework." data-full="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-2-full.png" data-thumb="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-2-thumb.jpg" data-original="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-2.png" data-image-type="figure" data-jats-mimetype="image" data-jats-mime-subtype="png" width="600" height="104"></a></div>
<figcaption itemprop="description">
               <h3 class="heading">
<span class="caption-label">Figure 2: </span>Abstract model explanation of proposed framework.</h3>
            <div class="figcaption-footer">
<div class="article-image-download"><a href="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-2-full.png" class="btn btn-mini" download="peerj-cs-677-fig-2.png" itemprop="url"><i class="icon-large icon-picture"> </i> Download full-size image</a></div>
<div class="object-id article-component-doi">DOI: <a href="https://doi.org/10.7717/peerjcs.677/fig-2" data-toggle="tooltip" title="Cite this object using this DOI">10.7717/peerjcs.677/fig-2</a>
</div>
</div></figcaption></figure>
         <figure class="fig" itemprop="image" itemscope="itemscope" itemtype="https://schema.org/ImageObject" id="fig-3"><div class="image-container"><a href="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-3-2x.jpg" title="View the full image" class="fresco" data-fresco-caption="Figure 3: Proposed framework in detail showing each steps involved." data-fresco-group="figure" data-fresco-options="fit: 'width', ui: 'outside', thumbnails: false, loop: true, position: true, overflow: true, preload: false"><img class="graphic" src="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-3-1x.jpg" itemprop="contentUrl" sizes="(min-width: 1200px) 581px, (max-width: 1199px) and (min-width: 980px) 462px, (max-width: 979px) and (min-width: 768px) 347px, (max-width: 767px) calc(100vw - 50px)" srcset="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-3-2x.jpg 1200w, https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-3-1x.jpg 600w, https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-3-small.jpg 355w" data-image-id="fig-3" alt="Proposed framework in detail showing each steps involved." data-full="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-3-full.png" data-thumb="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-3-thumb.jpg" data-original="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-3.png" data-image-type="figure" data-jats-mimetype="image" data-jats-mime-subtype="png" width="600" height="326"></a></div>
<figcaption itemprop="description">
               <h3 class="heading">
<span class="caption-label">Figure 3: </span>Proposed framework in detail showing each steps involved.</h3>
            <div class="figcaption-footer">
<div class="article-image-download"><a href="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-3-full.png" class="btn btn-mini" download="peerj-cs-677-fig-3.png" itemprop="url"><i class="icon-large icon-picture"> </i> Download full-size image</a></div>
<div class="object-id article-component-doi">DOI: <a href="https://doi.org/10.7717/peerjcs.677/fig-3" data-toggle="tooltip" title="Cite this object using this DOI">10.7717/peerjcs.677/fig-3</a>
</div>
</div></figcaption></figure>
         <p id="p-11">The framework consist of the following tasks:</p>
         <ol class="list" id="list-2" data-jats-list-type="order">
            <li class="list-item">
<p id="p-12">Collect the appropriate dataset from any domain, we choose Amazon product reviews dataset and social media dataset of different disasters.</p>
            </li>
            <li class="list-item">
<p id="p-13">Apply the LDA topic modeling with different parameters on a dataset and generate the hidden semantic topics with weights and select the appropriate LDA model.</p>
            </li>
            <li class="list-item">
<p id="p-14">Create the topic distributions for every review/tweet/document using the LDA model and convert them into feature vectors to feed in supervised algorithms.</p>
            </li>
            <li class="list-item">
<p id="p-15">Build supervised learning classifier and get F1, Accuracy, Precision, and Recall score to check the classification performance of the proposed model.</p>
            </li>
            <li class="list-item">
<p id="p-16">Also did experiment on unseen data, by applying the LDA topic distributions of current data and investigate to see if it generalizes.</p>
            </li>
         </ol>
         <p id="p-17">The first step is more important choosing the appropriate dataset, the dataset must be large enough and rich enough to cover a variety of topics that are suited to classification problems. This means that the nature of data should be discriminative enough to be observed by humans. The second step explains that we apply the famous topic modeling approach such as LDA (latent Dirichlet allocation) for creating topics from datasets. There is a lot of topic modeling approaches for topic modeling such as pLSA or LDA. We choose LDA because it has more concrete document generation. LDA was briefly discussed in the LDA topic modeling section. 3) As topic modeling gives the number of topics per document, we developed different LDA models with different settings such as with 10, 15, 20 topics also with the lemmatized data and using bigrams and trigrams, and also with different iterations. We observed the topic distributions outputs were impressive and satisfy our supervised learning classifiers, then we grab the topic distributions. 4) We build the classifiers by using the topic distributions as feature vectors, we choose supervised learning classifiers such as MaxEntropy, Max entropy with stochastic gradient descent (sgd) optimizer, and mostly used support vector machine (SVM). 5) This is an additional step to test the framework on unseen data, we run the classifiers on unseen data by creating topic distributions from the current LDA model and see if it generalizes or not. The extensive detail of each step will be discussed further in the relevant section.</p>
         <section class="sec">
            <h3 class="heading">Datasets</h3>
            <p id="p-18">Selecting the appropriate dataset is more important because the topics generated from these datasets directly impact the classifier results and performance of classifiers. Therefore to make these things in mind, we choose two large datasets of various nature. One dataset is Amazon review datasets about products and people’s sentiments about the products. The total reviews were data span a period of more than 10 years, including all 500,000 reviews up to October 2012 <a class="xref xref-bibr" href="https://scholar.google.com/scholar_lookup?title=From%20amateurs%20to%20connoisseurs:%20modeling%20the%20evolution%20of%20user%20expertise%20through%20online%20reviews&amp;author=McAuley&amp;publication_year=2013" title="From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews" data-jats-ref-type="bibr" data-jats-rid="ref-27">McAuley &amp; Leskovec (2013)</a>. Another dataset was a collection of various disaster-related social media datasets (collected from <a class="xref xref-bibr" href="https://scholar.google.com/scholar_lookup?title=Crisislex:%20a%20lexicon%20for%20collecting%20and%20filtering%20microblogged%20communications%20in%20crises&amp;author=Olteanu&amp;publication_year=2014" title="Crisislex: a lexicon for collecting and filtering microblogged communications in crises" data-jats-ref-type="bibr" data-jats-rid="ref-34">Olteanu et al. 2014</a>, <a class="xref xref-bibr" href="https://scholar.google.com/scholar_lookup?title=Practical%20extraction%20of%20disaster-relevant%20information%20from%20social%20media&amp;author=Imran&amp;publication_year=2013" title="Practical extraction of disaster-relevant information from social media" data-jats-ref-type="bibr" data-jats-rid="ref-14">Imran et al., 2013</a>) that contains tweets from various disasters annotated based on relatedness. The tweets were collected during seven crisis occurred during 2012 and 2013 and human-made crisis or natural disaster occurred in 2016. The total tweets were 70k, with categories of different relatedness such as relevant, irrelevant, on-topic, or off-topic. Full detail of datasets given in <a class="xref xref-table" href="#table-2" data-jats-ref-type="table" data-jats-rid="table-2">Table 2</a>. To check the effectiveness in various domains of our LDA models and classifiers we choose these datasets of different nature, tweet datasets are mostly short texts and noisy, and Amazon review dataset is more large text and compact detail of about products in the form of reviews.</p>
            <figure class="table-wrap" id="table-2"><div class="caption">
<span class="caption-label">Table 2: </span>
                  <div class="title">Dataset Statistics in detail.</div>
               </div>
               
               <div class="table-container"><table class="table table-bordered table-condensed table-hover">
                     <colgroup>
                        <col>
                        <col>
                     </colgroup>
                     <thead>
                        <tr>
                           <th><b>Dataset</b></th>
                           <th><b>Description</b></th>
                        </tr>
                     </thead>
                     <tbody>
                        <tr>
                           <td>Amazon user Reviews</td>
                           <td>Total 568,454 Reviews</td>
                        </tr>
                        <tr>
                           <td></td>
                           <td>
                              <ol class="list" id="list-11" data-jats-list-type="order">
                                 <li class="list-item">
<p id="p-19">256,059 users</p>
                                 </li>
                                 <li class="list-item">
<p id="p-20">74,528 products</p>
                                 </li>
                                 <li class="list-item">
<p id="p-21">260 users with &gt;50 reviews</p>
                                 </li>
                                 <li class="list-item">
<p id="p-22">Target Categories: Positive, Negative</p>
                                 </li>
                                 <li class="list-item">
<p id="p-23">Dataset includes, Summary, Text, Sentiment score, Product ID</p>
                                 </li>
                              </ol>
                           </td>
                        </tr>
                        <tr>
                           <td>Social media Dataset</td>
                           <td>Total 70k tweets with different categories of relatedness</td>
                        </tr>
                        <tr>
                           <td></td>
                           <td>
                              <ol class="list" id="list-12" data-jats-list-type="order">
                                 <li class="list-item">
<p id="p-24">Total 7 crisis related datasets each contains 10k tweets.</p>
                                 </li>
                                 <li class="list-item">
<p id="p-25">On topic (related to crisis), off topic (not related to crisis)</p>
                                 </li>
                                 <li class="list-item">
<p id="p-26">Tweets include tweet id, tweet content, time, tweet relatedness.</p>
                                 </li>
                              </ol>
                           </td>
                        </tr>
                     </tbody>
                  </table></div>
<div class="object-id article-component-doi">DOI: <a href="https://doi.org/10.7717/peerjcs.677/table-2" data-toggle="tooltip" title="Cite this object using this DOI">10.7717/peerjcs.677/table-2</a>
</div>
            </figure>
         </section>
         <section class="sec">
            <h3 class="heading">Data pre-processing</h3>
            <p id="p-27">All the pre-processing steps are shown in <a class="xref xref-fig" href="#fig-4" data-jats-ref-type="fig" data-jats-rid="fig-4">Fig. 4</a>, like removing punctuations, transforming to lowercase letters, and make into lists, the detail of remaining steps is in following section.</p>
            <figure class="fig" itemprop="image" itemscope="itemscope" itemtype="https://schema.org/ImageObject" id="fig-4"><div class="image-container"><a href="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-4-2x.jpg" title="View the full image" class="fresco" data-fresco-caption="Figure 4: Pre-processing steps involved in data pre-processing." data-fresco-group="figure" data-fresco-options="fit: 'width', ui: 'outside', thumbnails: false, loop: true, position: true, overflow: true, preload: false"><img class="graphic" src="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-4-1x.jpg" itemprop="contentUrl" sizes="(min-width: 1200px) 581px, (max-width: 1199px) and (min-width: 980px) 462px, (max-width: 979px) and (min-width: 768px) 347px, (max-width: 767px) calc(100vw - 50px)" srcset="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-4-2x.jpg 1200w, https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-4-1x.jpg 600w, https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-4-small.jpg 355w" data-image-id="fig-4" alt="Pre-processing steps involved in data pre-processing." data-full="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-4-full.png" data-thumb="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-4-thumb.jpg" data-original="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-4.png" data-image-type="figure" data-jats-mimetype="image" data-jats-mime-subtype="png" width="600" height="210"></a></div>
<figcaption itemprop="description">
                  <h4 class="heading">
<span class="caption-label">Figure 4: </span>Pre-processing steps involved in data pre-processing.</h4>
               <div class="figcaption-footer">
<div class="article-image-download"><a href="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-4-full.png" class="btn btn-mini" download="peerj-cs-677-fig-4.png" itemprop="url"><i class="icon-large icon-picture"> </i> Download full-size image</a></div>
<div class="object-id article-component-doi">DOI: <a href="https://doi.org/10.7717/peerjcs.677/fig-4" data-toggle="tooltip" title="Cite this object using this DOI">10.7717/peerjcs.677/fig-4</a>
</div>
</div></figcaption></figure>
            <section class="sec">
               <h4 class="heading">Tokenization and lemmatization</h4>
               <p id="p-28">Tokenization is the process of breaking the document or tweets into words called tokens. A token is an individual part of a sentence having some semantic values. Like Sentence hurricane is coming would be tokenized into ‘hurricane’, ‘is’, ‘coming’. We have utilized the Spacy function with the core English language model for tokenization and lemmatization (<a class="ext-link" href="https://spacy.io/usage/models" data-jats-ext-link-type="uri">https://spacy.io/usage/models</a>). The beauty of this Spacy function is that it gives you part of speech detail of every sentence, and you can choose from that which part of speech you need for further processing in the specific context. Spacy is capable enough to also give sentence dependencies in case you need them while performing graph embeddings. After tokenization, we need to see which part of the sentence we need and also need to extract the words into their original forms. Both the lemmatization process and the stemming process are used for this purpose. Many typical text classification techniques use stemming with the help of port stemmer, and snowball stemmer, such as words ‘compute’, ’computer’, ’computing’, ’computed’ would be reduced into word ‘comput’, a little drawback with stemming is that it reduces the word into its root form without looking into it the word is found in the dictionary of that specific language or not, as you can see ‘comput’ is not a dictionary word. There comes the lemmatization, Spacy; we performed the lemmatization. Lemmatization also reduced the word into its root form but by keeping in mind the dictionary database. With lemmatization the above examples of words (‘compute’,’ computer’,’ computed’,’ computing’) would be reduced to root form as (‘compute’,’ computer’,’ computed’,’ computing’), respectively, by keeping in mind the dictionary. While implementing the lemmatization part, we keep the sentence with words having only the ‘nouns’, ‘adjectives’, and ‘verbs’, which is useful if you need to be more specified about the LDA topics and in this way your topic distributions make more sense.</p>
            </section>
            <section class="sec">
               <h4 class="heading">Bigrams and trigrams</h4>
               <p id="p-29">Sometimes in large and sparse texts, we see the nouns or adjectives that make of multiple words, so to make the semantic context of words into sentences we need bigrams and even trigrams so that they will not break into single separate unigram tokens and lost their meaning and semantic of a sentence. Bigrams is an approach to make words that are of two tokens to remain in their semantic shape so that sentence contextual meaning would not be lost. We achieved this through Genism’s phrases class (<a class="ext-link" href="https://radimrehurek.com/gensim/models/ldamodel.html" data-jats-ext-link-type="uri">https://radimrehurek.com/gensim/models/ldamodel.html</a>), which allows us to group semantically related phrases into one token for LDA implementation. Such as ice_cream, new_york listed as single tokens. The output of genism’s phrases bigram mod class is a list of lists where each one represents reviews, documents, or tweets, and strings in each list is a mix of unigrams and bigrams. In the same way, for the sake of uniformity of three phrases words tokens, we applied trigrams through genism’s phrases class to group semantically related phrases into single tokens for LDA implementation. This normally mostly applies to country names such as united_states_of_America, or people’s_republic_of_china, etc. The output of genism’s phrases trigrams is a list of a list where each list represents review, document, or tweets, and strings in the list is a mix of, unigrams, bigrams, and trigrams. To make the LDA model more comprehensive and specific we applied the bigrams and trigrams.</p>
            </section>
            <section class="sec">
               <h4 class="heading">Sparse vector for LDA model</h4>
               <p id="p-30">Once you have the list of lists of different bigrams, and trigrams then you pass into Genism’s dictionary class. This will give the representation in the form of a word frequency count of each word in strings in the list. Genism’s LDA implementation needs text as a sparse vector for the LDA model. We have used Genism’s library doc2bow simply counts the occurrences of each word in documents and creates and returns the spare vectors of our text reviews to feed into the LDA model. The sparse vector [(0, 1), (1, 1)] therefore reads: in the document Human–computer interaction, the words computer (id 0) and human (id 1) appear once; the other ten dictionary words appear (implicitly) zero times.</p>
            </section>
         </section>
         <section class="sec">
            <h3 class="heading">LDA Model</h3>
            <section class="sec">
               <h4 class="heading">Apply LDA Model</h4>
               <p id="p-31">To apply the LDA model, there is a specific representation of the content that we need in the form of corpus and along with the corpus, we need the dictionary that assists that corpus. For different LDA models, we create a different type of corpus, with unigrams, bigrams, and trigrams. LDA model is specifically described in detail in <a class="xref xref-fig" href="#fig-1" data-jats-ref-type="fig" data-jats-rid="fig-1">Fig. 1</a>.</p>
            </section>
            <section class="sec">
               <h4 class="heading">LDA Model selection</h4>
               <p id="p-32">LDA model selection was the most difficult task, as it can ultimately impact the results of supervised classifiers. Therefore, to choose the best LDA model with many numbers of topics in the model was a time-consuming task. Finding the exact number of topics suited for a better LDA model was the main focus of previous studies (<a class="xref xref-bibr" href="https://doi.org/10.1007%2F978-3-662-44848-9_32" title="Machine Learning and Knowledge Discovery in Databases. ECML PKDD 2014" data-jats-ref-type="bibr" data-jats-rid="ref-13">Greene, O’Callaghan &amp; Cunningham, 2014</a>). The first technique was manual, which is to choose the different number of range of topics and check and investigate the results if it makes any sense. The second one was analyzing the coherence score metrics of LDA models more coherence increase means better model. Then we also explored the models by giving several various topics and every topic distributions results and vectors feed into supervised algorithms and check which one gives the better results in terms of F1 score. Approach one was very time consuming, the second one was to see the coherence score but that just check the topic identifications have not a large impact on supervised algorithms results, the third approach seems suitable in our context but our main purpose was to classify the documents/reviews with best results. Genism also provides a Hierarchical Dirichlet process (HDP) (<a class="ext-link" href="https://radimrehurek.com/gensim/models/hdpmodel.html" data-jats-ext-link-type="uri">https://radimrehurek.com/gensim/models/hdpmodel.html</a>) class that used to seek the correct number of topics for a different type of datasets it is not necessary to type the number of topics in HDP class and automatically seeks the number of topics based on data. It is only necessary to run this for a few times, and if it provides the same results with the same number of topics again and again then those number of topics are perfect learning topics for your type of data.</p>
            </section>
            <section class="sec">
               <h4 class="heading">Hierarchical Dirichlet process</h4>
               <p id="p-33">According to Genism’s documents, the hierarchical Dirichlet process (HDP) is based on stick-breaking construction that is an analogy used in the Chinese restaurant process. For example, in <a class="xref xref-fig" href="#fig-5" data-jats-ref-type="fig" data-jats-rid="fig-5">Fig. 5</a>, we need to assign 8 to any of the topics C1, C2, C3. There is a 3/8 probability that 8 will land in topic C1 topic, 4/8 probability that 8 will land in C2 topic, there is 1/3 probability that 8 will land in topic C3. HDP coherently discovered the topics, like bigger the cluster is the more likely it for the word to join that cluster of topics. It is a good way to choose a fixed set of topics for the LDA model (<a class="xref xref-bibr" href="https://scholar.google.com/scholar_lookup?title=Online%20variational%20inference%20for%20the%20hierarchical%20dirichlet%20process&amp;author=Wang&amp;publication_year=2011" title="Online variational inference for the hierarchical dirichlet process" data-jats-ref-type="bibr" data-jats-rid="ref-45">Wang, Paisley &amp; Blei, 2011</a>). While implementing HDP on our datasets, we test our third approach as well which was manually give the topic number and check the classifier results, to ensure consistency we built around 15 LDA models with different parameters, and compared with HDP results, and choose the best ones, that has a high influence on classifiers results and that gives best classifier results. In the end, the best LDA models were with lemmatized texts (with nouns, adjectives, and verbs), with 100 iterations, and with 10, 15, and 20 topics.</p>
               <figure class="fig" itemprop="image" itemscope="itemscope" itemtype="https://schema.org/ImageObject" id="fig-5"><div class="image-container"><a href="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-5-2x.jpg" title="View the full image" class="fresco" data-fresco-caption="Figure 5: Chinese restaurant analogy: HDP process based on Chinese restaurant analogy; in this analogy, C1,C2,C3 are tables and surrounding them are customers (1, 2,…,7), and new customer 8 needs to be assigned to any of the tables; so there is a 3/8 probability that the customer will be assigned to C1, a 4/8 probability 8 will be assigned to C2 and a 1/8 probability that the customer will be assigned to C3." data-fresco-group="figure" data-fresco-options="fit: 'width', ui: 'outside', thumbnails: false, loop: true, position: true, overflow: true, preload: false"><img class="graphic" src="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-5-1x.jpg" itemprop="contentUrl" sizes="(min-width: 1200px) 581px, (max-width: 1199px) and (min-width: 980px) 462px, (max-width: 979px) and (min-width: 768px) 347px, (max-width: 767px) calc(100vw - 50px)" srcset="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-5-2x.jpg 1200w, https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-5-1x.jpg 600w, https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-5-small.jpg 355w" data-image-id="fig-5" alt="Chinese restaurant analogy: HDP process based on Chinese restaurant analogy; in this analogy, C1,C2,C3 are tables and surrounding them are customers (1, 2,…,7), and new customer 8 needs to be assigned to any of the tables; so there is a 3/8 probability that the customer will be assigned to C1, a 4/8 probability 8 will be assigned to C2 and a 1/8 probability that the customer will be assigned to C3." data-full="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-5-full.png" data-thumb="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-5-thumb.jpg" data-original="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-5.png" data-image-type="figure" data-jats-mimetype="image" data-jats-mime-subtype="png" width="600" height="299"></a></div>
<figcaption itemprop="description">
                     <h5 class="heading">
<span class="caption-label">Figure 5: </span>Chinese restaurant analogy: HDP process based on Chinese restaurant analogy; in this analogy, C1,C2,C3 are tables and surrounding them are customers (1, 2,…,7), and new customer 8 needs to be assigned to any of the tables; so there is a 3/8 probability that the customer will be assigned to C1, a 4/8 probability 8 will be assigned to C2 and a 1/8 probability that the customer will be assigned to C3.</h5>
                  <div class="figcaption-footer">
<div class="article-image-download"><a href="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-5-full.png" class="btn btn-mini" download="peerj-cs-677-fig-5.png" itemprop="url"><i class="icon-large icon-picture"> </i> Download full-size image</a></div>
<div class="object-id article-component-doi">DOI: <a href="https://doi.org/10.7717/peerjcs.677/fig-5" data-toggle="tooltip" title="Cite this object using this DOI">10.7717/peerjcs.677/fig-5</a>
</div>
</div></figcaption></figure>
            </section>
         </section>
         <section class="sec">
            <h3 class="heading">Train classifiers with topic distributions</h3>
            <p id="p-34">The method for training the classifiers with topic distributions contains these steps: first, we choose the text classification algorithm from different learning methods; second we incorporate the topic distributions with some manually engineered features into the training data, test data, and future unseen data with specified representation that classifier needed. Then, in the end, we train the classifier and get the F1 measure scores.</p>
         </section>
         <section class="sec">
            <h3 class="heading">Choose classical text classification learning methods</h3>
            <p id="p-35">We have chosen the logistic regression classifier aka MaxEnt (MaxEntropy) and Support vector machines (SVM) to evaluate our framework. The reason for choosing these classifiers is that our implementation of topic distribution works with data represented as dense or sparse arrays of floating-point values for the feature vectors. Therefore, these models fit with this type of implementation context and can handle the sparse and dense type of feature arrays with floating values. Also, MaxEnt makes no independent assumptions for its features like uni-grams, bigrams, and trigrams. It implies that we can add features and phrases to MaxEnt without the fear of feature overlapping (<a class="xref xref-bibr" href="https://scholar.google.com/scholar_lookup?title=Twitter%20sentiment%20classification%20using%20distant%20supervision&amp;author=Go&amp;publication_year=2009" title="Twitter sentiment classification using distant supervision" data-jats-ref-type="bibr" data-jats-rid="ref-12">Go, Bhayani &amp; Huang, 2009</a>).</p>
         </section>
         <section class="sec">
            <h3 class="heading">Integrate topic distributions into dataset</h3>
            <p id="p-36">After implementing the LDA model on data and getting topics from the data, we created the topic distributions and incorporate the topic distribution, original document and one manually coded feature which is the frequency of document, into the classifier in a way that resulting vector representation would be according to the machine learning classifier format. Given a dataset <i>W</i> = <i>w</i><sup>m</sup> <sup><i>k</i></sup>, for example we need to classify w from a collection of documents <i>W</i>.<i>w</i> can be training, testing, or unseen data. Topic extraction for w needs to perform LDA. However, the number of iterations for inference is much smaller than of parameter estimation. The topic inference/extraction is demonstrated in the LDA generalization process in <a class="xref xref-fig" href="#fig-1" data-jats-ref-type="fig" data-jats-rid="fig-1">Fig. 1</a>, here in algorithm 1, we explain how we integrate those topics into feature vectors.</p>
            <p id="p-37">This algorithm consists of two main components, first, it creates the topic distribution in the form of probability and the second one is to convert those topic probability distributions along with the length of each document to create topic-oriented feature embeddings. As presented in the algorithm we intended to learn topic-based feature embeddings to be used in classifiers. We began by creating topic distributions for all the documents in the dataset, which are nothing but word distributions along with their weights, subsequently, we convert these topics into the format to create feature vectors that are ultimately used in classifiers. For this, it utilized the get document topic function to be applied on extracted topic words (line 7), which gives output in the form of integer and float values of each topic, after the algorithm learns the topic distributions float values and mapped into feature vectors embeddings to be used in the classifier (lines nine to 11).</p>
            <p id="p-38"> 
               <pre><code> 
_______________________ 
 Algorithm 1: Topic2vec: Integrating topic distributions into feature vec- 
  tors                                                                                            ____ 
    Input:  Dataset in form of document and tweets 
   Output:  topic embeddings feature vector to be used in 
             classifier 
 1  ki= Topic for each document; 
 2  Initialization; 
 3  topics (ki)  ← LDA (pre-processed text (tweets/documents)); 
 4  create topic distributions (ki)  ← Dataset; 
 5  while not the end of document  do 
     6   create topic embeddings; 
7   for each document  do 
    8   topic distributions = get document topic(topics); 
9   end 
10   for each topic distributions  do 
    11   topic distributions ← feature vector(topic dist length 
  of documents); 
12   feature vectors ← array(topic dist and length of 
  document); 
13   end 
14  end    </code></pre>
            </p>
            <p id="p-39">After we doing topic inference through LDA, we will integrate the topic distributions <i>tdm</i> = <i>tdm</i>,1….., <i>tdm</i>,2….., <i>tdm</i>, <i>k</i> and original document <i>di</i> = <i>dim</i>, 1….<i>dim</i>, 2….., <i>dim</i>, <i>n</i> in a order that resulting vector is suitable for the chosen learning technique. Because our classifier only can take discrete feature attributes, so we need to convert our topic distributions into the form of discrete values. Here we describe how we integrate the topic distribution into documents to get the resultant feature vector to be used into classifiers. Because our classifiers require discrete feature attributes so it is necessary to discretized probability values in <i>tdm</i> obtained topic names. The topic name appears once or several times depending on its probability. For example, a topic with probability 0.016671937 appears 6 times will be denoted as 0.016671937:6. Here is a simple example of integrating the topic distribution into its bag of words vector to obtain the resultant vector.</p>
            <p id="p-40"><i>tdm</i> =<i> tdm, 1….., tdm,2….., tdm, k</i>; where <i>tdm</i> = topic distribution of a single document</p>
            <p id="p-41"><i>di</i> =<i> dim,1 …. dim,2….. , dim,n</i>; where <i>di</i> = documents/reviews/tweets from dataset</p>
            <p id="p-42">Where each Topic distribution (<i>t</i><sup>dm</sup>, <i>k</i>) is computed as follows: <span class="disp-formula" id="eqn-1"><span class="article-label">(1)</span><math xmlns="http://www.w3.org/1998/Math/MathML" id="mml-eqn-1">
                        <mstyle displaystyle="true">
                           <msub>
                              <mrow>
                                 <mi>t</mi>
                              </mrow>
                              <mrow>
                                 <mi>d</mi>
                                 <mi>m</mi>
                              </mrow>
                           </msub>
                           <mi>k</mi>
                           <mo>=</mo>
                           <mfrac>
                              <mrow>
                                 <msubsup>
                                    <mrow>
                                       <mi>n</mi>
                                    </mrow>
                                    <mrow>
                                       <mi>m</mi>
                                    </mrow>
                                    <mrow>
                                       <mi>k</mi>
                                    </mrow>
                                 </msubsup>
                              </mrow>
                              <mrow>
                                 <munderover>
                                    <mrow>
                                       <mo mathsize="big" movablelimits="false"> ∑</mo>
                                    </mrow>
                                    <mrow>
                                       <mi>j</mi>
                                       <mo>=</mo>
                                       <mn>1</mn>
                                    </mrow>
                                    <mrow>
                                       <mi>k</mi>
                                    </mrow>
                                 </munderover>
                                 <msubsup>
                                    <mrow>
                                       <mi>n</mi>
                                    </mrow>
                                    <mrow>
                                       <mi>m</mi>
                                    </mrow>
                                    <mrow>
                                       <mi>j</mi>
                                    </mrow>
                                 </msubsup>
                              </mrow>
                           </mfrac>
                        </mstyle>
                     </math>
               </span>where</p>
            <p id="p-43"><span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" id="mml-ieqn-37">
                     <msubsup>
                        <mrow>
                           <mi>n</mi>
                        </mrow>
                        <mrow>
                           <mi>m</mi>
                        </mrow>
                        <mrow>
                           <mi>k</mi>
                        </mrow>
                     </msubsup>
                  </math></span> =number of words in documents assigned to topic (<i>k</i>),</p>
            <p id="p-44">and <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" id="mml-ieqn-40">
                     <msubsup>
                        <mrow>
                           <mi>n</mi>
                        </mrow>
                        <mrow>
                           <mi>m</mi>
                        </mrow>
                        <mrow>
                           <mi>j</mi>
                        </mrow>
                     </msubsup>
                  </math></span> = total no. of words in document (<i>m</i>),</p>
            <p id="p-45"><i>di</i>m = [confection, century, light, pillow, citrus, gelatin, nuts, case, filbert, , chewy, flavorful, yummy, brother, sister] and <i>td</i><sup>m</sup>: [0.18338655 (<i>td</i>1), 0.18334754 (<i>td</i>2), …., …., …., 0.016671937 (<i>tdn</i>) ,…..] . Applying discretization intervals</p>
            <p id="p-46"><i>t</i><sub><i>dm</i></sub> ∪ <i>td</i><sup>m</sup> = <i>rv</i></p>
            <p id="p-47">where <i>rv</i> (resultant vector to be used in classifier) = [[confection, century, light, pillow, citrus, gelatin, nuts, case, filbert, chewy, flavorful, yummy, brother, sister]], Topic1: Topic2: Topic3: Topic3: Topic4: Topic3: Topic3:Topic3: Topic8: Topic9: Topic10</p>
            <p id="p-48">We built multiple LDA with bigrams, trigrams, with different ranges of topics, and ultimately we estimated the best LDA model with the best hyper-parameters setting, and that yields better results when fed into supervised algorithms. The best one is 20 topics, with 100 iterations, and with bigrams. For this, we use the LDA get _document_topic function from Genism’s library (<a class="ext-link" href="https://radimrehurek.com/gensim/models/ldamodel.html" data-jats-ext-link-type="uri">https://radimrehurek.com/gensim/models/ldamodel.html</a>) on our topic distributions and get the topic distributions in the form of discretized probability values. Extracted LDA topics make the data more related, these are nothing but the probability distributions of words from documents, we built multiple topic models with various settings. We are more interested in seeing how the hidden topics’ semantic structure can be converted into and applied on a supervised algorithm and to see if it can improve the performance of supervised classification.</p>
         </section>
         <section class="sec">
            <h3 class="heading">Train classifiers</h3>
            <p id="p-49">We trained support vector machines classifiers and MaxEnt with stochastic gradient descent (sgd) optimization as it gives good results in terms of speed and performance. We have investigated that the Amazon review dataset has a disproportionate amount of classes, so on the Amazon dataset to handle the class imbalance we use the parameter class weight with value balanced. This will approximate under-sampling to correct for this. Besides this, all classifiers were applied with the same parameters. One thing to note here; while we were implementing these classifiers we noticed a modified Huber loss option in stochastic gradient implementation; the benefit of using this is that it avoids misclassification and it punishes you more on outliers as it brings tolerance to outliers as well as probability estimates. Therefore, we utilized this parameter to avoid misclassifications and punishing the outliers.</p>
         </section>
         <section class="sec">
            <h3 class="heading">Evaluation</h3>
            <p id="p-50">To verify our proposed framework we performed two classification tasks with two types of datasets, the first task was to check the sentiments of people from Amazon reviews, in short, classify the reviews into different categories of sentiments, the second task was classification of social media text into different categories of relatedness (on topic, off-topic, relevant, irrelevant) during natural crisis and disasters. Tweet texts are very short in comparison to reviews of Amazon datasets, each includes tweet id, tweet, tweet time and label. Amazon reviews are a bit longer. Each contains several sentences and also describes particular features of various products. Both datasets were sparse, short text, noisy, and hard enough to verify our framework.</p>
         </section>
         <section class="sec">
            <h3 class="heading">Evaluation measures</h3>
            <p id="p-51">Typically classification algorithms have the accuracy, F1 measure, Precision, and recall measures to measure the performance of the model. Accuracy is a measure to identify all correctly classified categories. Precision is a measure to identify positive from all predicted positive classes, while recall is a measure to correctly identify positive classes from actual positive classes, and F1 is a harmonic mean of precision and recall (<a class="xref xref-bibr" href="https://scholar.google.com/scholar_lookup?title=A%20novel%20approach%20for%20ontology-based%20feature%20vector%20generation%20for%20web%20text%20document%20classification&amp;author=Elhadad&amp;publication_year=2018" title="A novel approach for ontology-based feature vector generation for web text document classification" data-jats-ref-type="bibr" data-jats-rid="ref-9">Elhadad, Badran &amp; Salama, 2018</a>), (<a class="ext-link" href="https://medium.com/analytics-vidhya/accuracy-vs-f1-score-6258237beca2" data-jats-ext-link-type="uri">https://medium.com/analytics-vidhya/accuracy-vs-f1-score-6258237beca2</a>). So, to evaluate the performance of our proposed framework, we used the F1, Precision, and recall measure scores, because during preprocessing of our data we have investigated that our datasets have imbalanced classes, and F1 measure score is a suitable metric for imbalanced classes’ datasets. Besides F-measure, precision, and recall scores, we also intended to measure the statistical significance of our model, so we employed a k-fold cross validation (CV) test on our proposed model and as well on baseline approaches. We determine the classification accuracy of each fold on our datasets, and evaluate the average classification accuracy of our proposed framework and compared it with baseline approaches, to check the effectiveness of our model. The major advantage of k fold CV is that it takes every observation of data to have a chance of appearing in the training and testing set. The higher the mean performance of the model, the better the model is, therefore mean accuracies on k fold CV and average F1 score are dominantly used as evaluation measures.</p>
            <section class="sec">
               <h4 class="heading">Statistical Validity test</h4>
               <p id="p-52">In order to have statistical validity of our model and compare it with a baseline to observe any significant difference in performance, we ran a 5x2cv paired <i>t</i>-test on our dataset. Although there are many statistical tests, we applied this because it is a paired test, and in machine learning this means that the test data for the baseline and the trained model are the same, in our context, it is the same; we used the same Amazon and social media datasets for the baseline and proposed model. As its name implies this test typically split the dataset into two parts (training and testing) and repeat the splitting(50% training and 50% testing) five times, in each iteration (<a class="xref xref-bibr" href="https://doi.org/10.1162%2F089976698300017197" title="Approximate statistical tests for comparing supervised classification learning algorithms" data-jats-ref-type="bibr" data-jats-rid="ref-7">Dietterich, 1998</a>). In each of the five iterations, we fit A and B to the training split and evaluate their performance (<i>pAandpB</i>) on the test split. After this, it again rotates the test and train sets and computes performance again, which results in 2 performance difference measures: <span class="disp-formula" id="eqn-2"><span class="article-label">(2)</span><math xmlns="http://www.w3.org/1998/Math/MathML" id="mml-eqn-2">
                           <mstyle displaystyle="true">
                              <msup>
                                 <mrow>
                                    <mi>p</mi>
                                 </mrow>
                                 <mrow>
                                    <mn>1</mn>
                                 </mrow>
                              </msup>
                              <mo>=</mo>
                              <msubsup>
                                 <mrow>
                                    <mi>p</mi>
                                 </mrow>
                                 <mrow>
                                    <mi>A</mi>
                                 </mrow>
                                 <mrow>
                                    <mn>1</mn>
                                 </mrow>
                              </msubsup>
                              <mo>−</mo>
                              <msubsup>
                                 <mrow>
                                    <mi>p</mi>
                                 </mrow>
                                 <mrow>
                                    <mi>A</mi>
                                 </mrow>
                                 <mrow>
                                    <mn>1</mn>
                                 </mrow>
                              </msubsup>
                           </mstyle>
                        </math>
                  </span> 
                  <span class="disp-formula" id="eqn-3"><span class="article-label">(3)</span><math xmlns="http://www.w3.org/1998/Math/MathML" id="mml-eqn-3">
                           <mstyle displaystyle="true">
                              <msup>
                                 <mrow>
                                    <mi>p</mi>
                                 </mrow>
                                 <mrow>
                                    <mn>2</mn>
                                 </mrow>
                              </msup>
                              <mo>=</mo>
                              <msubsup>
                                 <mrow>
                                    <mi>p</mi>
                                 </mrow>
                                 <mrow>
                                    <mi>A</mi>
                                 </mrow>
                                 <mrow>
                                    <mn>2</mn>
                                 </mrow>
                              </msubsup>
                              <mo>−</mo>
                              <msubsup>
                                 <mrow>
                                    <mi>p</mi>
                                 </mrow>
                                 <mrow>
                                    <mi>A</mi>
                                 </mrow>
                                 <mrow>
                                    <mn>2</mn>
                                 </mrow>
                              </msubsup>
                           </mstyle>
                        </math>
                  </span>Then it estimates the estimate mean and variance of differences through following equations;</p>
               <p id="p-53">mean is: <span class="disp-formula" id="eqn-4"><span class="article-label">(4)</span><math xmlns="http://www.w3.org/1998/Math/MathML" id="mml-eqn-4">
                           <mstyle displaystyle="true">
                              <mover accent="false" class="mml-overline">
                                 <mrow>
                                    <mi>p</mi>
                                 </mrow>
                                 <mo accent="true">¯</mo>
                              </mover>
                              <mo>=</mo>
                              <mfrac>
                                 <mrow>
                                    <msup>
                                       <mrow>
                                          <mi>p</mi>
                                       </mrow>
                                       <mrow>
                                          <mn>1</mn>
                                       </mrow>
                                    </msup>
                                    <mo>+</mo>
                                    <msup>
                                       <mrow>
                                          <mi>p</mi>
                                       </mrow>
                                       <mrow>
                                          <mn>2</mn>
                                       </mrow>
                                    </msup>
                                 </mrow>
                                 <mrow>
                                    <mn>2</mn>
                                 </mrow>
                              </mfrac>
                           </mstyle>
                        </math>
                  </span>and variance is: <span class="disp-formula" id="eqn-5"><span class="article-label">(5)</span><math xmlns="http://www.w3.org/1998/Math/MathML" id="mml-eqn-5">
                           <mstyle displaystyle="true">
                              <msup>
                                 <mrow>
                                    <mi>s</mi>
                                 </mrow>
                                 <mrow>
                                    <mn>2</mn>
                                 </mrow>
                              </msup>
                              <mo>=</mo>
                              <msup>
                                 <mrow>
                                    <mrow><mfenced separators="" open="(" close=")"><msup>
                                          <mrow>
                                             <mi>p</mi>
                                          </mrow>
                                          <mrow>
                                             <mn>1</mn>
                                          </mrow>
                                       </msup>
                                       <mo>−</mo>
                                       <msup>
                                          <mrow>
                                             <mover accent="false" class="mml-overline">
                                                <mrow>
                                                   <mi>p</mi>
                                                </mrow>
                                                <mo accent="true">¯</mo>
                                             </mover>
                                          </mrow>
                                          <mrow>
                                             <mn>2</mn>
                                          </mrow>
                                       </msup></mfenced></mrow>
                                 </mrow>
                                 <mrow>
                                    <mn>2</mn>
                                 </mrow>
                              </msup>
                              <mo>+</mo>
                              <msup>
                                 <mrow>
                                    <mrow><mfenced separators="" open="(" close=")"><msup>
                                          <mrow>
                                             <mi>p</mi>
                                          </mrow>
                                          <mrow>
                                             <mn>2</mn>
                                          </mrow>
                                       </msup>
                                       <mo>−</mo>
                                       <msup>
                                          <mrow>
                                             <mover accent="false" class="mml-overline">
                                                <mrow>
                                                   <mi>p</mi>
                                                </mrow>
                                                <mo accent="true">¯</mo>
                                             </mover>
                                          </mrow>
                                          <mrow>
                                             <mn>2</mn>
                                          </mrow>
                                       </msup></mfenced></mrow>
                                 </mrow>
                                 <mrow>
                                    <mn>2</mn>
                                 </mrow>
                              </msup>
                           </mstyle>
                        </math>
                  </span>
               </p>
               <p id="p-54">The formula of computing <i>t</i>-test statistics for this test is as follows: <span class="disp-formula" id="eqn-6"><span class="article-label">(6)</span><math xmlns="http://www.w3.org/1998/Math/MathML" id="mml-eqn-6">
                           <mstyle displaystyle="true">
                              <mi>t</mi>
                              <mo>=</mo>
                              <mfrac>
                                 <mrow>
                                    <mi>p</mi>
                                    <msup>
                                       <mrow>
                                          <mn>1</mn>
                                       </mrow>
                                       <mrow>
                                          <mn>1</mn>
                                       </mrow>
                                    </msup>
                                 </mrow>
                                 <mrow>
                                    <msqrt>
                                       <mrow>
                                          <mn>1</mn>
                                          <mo>∕</mo>
                                          <mn>5</mn>
                                          <munderover>
                                             <mrow>
                                                <mo mathsize="big" movablelimits="false"> ∑</mo>
                                             </mrow>
                                             <mrow>
                                                <mi>i</mi>
                                                <mo>=</mo>
                                                <mn>1</mn>
                                             </mrow>
                                             <mrow>
                                                <mn>5</mn>
                                             </mrow>
                                          </munderover>
                                          <msubsup>
                                             <mrow>
                                                <mi>S</mi>
                                             </mrow>
                                             <mrow>
                                                <mi>i</mi>
                                             </mrow>
                                             <mrow>
                                                <mn>2</mn>
                                             </mrow>
                                          </msubsup>
                                       </mrow>
                                    </msqrt>
                                 </mrow>
                              </mfrac>
                           </mstyle>
                        </math>
                  </span>
               </p>
               <p id="p-55">where p1<sup>1</sup> is p1 from very first iteration. The t statistics assuming that it approximately follows as t distribution with 5 degrees of freedom, and our hypotheses statements and threshold values are;</p>
               <p id="p-56">H0 = Both the classifiers have same performance on this dataset.</p>
               <p id="p-57">H1 = Both classifiers does not have same performance on this dataset.</p>
               <p id="p-58">Our threshold significance level <b><i>α</i>=0.05</b> for rejecting the null hypothesis that both classifiers have same performance on this dataset. Under the null hypotheses, t-statistics value approximately follows a t-distribution with 5 degrees of freedom, so its value should remain in a given confidence interval which is <b>2.571</b> for <b>5%</b> threshold, and it indicates that both classifiers have equal performance, if t-statistics value greater than this value, we can reject the null hypotheses. You can implement the 5 by 2 fold cv paired <i>t</i>-test from scratch, but there is a package called MLxtend that implements this test and gives you t-values and <i>p</i>-values of two models (<a class="ext-link" href="http://rasbt.github.io/mlxtend/user_guide/evaluate/paired_ttest_5x2cv/" data-jats-ext-link-type="uri">http://rasbt.github.io/mlxtend/user_guide/evaluate/paired_ttest_5x2cv/</a>), in its parameters, we just gave the models names and scoring mode was mean accuracy.</p>
            </section>
         </section>
         <section class="sec">
            <h3 class="heading">Amazon reviews sentiment classification</h3>
            <p id="p-59">Sentiment analysis is a typical classification problem, used in various ways, some researchers apply sentiment analysis on reviews of movies (<a class="xref xref-bibr" href="https://doi.org/10.1016%2Fj.knosys.2019.105004" title="Dual memory network model for sentiment analysis of review text" data-jats-ref-type="bibr" data-jats-rid="ref-38">Shen et al., 2020</a>). Many deep learning and natural language processing techniques are proposed for sentiment analysis (<a class="xref xref-bibr" href="https://doi.org/10.1016%2Fj.icte.2020.07.003" title="An algorithm and method for sentiment analysis using the text and emoticon" data-jats-ref-type="bibr" data-jats-rid="ref-43">Ullah et al., 2020</a>). For sentiment classification in our article, we have considered a public dataset that we collected from the data repository Kaggle. The dataset description is already given in the dataset section, which is the collection of customer reviews of customers about Amazon products. The reviews are assigned into two categories positive and negative. 1/5 of the total reviews we used as test data and the remaining used as training data. We utilized retrieved bigrams, trigrams, and lemmatized text from the dataset and apply the LDA model with different parameters, and with 10, 15, and 20 topics. One thing is to be noted here is that we lemmatized the data and take only nouns, adjectives, and verbs to grab the actual meaning from reviews and apply the LDA model to actual contextual meaning of texts or reviews. After the lemmatization process, it remains with 378,123 reviews.</p>
            <section class="sec">
               <h4 class="heading">Result and analysis of Amazon dataset</h4>
               <p id="p-60">To examine our proposed models based on evaluation measures with different parameters settings, we examined the F1, precision, and recall scores of classifiers.</p>
               <p id="p-61">We randomly divided the data into 5-fold CV, we ran experiments by feeding different LDA topic distributions into the classifiers. The results are in the <a class="xref xref-fig" href="#fig-6" data-jats-ref-type="fig" data-jats-rid="fig-6">Figs. 6</a>, <a class="xref xref-fig" href="#fig-7" data-jats-ref-type="fig" data-jats-rid="fig-7">7</a> and <a class="xref xref-fig" href="#fig-8" data-jats-ref-type="fig" data-jats-rid="fig-8">8</a>, on <i>Y</i>-axis the LDA models with different parameters, and on <i>X</i>-axis it shows the classification results with each classification algorithms. The best performing algorithms (using bigrams and 20 topics) based on the precision scores are MaxEnt, SGD, and SVM. As seen in <a class="xref xref-fig" href="#fig-6" data-jats-ref-type="fig" data-jats-rid="fig-6">Fig. 6</a>, these two algorithms (with bigrams features and 20 topic distributions) are slightly better than the other algorithm. In <a class="xref xref-fig" href="#fig-7" data-jats-ref-type="fig" data-jats-rid="fig-7">Fig. 7</a>, a noise factor can be seen as MaxEnt and MaxEnt SGD underperformed in terms of recall scores. Then we can see, the model with bigrams and 20 topics achieved the highest F1, precision, and recall score of 91% with support vector machine classifier, while when we apply the trigrams into the LDA model, the MaxEnt classifier algorithm achieved the best result. It implies that the Amazon review dataset has large texts and when you lower the topics then it works well with trigrams and when you increase the topics it works well with bigrams.</p>
               <figure class="fig" itemprop="image" itemscope="itemscope" itemtype="https://schema.org/ImageObject" id="fig-6"><div class="image-container"><a href="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-6-2x.jpg" title="View the full image" class="fresco" data-fresco-caption="Figure 6: Comparison of the Amazon dataset f1 measure scores with different parameters." data-fresco-group="figure" data-fresco-options="fit: 'width', ui: 'outside', thumbnails: false, loop: true, position: true, overflow: true, preload: false"><img class="graphic" src="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-6-1x.jpg" itemprop="contentUrl" sizes="(min-width: 1200px) 581px, (max-width: 1199px) and (min-width: 980px) 462px, (max-width: 979px) and (min-width: 768px) 347px, (max-width: 767px) calc(100vw - 50px)" srcset="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-6-2x.jpg 1200w, https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-6-1x.jpg 600w, https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-6-small.jpg 355w" data-image-id="fig-6" alt="Comparison of the Amazon dataset f1 measure scores with different parameters." data-full="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-6-full.png" data-thumb="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-6-thumb.jpg" data-original="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-6.png" data-image-type="figure" data-jats-mimetype="image" data-jats-mime-subtype="png" width="600" height="383"></a></div>
<figcaption itemprop="description">
                     <h5 class="heading">
<span class="caption-label">Figure 6: </span>Comparison of the Amazon dataset f1 measure scores with different parameters.</h5>
                  <div class="figcaption-footer">
<div class="article-image-download"><a href="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-6-full.png" class="btn btn-mini" download="peerj-cs-677-fig-6.png" itemprop="url"><i class="icon-large icon-picture"> </i> Download full-size image</a></div>
<div class="object-id article-component-doi">DOI: <a href="https://doi.org/10.7717/peerjcs.677/fig-6" data-toggle="tooltip" title="Cite this object using this DOI">10.7717/peerjcs.677/fig-6</a>
</div>
</div></figcaption></figure>
               <figure class="fig" itemprop="image" itemscope="itemscope" itemtype="https://schema.org/ImageObject" id="fig-7"><div class="image-container"><a href="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-7-2x.jpg" title="View the full image" class="fresco" data-fresco-caption="Figure 7: Comparison of the Amazon dataset precision scores with different parameters." data-fresco-group="figure" data-fresco-options="fit: 'width', ui: 'outside', thumbnails: false, loop: true, position: true, overflow: true, preload: false"><img class="graphic" src="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-7-1x.jpg" itemprop="contentUrl" sizes="(min-width: 1200px) 581px, (max-width: 1199px) and (min-width: 980px) 462px, (max-width: 979px) and (min-width: 768px) 347px, (max-width: 767px) calc(100vw - 50px)" srcset="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-7-2x.jpg 1200w, https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-7-1x.jpg 600w, https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-7-small.jpg 355w" data-image-id="fig-7" alt="Comparison of the Amazon dataset precision scores with different parameters." data-full="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-7-full.png" data-thumb="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-7-thumb.jpg" data-original="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-7.png" data-image-type="figure" data-jats-mimetype="image" data-jats-mime-subtype="png" width="600" height="385"></a></div>
<figcaption itemprop="description">
                     <h5 class="heading">
<span class="caption-label">Figure 7: </span>Comparison of the Amazon dataset precision scores with different parameters.</h5>
                  <div class="figcaption-footer">
<div class="article-image-download"><a href="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-7-full.png" class="btn btn-mini" download="peerj-cs-677-fig-7.png" itemprop="url"><i class="icon-large icon-picture"> </i> Download full-size image</a></div>
<div class="object-id article-component-doi">DOI: <a href="https://doi.org/10.7717/peerjcs.677/fig-7" data-toggle="tooltip" title="Cite this object using this DOI">10.7717/peerjcs.677/fig-7</a>
</div>
</div></figcaption></figure>
               <figure class="fig" itemprop="image" itemscope="itemscope" itemtype="https://schema.org/ImageObject" id="fig-8"><div class="image-container"><a href="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-8-2x.jpg" title="View the full image" class="fresco" data-fresco-caption="Figure 8: Comparison of the Amazon dataset recall scores with different parameters." data-fresco-group="figure" data-fresco-options="fit: 'width', ui: 'outside', thumbnails: false, loop: true, position: true, overflow: true, preload: false"><img class="graphic" src="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-8-1x.jpg" itemprop="contentUrl" sizes="(min-width: 1200px) 581px, (max-width: 1199px) and (min-width: 980px) 462px, (max-width: 979px) and (min-width: 768px) 347px, (max-width: 767px) calc(100vw - 50px)" srcset="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-8-2x.jpg 1200w, https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-8-1x.jpg 600w, https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-8-small.jpg 355w" data-image-id="fig-8" alt="Comparison of the Amazon dataset recall scores with different parameters." data-full="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-8-full.png" data-thumb="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-8-thumb.jpg" data-original="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-8.png" data-image-type="figure" data-jats-mimetype="image" data-jats-mime-subtype="png" width="600" height="387"></a></div>
<figcaption itemprop="description">
                     <h5 class="heading">
<span class="caption-label">Figure 8: </span>Comparison of the Amazon dataset recall scores with different parameters.</h5>
                  <div class="figcaption-footer">
<div class="article-image-download"><a href="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-8-full.png" class="btn btn-mini" download="peerj-cs-677-fig-8.png" itemprop="url"><i class="icon-large icon-picture"> </i> Download full-size image</a></div>
<div class="object-id article-component-doi">DOI: <a href="https://doi.org/10.7717/peerjcs.677/fig-8" data-toggle="tooltip" title="Cite this object using this DOI">10.7717/peerjcs.677/fig-8</a>
</div>
</div></figcaption></figure>
            </section>
            <section class="sec">
               <h4 class="heading">Comparison with baseline approaches Amazon dataset</h4>
               <p id="p-62">Below in the <a class="xref xref-table" href="#table-3" data-jats-ref-type="table" data-jats-rid="table-3">Table 3</a> we provided the result without the LDA model, we compare the result with baseline approaches by classifying the data without leveraging the topic distributions. We have implemented the most commonly used TFIDF feature vectors with different classifiers on our Amazon review dataset as a baseline. When we apply the classifiers with TFIDF feature vector representations then F1 scores decrease about 9% and 17% with support vector machine and Multinomial Naive Bayes classifiers respectively as compared to T2F with support vector machine. This means that topic distributions give better results because it semantically capture the words within the documents and their distributions, so that classification performance would be increased, and our proposed framework able to achieve the higher classification results than the baseline approaches. While TFIDF has been popular in its regard, there remains a void where understanding the context of the word was concerned, this is where word embedding techniques such as doc2vec can be utilized, <a class="xref xref-bibr" href="https://scholar.google.com/scholar_lookup?title=Distributed%20representations%20of%20sentences%20and%20documents&amp;author=Le&amp;publication_year=2014" title="Distributed representations of sentences and documents" data-jats-ref-type="bibr" data-jats-rid="ref-21">Le &amp; Mikolov (2014)</a>. Therefore, we implemented doc2vec with logistic regression classifier as one of our baseline approaches to analyze if it increases performance, the f1 score reaches 86% as compared to the TFIDF approach with SVM classifier which was 82%, but still lower than the F1 score of 91% which we achieved by applying LDA topic distributions as feature vectors.</p>
               <figure class="table-wrap" id="table-3"><div class="caption">
<span class="caption-label">Table 3: </span>
                     <div class="title">Amazon Dataset F1, Precision,Recall and Average accuracy statistics: comparison with baseline approaches evaluation measures results.</div>
                  </div>
                  
                  <div class="table-container"><table class="table table-bordered table-condensed table-hover">
                        <colgroup>
                           <col>
                           <col>
                           <col>
                           <col>
                           <col>
                        </colgroup>
                        <thead>
                           <tr>
                              <th><b>Algorithms</b></th>
                              <th><b>F1 score</b></th>
                              <th><b>Precision</b></th>
                              <th><b>Recall</b></th>
                              <th><b> Mean Accuracy</b></th>
                           </tr>
                        </thead>
                        <tbody>
                           <tr>
                              <td>SVM (TFIDF)</td>
                              <td>82%</td>
                              <td><b>83%</b></td>
                              <td>80%</td>
                              <td>74%</td>
                           </tr>
                           <tr>
                              <td>Multinomial Naive Bayes(TFIDF)</td>
                              <td>74%</td>
                              <td>76%</td>
                              <td>75%</td>
                              <td>71%</td>
                           </tr>
                           <tr>
                              <td>MaxEnt (TFIDF)</td>
                              <td>71%</td>
                              <td>72%</td>
                              <td>68%</td>
                              <td>73%</td>
                           </tr>
                           <tr>
                              <td>MaxEnt (doc2vec)</td>
                              <td><b>86%</b></td>
                              <td>77%</td>
                              <td>90%</td>
                              <td>79%</td>
                           </tr>
                           <tr>
                              <td>MaxEnt Sgd (proposed T2F)</td>
                              <td>88%</td>
                              <td><b>91%</b></td>
                              <td>88%</td>
                              <td><b>81%</b></td>
                           </tr>
                           <tr>
                              <td>MaxEnt (proposed T2F)</td>
                              <td>77%</td>
                              <td>83%</td>
                              <td>77%</td>
                              <td>73%</td>
                           </tr>
                           <tr>
                              <td>SVM (proposed T2F)</td>
                              <td><b>91%</b></td>
                              <td>87%</td>
                              <td><b>91%</b></td>
                              <td>77%</td>
                           </tr>
                        </tbody>
                     </table></div>
<div class="object-id article-component-doi">DOI: <a href="https://doi.org/10.7717/peerjcs.677/table-3" data-toggle="tooltip" title="Cite this object using this DOI">10.7717/peerjcs.677/table-3</a>
</div>
               </figure>
               <p id="p-63">To examine the classification accuracy and compared it with baseline approaches, we performed 5-fold CV in which we reserved 1/4 observations as the validation set and 4/5 as training observations the advantage of leveraging 5 fold CV is it uses every sample of the dataset in training and testing in iterations. We ran 5-fold CV experiments on the baseline approaches to measure the classification accuracy and also on the proposed model. The detailed accuracy is also shown in <a class="xref xref-table" href="#table-3" data-jats-ref-type="table" data-jats-rid="table-3">Table 3</a>. The comparison of accuracy shown in <a class="xref xref-fig" href="#fig-9" data-jats-ref-type="fig" data-jats-rid="fig-9">Fig. 9</a>, starting from fold 1 our approach performs less than the baseline, but after fold 1 it performs better on each fold than the applied baseline and overall average classification accuracy is also higher, the last two columns show the average classification accuracy which improved from 79.3% to 81%, i.e., classification error reduces from 20.7% to 19%. This means that within the dataset with a certain degree of words shared among the documents our framework is capable to reduce the classification error and increase the classification mean accuracy.</p>
               <figure class="fig" itemprop="image" itemscope="itemscope" itemtype="https://schema.org/ImageObject" id="fig-9"><div class="image-container"><a href="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-9-2x.jpg" title="View the full image" class="fresco" data-fresco-caption="Figure 9: Classification accuracy comparison between baseline and proposed approach on the Amazon dataset." data-fresco-group="figure" data-fresco-options="fit: 'width', ui: 'outside', thumbnails: false, loop: true, position: true, overflow: true, preload: false"><img class="graphic" src="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-9-1x.jpg" itemprop="contentUrl" sizes="(min-width: 1200px) 581px, (max-width: 1199px) and (min-width: 980px) 462px, (max-width: 979px) and (min-width: 768px) 347px, (max-width: 767px) calc(100vw - 50px)" srcset="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-9-2x.jpg 1200w, https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-9-1x.jpg 600w, https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-9-small.jpg 355w" data-image-id="fig-9" alt="Classification accuracy comparison between baseline and proposed approach on the Amazon dataset." data-full="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-9-full.png" data-thumb="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-9-thumb.jpg" data-original="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-9.png" data-image-type="figure" data-jats-mimetype="image" data-jats-mime-subtype="png" width="600" height="389"></a></div>
<figcaption itemprop="description">
                     <h5 class="heading">
<span class="caption-label">Figure 9: </span>Classification accuracy comparison between baseline and proposed approach on the Amazon dataset.</h5>
                     <span class="p">The 5-fold CV scores of best performing classifier of baseline and best performing classifier of proposed are shown, demonstrating each fold results of classifiers and comparing those classifiers who achieved highest classification average accuracy.</span>
                  <div class="figcaption-footer">
<div class="article-image-download"><a href="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-9-full.png" class="btn btn-mini" download="peerj-cs-677-fig-9.png" itemprop="url"><i class="icon-large icon-picture"> </i> Download full-size image</a></div>
<div class="object-id article-component-doi">DOI: <a href="https://doi.org/10.7717/peerjcs.677/fig-9" data-toggle="tooltip" title="Cite this object using this DOI">10.7717/peerjcs.677/fig-9</a>
</div>
</div></figcaption></figure>
               <p id="p-65">To compare the proposed model with the applied baselines approaches and check which approach has more statistical significance on the same Amazon dataset, we ran the 5 X 2 CV paired test on models, and compare the applied baselines with the proposed MaxEnt sgd model, we compared MaxEnt sgd because, if we see the <a class="xref xref-table" href="#table-3" data-jats-ref-type="table" data-jats-rid="table-3">Table 3</a>, the mean accuracy of MaxEnt sgd is higher than other proposed models. We computed the 5X2 CV paired t-test’s <i>t</i>-value and <i>p</i>-value of models, then compare it in the following table. We computed every fold(2 folds) of each iteration(5 iterations) and listed the mean results in the table. You can see in the <a class="xref xref-table" href="#table-4" data-jats-ref-type="table" data-jats-rid="table-4">Table 4</a>, proposed MaxEnt sgd comparison with every baseline model has <i>p</i>-value less than the threshold value <i>α</i> = 0.05, and also t-statistics value is greater than the threshold value, thus we can reject the null hypotheses and accept that two models have significantly different performance, and T2F with MaxEnt sgd with better mean accuracy has performed significantly better than the applied baselines.</p>
               <figure class="table-wrap" id="table-4"><div class="caption">
<span class="caption-label">Table 4: </span>
                     <div class="title">Comparison of each baseline model with the Proposed MaxEnt sgd(T2F) on the same Amazon dataset, and the <i>t</i>-value and <i>p</i>-value scores are listed.</div>
                  </div>
                  
                  <div class="table-container"><table class="table table-bordered table-condensed table-hover">
                        <colgroup>
                           <col>
                           <col>
                           <col>
                        </colgroup>
                        <thead>
                           <tr>
                              <th></th>
                              <th><b>MaxEnt sgd(T2F)</b></th>
                              <th><b>MaxEnt sgd(T2F)</b></th>
                           </tr>
                           <tr>
                              <th><b>Algorithms</b></th>
                              <th><b>t-statictics value</b></th>
                              <th>
<i>p</i>-value</th>
                           </tr>
                        </thead>
                        <tbody>
                           <tr>
                              <td>SVM (TFIDF)</td>
                              <td>3.248</td>
                              <td>0.0437</td>
                           </tr>
                           <tr>
                              <td>Multinomial Naive Bayes(TFIDF)</td>
                              <td>4.784</td>
                              <td>0.0079</td>
                           </tr>
                           <tr>
                              <td>MaxEnt (TFIDF)</td>
                              <td>4.562</td>
                              <td>0.0060</td>
                           </tr>
                           <tr>
                              <td>MaxEnt (doc2vec)</td>
                              <td>2.932</td>
                              <td>0.0362</td>
                           </tr>
                        </tbody>
                     </table></div>
<div class="object-id article-component-doi">DOI: <a href="https://doi.org/10.7717/peerjcs.677/table-4" data-toggle="tooltip" title="Cite this object using this DOI">10.7717/peerjcs.677/table-4</a>
</div>
               </figure>
            </section>
         </section>
         <section class="sec">
            <h3 class="heading">Social media data classification</h3>
            <p id="p-66">To find out how our method works well with another kind of data and in different domains, we leveraged the social media datasets from the domain of disasters. We performed experiments with tweet classification with the categories of on the topic, and off-topic, support government, criticize the government. For the sake of simplicity, we take off-topic and on-topic categories. On-topic means tweet is related to and within the context of a specific disaster, similarly, off-topic means tweet text is not about the disaster. There are numerous applications of classification in the context of natural disasters or pandemics such as classify the situational information from Twitter in pandemics (<a class="xref xref-bibr" href="https://doi.org/10.1109%2FTCSS.2020.2980007" title="Characterizing the propagation of situational information in social media during covid-19 epidemic: a case study on weibo" data-jats-ref-type="bibr" data-jats-rid="ref-22">Li et al., 2020</a>). Some researchers utilized the topic modeling techniques and analyze the topics during disasters by leveraging Twitter data (<a class="xref xref-bibr" href="https://doi.org/10.1177%2F0165551519828620" title="Twitter speaks: a case of national disaster situational awareness" data-jats-ref-type="bibr" data-jats-rid="ref-15">Karami et al., 2020</a>). As social media is one of the main and user-oriented text data sources therefore we have utilized the social media datasets to check the efficiency of our framework. After the pre-processing steps, we remain with 61,220 tweets.</p>
            <section class="sec">
               <h4 class="heading">Result and analysis of Social media disaster dataset</h4>
               <p id="p-67">As in the Amazon dataset, we ran the same LDA models on the social media datasets, and investigate the F1, precision, and recall scores, social media data is more difficult to classify, as it has more slang words, therefore we can see in <a class="xref xref-fig" href="#fig-10" data-jats-ref-type="fig" data-jats-rid="fig-10">Fig. 10</a>, the false positive and false negative (recall) is higher than the precision with support vector machine algorithm, in <a class="xref xref-fig" href="#fig-11" data-jats-ref-type="fig" data-jats-rid="fig-11">Fig. 11</a> in precision scores we can investigate rather than with the 20 topics it relatively gives better result with 15 topics and 10 topics with MaxEnt and MaxEnt sgd classifiers.</p>
               <figure class="fig" itemprop="image" itemscope="itemscope" itemtype="https://schema.org/ImageObject" id="fig-10"><div class="image-container"><a href="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-10-2x.jpg" title="View the full image" class="fresco" data-fresco-caption="Figure 10: Comparison of recall scores of the social media dataset with different parameters." data-fresco-group="figure" data-fresco-options="fit: 'width', ui: 'outside', thumbnails: false, loop: true, position: true, overflow: true, preload: false"><img class="graphic" src="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-10-1x.jpg" itemprop="contentUrl" sizes="(min-width: 1200px) 581px, (max-width: 1199px) and (min-width: 980px) 462px, (max-width: 979px) and (min-width: 768px) 347px, (max-width: 767px) calc(100vw - 50px)" srcset="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-10-2x.jpg 1200w, https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-10-1x.jpg 600w, https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-10-small.jpg 355w" data-image-id="fig-10" alt="Comparison of recall scores of the social media dataset with different parameters." data-full="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-10-full.png" data-thumb="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-10-thumb.jpg" data-original="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-10.png" data-image-type="figure" data-jats-mimetype="image" data-jats-mime-subtype="png" width="600" height="387"></a></div>
<figcaption itemprop="description">
                     <h5 class="heading">
<span class="caption-label">Figure 10: </span>Comparison of recall scores of the social media dataset with different parameters.</h5>
                  <div class="figcaption-footer">
<div class="article-image-download"><a href="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-10-full.png" class="btn btn-mini" download="peerj-cs-677-fig-10.png" itemprop="url"><i class="icon-large icon-picture"> </i> Download full-size image</a></div>
<div class="object-id article-component-doi">DOI: <a href="https://doi.org/10.7717/peerjcs.677/fig-10" data-toggle="tooltip" title="Cite this object using this DOI">10.7717/peerjcs.677/fig-10</a>
</div>
</div></figcaption></figure>
               <figure class="fig" itemprop="image" itemscope="itemscope" itemtype="https://schema.org/ImageObject" id="fig-11"><div class="image-container"><a href="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-11-2x.jpg" title="View the full image" class="fresco" data-fresco-caption="Figure 11: Comparison of precision scores of the social media dataset with different parameters." data-fresco-group="figure" data-fresco-options="fit: 'width', ui: 'outside', thumbnails: false, loop: true, position: true, overflow: true, preload: false"><img class="graphic" src="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-11-1x.jpg" itemprop="contentUrl" sizes="(min-width: 1200px) 581px, (max-width: 1199px) and (min-width: 980px) 462px, (max-width: 979px) and (min-width: 768px) 347px, (max-width: 767px) calc(100vw - 50px)" srcset="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-11-2x.jpg 1200w, https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-11-1x.jpg 600w, https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-11-small.jpg 355w" data-image-id="fig-11" alt="Comparison of precision scores of the social media dataset with different parameters." data-full="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-11-full.png" data-thumb="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-11-thumb.jpg" data-original="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-11.png" data-image-type="figure" data-jats-mimetype="image" data-jats-mime-subtype="png" width="600" height="388"></a></div>
<figcaption itemprop="description">
                     <h5 class="heading">
<span class="caption-label">Figure 11: </span>Comparison of precision scores of the social media dataset with different parameters.</h5>
                  <div class="figcaption-footer">
<div class="article-image-download"><a href="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-11-full.png" class="btn btn-mini" download="peerj-cs-677-fig-11.png" itemprop="url"><i class="icon-large icon-picture"> </i> Download full-size image</a></div>
<div class="object-id article-component-doi">DOI: <a href="https://doi.org/10.7717/peerjcs.677/fig-11" data-toggle="tooltip" title="Cite this object using this DOI">10.7717/peerjcs.677/fig-11</a>
</div>
</div></figcaption></figure>
               <p id="p-68">With both bigrams and trigrams setting and 10 and 15 topics, it performs best with the MaxEnt sgd classifier giving up to 78% F1 score as shown in <a class="xref xref-fig" href="#fig-12" data-jats-ref-type="fig" data-jats-rid="fig-12">Fig. 12</a>, it may be because MaxEnt sgd classifier can well handle the noisy short and sparse type of data (<a class="xref xref-bibr" href="https://scholar.google.com/scholar_lookup?title=Twitter%20sentiment%20classification%20using%20distant%20supervision&amp;author=Go&amp;publication_year=2009" title="Twitter sentiment classification using distant supervision" data-jats-ref-type="bibr" data-jats-rid="ref-12">Go, Bhayani &amp; Huang, 2009</a>) thus having a higher coverage, and social media is the same kind of noisy unstructured text data. Also in a two-class scenario, it works well because of the binary nature of the target class and we have target class is binary in the social media dataset. Interestingly support vector machines outperformed others algorithms in terms of recall that implies that support vector machines can also somehow, if not at all, handle the noisy data of social media. The social media dataset was short and noisy such as it contains slang, etc. Therefore, it can be seen that the highest F1 score with any parameter setting reached up to 78% as compared to 91% with the Amazon dataset. But that is also satisfactory in the context of the social media data with unsupervised topic modeling. As compared to the Amazon dataset’s large texts, the social media dataset gives more satisfaction with fewer topics, this is because of the length of tweets, which implies that the LDA topic model with less topic setting gives more good results than the LDA topic model with more topics.</p>
               <figure class="fig" itemprop="image" itemscope="itemscope" itemtype="https://schema.org/ImageObject" id="fig-12"><div class="image-container"><a href="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-12-2x.jpg" title="View the full image" class="fresco" data-fresco-caption="Figure 12: Comparison of F1 scores of social media dataset with different parameters." data-fresco-group="figure" data-fresco-options="fit: 'width', ui: 'outside', thumbnails: false, loop: true, position: true, overflow: true, preload: false"><img class="graphic" src="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-12-1x.jpg" itemprop="contentUrl" sizes="(min-width: 1200px) 581px, (max-width: 1199px) and (min-width: 980px) 462px, (max-width: 979px) and (min-width: 768px) 347px, (max-width: 767px) calc(100vw - 50px)" srcset="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-12-2x.jpg 1200w, https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-12-1x.jpg 600w, https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-12-small.jpg 355w" data-image-id="fig-12" alt="Comparison of F1 scores of social media dataset with different parameters." data-full="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-12-full.png" data-thumb="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-12-thumb.jpg" data-original="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-12.png" data-image-type="figure" data-jats-mimetype="image" data-jats-mime-subtype="png" width="600" height="385"></a></div>
<figcaption itemprop="description">
                     <h5 class="heading">
<span class="caption-label">Figure 12: </span>Comparison of F1 scores of social media dataset with different parameters.</h5>
                  <div class="figcaption-footer">
<div class="article-image-download"><a href="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-12-full.png" class="btn btn-mini" download="peerj-cs-677-fig-12.png" itemprop="url"><i class="icon-large icon-picture"> </i> Download full-size image</a></div>
<div class="object-id article-component-doi">DOI: <a href="https://doi.org/10.7717/peerjcs.677/fig-12" data-toggle="tooltip" title="Cite this object using this DOI">10.7717/peerjcs.677/fig-12</a>
</div>
</div></figcaption></figure>
            </section>
            <section class="sec">
               <h4 class="heading">Comparison with baseline approaches on social media dataset</h4>
               <p id="p-69">In comparison with the baseline approaches that we implemented with different types of word embedding techniques such as TFIDF and doc2vec when applying on social media dataset, it reaches up to 75% high in terms of F1 score with doc2vec embeddings on logistic regression classifier, but still less than the overall highest 78% F1 score with topic distributions as feature vectors, which shows how topic distributions accurately capture the contextual meaning and classify he data accurately. However, an interesting aspect is to analyze that F1, precision, and recall score increases while implementing doc2vec embeddings which indicates among the baseline approaches doc2vec performs best.</p>
               <p id="p-70">As we had run experiments on Amazon datasets same we run 5 fold CV on social media dataset to determine the classification significance by comparing the mean accuracy, although the classification means accuracy drops as compared to when applying on Amazon dataset, still it gives 73% mean accuracy with proposed T2F approach on MaxEnt sgd classifier, when it compared to baseline approaches it falls to 69% with doc2vec feature on MaxEnt classifier, which is highest among the baseline approaches only, but still lower than the proposed T2F approach. The mean accuracy of each fold comparison of highest baseline and highest proposed given in <a class="xref xref-fig" href="#fig-13" data-jats-ref-type="fig" data-jats-rid="fig-13">Fig. 13</a>, it starts from fold 1 to fold 5 then, in the end, last two bars showing the mean accuracy which depicts how the classifiers feed with the topic distribution features classified the data significantly better than the baseline approaches and also even better than the mostly used NLP deep learning baseline approach doc2vec.</p>
               <figure class="fig" itemprop="image" itemscope="itemscope" itemtype="https://schema.org/ImageObject" id="fig-13"><div class="image-container"><a href="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-13-2x.jpg" title="View the full image" class="fresco" data-fresco-caption="Figure 13: Classification accuracy comparison between baseline and proposed approach on social media dataset." data-fresco-group="figure" data-fresco-options="fit: 'width', ui: 'outside', thumbnails: false, loop: true, position: true, overflow: true, preload: false"><img class="graphic" src="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-13-1x.jpg" itemprop="contentUrl" sizes="(min-width: 1200px) 581px, (max-width: 1199px) and (min-width: 980px) 462px, (max-width: 979px) and (min-width: 768px) 347px, (max-width: 767px) calc(100vw - 50px)" srcset="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-13-2x.jpg 1200w, https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-13-1x.jpg 600w, https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-13-small.jpg 355w" data-image-id="fig-13" alt="Classification accuracy comparison between baseline and proposed approach on social media dataset." data-full="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-13-full.png" data-thumb="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-13-thumb.jpg" data-original="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-13.png" data-image-type="figure" data-jats-mimetype="image" data-jats-mime-subtype="png" width="600" height="389"></a></div>
<figcaption itemprop="description">
                     <h5 class="heading">
<span class="caption-label">Figure 13: </span>Classification accuracy comparison between baseline and proposed approach on social media dataset.</h5>
                     <span class="p">The five fold CV scores of the best performing classifier of baseline and best performing classifier of the proposed model are shown, demonstrating each fold results of classifiers and comparing those classifiers who achieved highest classification average accuracy.</span>
                  <div class="figcaption-footer">
<div class="article-image-download"><a href="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-13-full.png" class="btn btn-mini" download="peerj-cs-677-fig-13.png" itemprop="url"><i class="icon-large icon-picture"> </i> Download full-size image</a></div>
<div class="object-id article-component-doi">DOI: <a href="https://doi.org/10.7717/peerjcs.677/fig-13" data-toggle="tooltip" title="Cite this object using this DOI">10.7717/peerjcs.677/fig-13</a>
</div>
</div></figcaption></figure>
               <p id="p-72">In order to compare the proposed model with the applied baselines approaches and check which approach has more statistical significance on the same social media dataset, we ran the 5X2 CV paired test on models, and compared the applied baselines with the proposed MaxEnt sgd model; we also compared MaxEnt sgd because also on the social media dataset (see <a class="xref xref-table" href="#table-5" data-jats-ref-type="table" data-jats-rid="table-5">Table 5</a>), the mean accuracy of MaxEnt sgd is higher among the proposed models. We computed the 5X2 cv paired t-test’s <i>t</i>-value and <i>p</i>-value of models, then compare it in the following table. We computed every fold (two folds) of each iteration (five iterations) and listed the mean results in the table. As shown in <a class="xref xref-table" href="#table-6" data-jats-ref-type="table" data-jats-rid="table-6">Table 6</a>, the proposed MaxEnt sgd comparison with every baseline model has <i>p</i>-value less than the threshold value which is <i>α</i> = 0.05, and also t-statistics value is greater than the threshold value, thus we can reject the null hypotheses and accept that two models have significantly different performance, and proposed MaxEnt sgd(T2F) with better mean accuracy has performed significantly better than the applied baselines.</p>
               <figure class="table-wrap" id="table-5"><div class="caption">
<span class="caption-label">Table 5: </span>
                     <div class="title">Social media dataset F1, Precision, Recall and Average accuracy statistics: comparison with baseline approaches evaluation measures.</div>
                  </div>
                  
                  <div class="table-container"><table class="table table-bordered table-condensed table-hover">
                        <colgroup>
                           <col>
                           <col>
                           <col>
                           <col>
                           <col>
                        </colgroup>
                        <thead>
                           <tr>
                              <th><b>Algorithms</b></th>
                              <th><b>F1 score</b></th>
                              <th><b>Precision</b></th>
                              <th><b>Recall</b></th>
                              <th><b>Mean Accuracy</b></th>
                           </tr>
                        </thead>
                        <tbody>
                           <tr>
                              <td>SVM (TFIDF)</td>
                              <td>68%</td>
                              <td>71%</td>
                              <td>70%</td>
                              <td>67%</td>
                           </tr>
                           <tr>
                              <td>Multinomial Naive Bayes (TFIDF)</td>
                              <td>73%</td>
                              <td>76%</td>
                              <td>74%</td>
                              <td>68%</td>
                           </tr>
                           <tr>
                              <td>MaxEnt (TFIDF)</td>
                              <td>52%</td>
                              <td>60%</td>
                              <td>54%</td>
                              <td>65%</td>
                           </tr>
                           <tr>
                              <td>MaxEnt (doc2vec)</td>
                              <td>77%</td>
                              <td>75%</td>
                              <td>74%</td>
                              <td>69%</td>
                           </tr>
                           <tr>
                              <td>MaxEnt Sgd (proposed T2F)</td>
                              <td><b>78%</b></td>
                              <td>76%</td>
                              <td>76%</td>
                              <td><b>73%</b></td>
                           </tr>
                           <tr>
                              <td>MaxEnt (proposed T2F)</td>
                              <td>77%</td>
                              <td><b>76%</b></td>
                              <td>76%</td>
                              <td>69%</td>
                           </tr>
                           <tr>
                              <td>SVM (proposed T2F)</td>
                              <td>70%</td>
                              <td>65%</td>
                              <td><b>77%</b></td>
                              <td>68%</td>
                           </tr>
                        </tbody>
                     </table></div>
<div class="object-id article-component-doi">DOI: <a href="https://doi.org/10.7717/peerjcs.677/table-5" data-toggle="tooltip" title="Cite this object using this DOI">10.7717/peerjcs.677/table-5</a>
</div>
               </figure>
               <figure class="table-wrap" id="table-6"><div class="caption">
<span class="caption-label">Table 6: </span>
                     <div class="title">Comparison of each baseline model with the proposed MaxEnt sgd (T2F) model on same social media dataset, and the <i>t</i>-value and <i>p</i>-value scores are listed.</div>
                  </div>
                  
                  <div class="table-container"><table class="table table-bordered table-condensed table-hover">
                        <colgroup>
                           <col>
                           <col>
                           <col>
                        </colgroup>
                        <thead>
                           <tr>
                              <th></th>
                              <th><b>MaxEnt sgd(T2F)</b></th>
                              <th><b>MaxEnt sgd(T2F)</b></th>
                           </tr>
                           <tr>
                              <th><b>Algorithms</b></th>
                              <th><b>t-statictics value</b></th>
                              <th>
<i>p</i>-value</th>
                           </tr>
                        </thead>
                        <tbody>
                           <tr>
                              <td>SVM (TFIDF)</td>
                              <td>3.257</td>
                              <td>0.0083</td>
                           </tr>
                           <tr>
                              <td>Multinomial Naive Bayes (TFIDF)</td>
                              <td>3.127</td>
                              <td>0.0024</td>
                           </tr>
                           <tr>
                              <td>MaxEnt (TFIDF)</td>
                              <td>4.273</td>
                              <td>0.0071</td>
                           </tr>
                           <tr>
                              <td>MaxEnt (doc2vec)</td>
                              <td>3.101</td>
                              <td>0.0271</td>
                           </tr>
                        </tbody>
                     </table></div>
<div class="object-id article-component-doi">DOI: <a href="https://doi.org/10.7717/peerjcs.677/table-6" data-toggle="tooltip" title="Cite this object using this DOI">10.7717/peerjcs.677/table-6</a>
</div>
               </figure>
            </section>
         </section>
         <section class="sec">
            <h3 class="heading">Result and analysis of unseen data</h3>
            <p id="p-73">To further investigate the efficiency of our framework we validate the LDA model on completely unseen data, for this, we chose the Amazon dataset that has data of reviews on yearly basis, we prepared the LDA model of 2011 data and use the same model to get feature topic distributions for 2012 data, it is to be noted that LDA model did not see this 2012 data, it is completely unseen for the trained LDA model. We get the test vectors for 2012 data and re-run the classifiers, results are reasonably well, as you can see in <a class="xref xref-fig" href="#fig-14" data-jats-ref-type="fig" data-jats-rid="fig-14">Fig. 14</a>, it gives 87% F1 score, 87% precision score with support vector machine classifier, and 79% F1 score with MaxEnt classifier and 81% F1 score with MaxEnt sgd classifier. The 5-fold CV test was also applied to this data and in classification accuracy, the SVM classifier gives the best classification performance with 83% mean accuracy. Also each fold unseen data test results shown in <a class="xref xref-fig" href="#fig-15" data-jats-ref-type="fig" data-jats-rid="fig-15">Fig. 15</a> with all three classifiers. This also implies even if the model did not see the data, it classified it with good classification accuracy and F1 scores. Results indicate that this framework also works well with unseen data of the same context. We did the validity tests through 5-fold CV and through Mcnemar’s test by using the model trained on 2011 data and test it on 2012 unseen data.</p>
            <figure class="fig" itemprop="image" itemscope="itemscope" itemtype="https://schema.org/ImageObject" id="fig-14"><div class="image-container"><a href="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-14-2x.jpg" title="View the full image" class="fresco" data-fresco-caption="Figure 14: Comparative results of evaluation measures statistics on unseen data." data-fresco-group="figure" data-fresco-options="fit: 'width', ui: 'outside', thumbnails: false, loop: true, position: true, overflow: true, preload: false"><img class="graphic" src="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-14-1x.jpg" itemprop="contentUrl" sizes="(min-width: 1200px) 581px, (max-width: 1199px) and (min-width: 980px) 462px, (max-width: 979px) and (min-width: 768px) 347px, (max-width: 767px) calc(100vw - 50px)" srcset="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-14-2x.jpg 1200w, https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-14-1x.jpg 600w, https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-14-small.jpg 355w" data-image-id="fig-14" alt="Comparative results of evaluation measures statistics on unseen data." data-full="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-14-full.png" data-thumb="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-14-thumb.jpg" data-original="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-14.png" data-image-type="figure" data-jats-mimetype="image" data-jats-mime-subtype="png" width="600" height="388"></a></div>
<figcaption itemprop="description">
                  <h4 class="heading">
<span class="caption-label">Figure 14: </span>Comparative results of evaluation measures statistics on unseen data.</h4>
               <div class="figcaption-footer">
<div class="article-image-download"><a href="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-14-full.png" class="btn btn-mini" download="peerj-cs-677-fig-14.png" itemprop="url"><i class="icon-large icon-picture"> </i> Download full-size image</a></div>
<div class="object-id article-component-doi">DOI: <a href="https://doi.org/10.7717/peerjcs.677/fig-14" data-toggle="tooltip" title="Cite this object using this DOI">10.7717/peerjcs.677/fig-14</a>
</div>
</div></figcaption></figure>
            <figure class="fig" itemprop="image" itemscope="itemscope" itemtype="https://schema.org/ImageObject" id="fig-15"><div class="image-container"><a href="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-15-2x.jpg" title="View the full image" class="fresco" data-fresco-caption="Figure 15: Comparative results of each fold of all models on unseen data." data-fresco-group="figure" data-fresco-options="fit: 'width', ui: 'outside', thumbnails: false, loop: true, position: true, overflow: true, preload: false"><img class="graphic" src="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-15-1x.jpg" itemprop="contentUrl" sizes="(min-width: 1200px) 581px, (max-width: 1199px) and (min-width: 980px) 462px, (max-width: 979px) and (min-width: 768px) 347px, (max-width: 767px) calc(100vw - 50px)" srcset="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-15-2x.jpg 1200w, https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-15-1x.jpg 600w, https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-15-small.jpg 355w" data-image-id="fig-15" alt="Comparative results of each fold of all models on unseen data." data-full="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-15-full.png" data-thumb="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-15-thumb.jpg" data-original="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-15.png" data-image-type="figure" data-jats-mimetype="image" data-jats-mime-subtype="png" width="600" height="387"></a></div>
<figcaption itemprop="description">
                  <h4 class="heading">
<span class="caption-label">Figure 15: </span>Comparative results of each fold of all models on unseen data.</h4>
                  <span class="p">The every fold result of our model that we applied to data unseen data; by using the train vectors of previous data, we applied to this unseen data to check the validity of our models that was trained on previous data.</span>
               <div class="figcaption-footer">
<div class="article-image-download"><a href="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-15-full.png" class="btn btn-mini" download="peerj-cs-677-fig-15.png" itemprop="url"><i class="icon-large icon-picture"> </i> Download full-size image</a></div>
<div class="object-id article-component-doi">DOI: <a href="https://doi.org/10.7717/peerjcs.677/fig-15" data-toggle="tooltip" title="Cite this object using this DOI">10.7717/peerjcs.677/fig-15</a>
</div>
</div></figcaption></figure>
            <section class="sec">
               <h4 class="heading">McNemar’s statistical test on unseen data</h4>
               <p id="p-75">We did a hypotheses test by applying McNemar’s test to check whether these classifiers are statistically significant on unseen data. In machine learning McNemar’s test can be used to compare the performance accuracy of two models (<a class="xref xref-bibr" href="https://doi.org/10.1007%2FBF02295996" title="Note on the sampling error of the difference between correlated proportions or percentages" data-jats-ref-type="bibr" data-jats-rid="ref-28">McNemar, 1947</a>; <a class="ext-link" href="http://rasbt.github.io/mlxtend/user_guide/evaluate/mcnemar/" data-jats-ext-link-type="uri">http://rasbt.github.io/mlxtend/user_guide/evaluate/mcnemar/</a>). McNemar’s test operates on contingency table values that showed in <a class="xref xref-table" href="#table-7" data-jats-ref-type="table" data-jats-rid="table-7">Table 7</a>.</p>
               <figure class="table-wrap" id="table-7"><div class="caption">
<span class="caption-label">Table 7: </span>
                     <div class="title">Contingency table for McNemar‘s statistics test.</div>
                  </div>
                  
                  <div class="table-container"><table class="table table-bordered table-condensed table-hover">
                        <colgroup>
                           <col>
                           <col>
                        </colgroup>
                        <tbody>
                           <tr>
                              <td>correctly classified by both A and B (n00)</td>
                              <td>correctly classified by A but not by B (n01)</td>
                           </tr>
                           <tr>
                              <td>correctly classified by B but not by A (n10)</td>
                              <td>correctly classified neither by A or B (n11)</td>
                           </tr>
                        </tbody>
                     </table></div>
<div class="object-id article-component-doi">DOI: <a href="https://doi.org/10.7717/peerjcs.677/table-7" data-toggle="tooltip" title="Cite this object using this DOI">10.7717/peerjcs.677/table-7</a>
</div>
               </figure>
               <p id="p-76">A = SVM classifier</p>
               <p id="p-77">B = MaxEnt sgd classifier</p>
               <p id="p-78">The McNemar’s test is computed as follows: <span class="disp-formula" id="eqn-7"><span class="article-label">(7)</span><math xmlns="http://www.w3.org/1998/Math/MathML" id="mml-eqn-7">
                           <mstyle displaystyle="true">
                              <mfrac>
                                 <mrow>
                                    <msup>
                                       <mrow>
                                          <mrow><mfenced separators="" open="(" close=")"><mo>|</mo>
                                             <mi>n</mi>
                                             <mn>01</mn>
                                             <mo>−</mo>
                                             <mi>n</mi>
                                             <mn>10</mn>
                                             <mo>|</mo>
                                             <mo>−</mo>
                                             <mn>1</mn></mfenced></mrow>
                                       </mrow>
                                       <mrow>
                                          <mn>2</mn>
                                       </mrow>
                                    </msup>
                                 </mrow>
                                 <mrow>
                                    <mi>n</mi>
                                    <mn>01</mn>
                                    <mo>+</mo>
                                    <mi>n</mi>
                                    <mn>10</mn>
                                 </mrow>
                              </mfrac>
                           </mstyle>
                        </math>
                  </span>n00 = no of samples correctly classified by both A and B</p>
               <p id="p-79">n01 = no of samples correctly classified by A but not by B</p>
               <p id="p-80">n10 = no of samples correctly classified by B but not by A</p>
               <p id="p-81">n11 = no of samples not correctly classified by either A or B</p>
               <p id="p-82">The first step in the statistical test to state the Null hypotheses statement. Our statement is;</p>
               <p id="p-83">H0 = cannot reject the null hypotheses indicating both classifiers have the same performance on the dataset if the calculated <i>p</i>-value greater than the threshold <i>p</i>-value.</p>
               <p id="p-84">H1 = can reject the null hypotheses indicating both classifiers have different performance on dataset if calculated <i>p</i>-value less than threshold <i>p</i>-value.</p>
               <p id="p-85">We ran chi-squared McNemar’s with threshold <i>p</i>-value of 0.05. As shown in <a class="xref xref-fig" href="#fig-15" data-jats-ref-type="fig" data-jats-rid="fig-15">Fig. 15</a> the SVM and MaxEnt with sgd have higher average accuracy than the MaxEnt, so we ran McNemar’s test on these two classifiers and the <b>computed <i>p</i>-value was 0.005667</b>, it indicates that these two classifiers are different, and SVM performs significantly better than the MaxEnt, and the final result is statistically significant.</p>
            </section>
         </section>
         <section class="sec">
            <h3 class="heading">Overall results analysis</h3>
            <p id="p-86">To examine the performance of our framework and ultimately the classifiers based on our proposed framework, we ran a 5-fold CV, so that in each run 1/5 of the reviews and tweets are held as validation data and remaining held as training data. This setting repeated for every fold and in the last, we checked the F1, precision, and recall scores of our classifiers to check the performance. The detailed measure scores of classifiers while compared with baseline methods are shown in results and analysis sections of the Amazon and social media dataset separately. While analyzing the Amazon dataset results, the appropriate model was with 20 topics, and with bi-gram vectors, it may be because the Amazon dataset contains relatively large texts and more information. When we change the parameters and try the LDA model with bigrams and decrease the topic numbers then it ultimately affects on average F1 score and recall scores of classifiers, as the F1 score drastically decreases from 91% to lowest 64%, similarly recall scores drops to 65% from the 91%. We compared our approach with the baseline approach such as without topic distributions feature vectors, and we implemented the typical text classifiers with different embedding schemes such TFIDF and doc2vec as a baseline, and overall our approach fairly performed well in classifying the text. In <a class="xref xref-table" href="#table-8" data-jats-ref-type="table" data-jats-rid="table-8">Table 8</a>, baseline method overall highest achieved scores are given in comparison with T2F approach, doc2vec applied on Amazon dataset performs best among the baselines, but still, it is 5% lower than the proposed method in terms of f1 score, T2F, when applied with SVM classifier, achieved the best outcomes and yield 91% f1 score, on MaxEnt sgd classifier it achieved 88% f1 score, still 2% higher than the highest score of implemented baseline method which was 86%. To further analyze from the perspective of different types of embedding schemes researchers proposed in their studies, we have decided to compare our proposed approach with approaches from other research studies that classify the textual data, we have picked up performance results from those research studies, those leveraged different feature embedding schemes, and compared it with our proposed approach, we compared with those approaches from prior studies because their context was also to classify the data by using different feature vectors schemes, like researchers in (<a class="xref xref-bibr" href="https://doi.org/10.1016%2Fj.joi.2020.101121" title="Using graph embedding and machine learning to identify rebels on twitter" data-jats-ref-type="bibr" data-jats-rid="ref-26">Masood &amp; Abbasi, 2021</a>) used graph embedding features to classify the social media textual data (284k tweets) into 3 categories and highest overall F1 score was 87% as compared to 91% F1 score of our framework, see results in <a class="xref xref-table" href="#table-9" data-jats-ref-type="table" data-jats-rid="table-9">Table 9</a>, for the dataset, they manually collected the tweets, manually labeled them into categories of rebel users and classify them. Another study uses the feature vector embedding combining initial letter, paragraph, and frequency features to classify the English documents (174 documents) of 4 different categories and their F1 scores fall short by 7% and 5% while using MaxEnt and support vector machine algorithms respectively (<a class="xref xref-bibr" href="https://doi.org/10.1016%2Fj.aej.2021.02.009" title="Efficient english text classification using selected machine learning techniques" data-jats-ref-type="bibr" data-jats-rid="ref-25">Luo, 2021</a>) in comparison with our proposed T2F. Graph of words and subgraph feature representations experimented instead of a typical bag of word features by (<a class="xref xref-bibr" href="https://scholar.google.com/scholar_lookup?title=Text%20categorization%20as%20a%20graph%20classification%20problem&amp;author=Rousseau&amp;publication_year=2015" title="Text categorization as a graph classification problem" data-jats-ref-type="bibr" data-jats-rid="ref-37">Rousseau, Kiagias &amp; Vazirgiannis, 2015</a>) and maximum F1 score reached up to 79% while implementing on Amazon dataset (16000 user reviews), their dataset is related to our Amazon review dataset to some extent, instead, they just used the portion of Amazon reviews dataset only about specific products categories such as Kitchen, DVD’s, books and electronics and we are using Amazon reviews about all the products. All the comparisons with baseline approaches and some other proposed approached in different research studies imply that our novelistic framework performed fairly better. It also indicates that apply the topic modeling with more topics when you have large sentence texts. This can be applied to other classification problems, online complaints, document classification, news classification, and medical text classification.</p>
            <figure class="table-wrap" id="table-8"><div class="caption">
<span class="caption-label">Table 8: </span>
                  <div class="title">Comparative results of Best Average F1,Precision and Recall score with baseline approaches.</div>
               </div>
               
               <div class="table-container"><table class="table table-bordered table-condensed table-hover">
                     <colgroup>
                        <col>
                        <col>
                        <col>
                        <col>
                     </colgroup>
                     <thead>
                        <tr>
                           <th><b>Methods</b></th>
                           <th><b>F1 Score</b></th>
                           <th><b>Precision</b></th>
                           <th><b>Recall</b></th>
                        </tr>
                     </thead>
                     <tbody>
                        <tr>
                           <td>TFIDF SVM SGD</td>
                           <td>82%</td>
                           <td>83%</td>
                           <td>80%</td>
                        </tr>
                        <tr>
                           <td>TFIDF Multinomial NB</td>
                           <td>74%</td>
                           <td>76%</td>
                           <td>75%</td>
                        </tr>
                        <tr>
                           <td>TFIDF MaxEnt</td>
                           <td>71%</td>
                           <td>72%</td>
                           <td>68%</td>
                        </tr>
                        <tr>
                           <td>doc2vec MaxEnt</td>
                           <td>86%</td>
                           <td>77%</td>
                           <td><b>92%</b></td>
                        </tr>
                        <tr>
                           <td>T2F (SVM)</td>
                           <td><b>91%</b></td>
                           <td>87%</td>
                           <td>91%</td>
                        </tr>
                        <tr>
                           <td>T2F (MaxEnt)</td>
                           <td>81%</td>
                           <td>83%</td>
                           <td>78%</td>
                        </tr>
                        <tr>
                           <td>T2F (MaxEnt sgd)</td>
                           <td>88%</td>
                           <td><b>91%</b></td>
                           <td>88%</td>
                        </tr>
                     </tbody>
                  </table></div>
<div class="object-id article-component-doi">DOI: <a href="https://doi.org/10.7717/peerjcs.677/table-8" data-toggle="tooltip" title="Cite this object using this DOI">10.7717/peerjcs.677/table-8</a>
</div>
            </figure>
            <figure class="table-wrap" id="table-9"><div class="caption">
<span class="caption-label">Table 9: </span>
                  <div class="title">Comparative results of Best Average F1, Precision and Recall score with prior studies work from the perspective of using different feature representation embedding schemes.</div>
               </div>
               
               <div class="table-container"><table class="table table-bordered table-condensed table-hover">
                     <colgroup>
                        <col>
                        <col>
                        <col>
                        <col>
                     </colgroup>
                     <thead>
                        <tr>
                           <th><b>Prior study Methods</b></th>
                           <th><b>F1 Score</b></th>
                           <th><b>Precision</b></th>
                           <th><b>Recall</b></th>
                        </tr>
                     </thead>
                     <tbody>
                        <tr>
                           <td>SRI (profile, content+ graph) masood15using</td>
                           <td>87%</td>
                           <td>91%</td>
                           <td>90%</td>
                        </tr>
                        <tr>
                           <td>SRI (profile, content) masood15using</td>
                           <td>79%</td>
                           <td>79%</td>
                           <td>79%</td>
                        </tr>
                        <tr>
                           <td>SRI doc embedding masood15using</td>
                           <td>86%</td>
                           <td>87%</td>
                           <td>88%</td>
                        </tr>
                        <tr>
                           <td>IPF SVM LUO20213401</td>
                           <td>86%</td>
                           <td>88%</td>
                           <td>87%</td>
                        </tr>
                        <tr>
                           <td>IPF with MaxEnt LUO20213401</td>
                           <td>81%</td>
                           <td>83%</td>
                           <td>85%</td>
                        </tr>
                        <tr>
                           <td>T2G embeddings svm rousseau2015text</td>
                           <td>79%</td>
                           <td>79%</td>
                           <td>77%</td>
                        </tr>
                        <tr>
                           <td><b>Proposed Methods</b></td>
                           <td></td>
                           <td></td>
                           <td></td>
                        </tr>
                        <tr>
                           <td>T2F (SVM)</td>
                           <td><b>91%</b></td>
                           <td>87%</td>
                           <td>91%</td>
                        </tr>
                        <tr>
                           <td>T2F (MaxEnt)</td>
                           <td>81%</td>
                           <td>83%</td>
                           <td>78%</td>
                        </tr>
                        <tr>
                           <td>T2F (MaxEnt sgd)</td>
                           <td>88%</td>
                           <td><b>91%</b></td>
                           <td>88%</td>
                        </tr>
                     </tbody>
                  </table></div>
<div class="object-id article-component-doi">DOI: <a href="https://doi.org/10.7717/peerjcs.677/table-9" data-toggle="tooltip" title="Cite this object using this DOI">10.7717/peerjcs.677/table-9</a>
</div>
            </figure>
         </section>
      </section>
      <section class="sec" id="discussion">
         <h2 class="heading">Discussion</h2>
         <p id="p-87">A novel framework with the integration of topic distribution features from an unsupervised topic modeling approach considering the features selection is presented. It deals with sparse, user-oriented, short, and slang types of data from different domains. Relevant features extraction to increase the classifier performance is the main purpose of this framework. We focus on the semantic unsupervised generated structure of words that occurred in the texts to classify the user reviews or tweets and how it can assist in supervised classification. Besides classification of user reviews or tweets, recent studies concatenated recently evolved doc2vec with LDA topics, researchers in <a class="xref xref-bibr" href="https://scholar.google.com/scholar_lookup?title=Sentiment%20analysis%20using%20topic-document%20embeddings&amp;author=Mitroi&amp;publication_year=2020" title="Sentiment analysis using topic-document embeddings" data-jats-ref-type="bibr" data-jats-rid="ref-30">Mitroi et al. (2020)</a> proposed topicdoc2vec model for classifying the sentiment from textual data, they applied doc2vec for vectorizing the textual content and LDA to detect topics, and then they combined both doc2vec vector representation of the best topic of the document through LDA and named it as topicdoc2vec. Their approach claimed to be an approach that adds the context of the topic to the classification process. Although it is an effective approach to construct the context of a document through combined embeddings, this can also be done by only converting LDA topics and their probability distributions to feature vectors as we did in our framework, which is easy to use, flexible, and gives good classification performance. Most of the researchers leverages LDA in combination with other techniques to create a joint topic-oriented word embeddings for a specific context; researchers in <a class="xref xref-bibr" href="https://scholar.google.com/scholar_lookup?title=Joint%20topical%20word%20embedding%20for%20detecting%20drift%20in%20social%20media%20text&amp;author=Geetha&amp;publication_year=2020" title="Joint topical word embedding for detecting drift in social media text" data-jats-ref-type="bibr" data-jats-rid="ref-11">Geetha (2020)</a> built a joint topical model through LDA, and that model associates topics with a mixture of distributions of words, hashtags and geotags to create topical embeddings specifically for location context. Their embeddings with co-occurrence and location contexts are specified with hashtag vector and geotag context vector respectively. Indeed it is an interesting approach to explore the LDA topic model more for creating embeddings, but it is specified and restricted to geo-located textual data.</p>
         <p id="p-88">Our framework gives comparatively better results in comparison to other prior study approaches that used typical features such as TFIDF, graph embeddings, and graph of words features (see <a class="xref xref-fig" href="#fig-16" data-jats-ref-type="fig" data-jats-rid="fig-16">Fig. 16</a>) and with baseline approaches comparison (see <a class="xref xref-fig" href="#fig-17" data-jats-ref-type="fig" data-jats-rid="fig-17">Fig. 17</a>). In this framework, we did not feed the classifier with classic TFIDF representations or doc2vec word embeddings, instead, we feed classifiers with novel topic distributions features after getting topics on the dataset. This approach can be seen as semi-supervised in a way that it feeds the feature vectors from the unsupervised topic modeling approach into supervised classification algorithms. While building LDA models we analyzed that to extract the most relevant topic distributions, careful text preprocessing is very necessary as it ultimately impacts the model performance. In this regard, we leveraged lemmatization instead of stemming in our text preprocessing, because it gives or reduced the words into their root form with the contextual meaning (<a class="xref xref-bibr" href="https://doi.org/10.1016%2Fj.icte.2020.07.003" title="An algorithm and method for sentiment analysis using the text and emoticon" data-jats-ref-type="bibr" data-jats-rid="ref-43">Ullah et al., 2020</a>). This framework is flexible in a way that it only requires text contents and categories in which you want to classify the data, and this framework is capable to be applied to different domains, like opinion mining, social media sentiment classification, user reviews classification, customer complaints classification government organization. From the results, we found out that for large type text such as documents and large reviews LDA model with more topics would be more suitable and for the sparse short and slang type of texts, an LDA model with fewer topics would be feasible.</p>
         <figure class="fig" itemprop="image" itemscope="itemscope" itemtype="https://schema.org/ImageObject" id="fig-16"><div class="image-container"><a href="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-16-2x.jpg" title="View the full image" class="fresco" data-fresco-caption="Figure 16: Comparative results of evaluation measures in comparison with prior studies approaches." data-fresco-group="figure" data-fresco-options="fit: 'width', ui: 'outside', thumbnails: false, loop: true, position: true, overflow: true, preload: false"><img class="graphic" src="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-16-1x.jpg" itemprop="contentUrl" sizes="(min-width: 1200px) 581px, (max-width: 1199px) and (min-width: 980px) 462px, (max-width: 979px) and (min-width: 768px) 347px, (max-width: 767px) calc(100vw - 50px)" srcset="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-16-2x.jpg 1200w, https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-16-1x.jpg 600w, https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-16-small.jpg 355w" data-image-id="fig-16" alt="Comparative results of evaluation measures in comparison with prior studies approaches." data-full="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-16-full.png" data-thumb="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-16-thumb.jpg" data-original="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-16.png" data-image-type="figure" data-jats-mimetype="image" data-jats-mime-subtype="png" width="600" height="355"></a></div>
<figcaption itemprop="description">
               <h3 class="heading">
<span class="caption-label">Figure 16: </span>Comparative results of evaluation measures in comparison with prior studies approaches.</h3>
            <div class="figcaption-footer">
<div class="article-image-download"><a href="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-16-full.png" class="btn btn-mini" download="peerj-cs-677-fig-16.png" itemprop="url"><i class="icon-large icon-picture"> </i> Download full-size image</a></div>
<div class="object-id article-component-doi">DOI: <a href="https://doi.org/10.7717/peerjcs.677/fig-16" data-toggle="tooltip" title="Cite this object using this DOI">10.7717/peerjcs.677/fig-16</a>
</div>
</div></figcaption></figure>
         <figure class="fig" itemprop="image" itemscope="itemscope" itemtype="https://schema.org/ImageObject" id="fig-17"><div class="image-container"><a href="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-17-2x.jpg" title="View the full image" class="fresco" data-fresco-caption="Figure 17: Comparative results of evaluation measures in comparison with baseline approaches." data-fresco-group="figure" data-fresco-options="fit: 'width', ui: 'outside', thumbnails: false, loop: true, position: true, overflow: true, preload: false"><img class="graphic" src="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-17-1x.jpg" itemprop="contentUrl" sizes="(min-width: 1200px) 581px, (max-width: 1199px) and (min-width: 980px) 462px, (max-width: 979px) and (min-width: 768px) 347px, (max-width: 767px) calc(100vw - 50px)" srcset="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-17-2x.jpg 1200w, https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-17-1x.jpg 600w, https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-17-small.jpg 355w" data-image-id="fig-17" alt="Comparative results of evaluation measures in comparison with baseline approaches." data-full="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-17-full.png" data-thumb="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-17-thumb.jpg" data-original="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-17.png" data-image-type="figure" data-jats-mimetype="image" data-jats-mime-subtype="png" width="600" height="329"></a></div>
<figcaption itemprop="description">
               <h3 class="heading">
<span class="caption-label">Figure 17: </span>Comparative results of evaluation measures in comparison with baseline approaches.</h3>
            <div class="figcaption-footer">
<div class="article-image-download"><a href="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/fig-17-full.png" class="btn btn-mini" download="peerj-cs-677-fig-17.png" itemprop="url"><i class="icon-large icon-picture"> </i> Download full-size image</a></div>
<div class="object-id article-component-doi">DOI: <a href="https://doi.org/10.7717/peerjcs.677/fig-17" data-toggle="tooltip" title="Cite this object using this DOI">10.7717/peerjcs.677/fig-17</a>
</div>
</div></figcaption></figure>
      </section>
      <section class="sec">
         <h2 class="heading">Conclusion and future work</h2>
         <p id="p-89">The proposed framework implements an LDA topic model with text classifiers, which can make a text classification by leveraging the hidden topics retrieved from datasets. The method was tested on two datasets of two different domains, datasets with noisy values, sparse data, and imbalanced ratios within, and our proposed method handles that as well in a way to classify the text. From the results, it is evident that our method outperforms other baseline approaches and comparable methods by a reasonably good margin in terms of average F1 scores. We have measured the validity of our model through the 5-fold CV that yields 81% classification accuracy, 5X2 fold CV paired <i>t</i>-test, and McNemar’s test statistics. In addition, we applied our model on unseen data, which includes utilizing the topic distributions from specific year’s data and applying it to completely unseen data, and this behavior also gives good results in terms of evaluation measures performance. When compared with baseline and prior study approaches, results show improvement while using T2F representations, with the highest 91% average F1 score with SVM classifiers along with bi-grams, and the highest mean accuracy of 81%. Moreover, the search for the best combination of parameters is based on how evaluation measures are performed. We got the best combination of SVM classifiers using bi-grams on Amazon dataset that yields highest average F1 score, and with MaxEnt classifier with both 15 and 10 topics and trigrams combination that gives highest average F1 score on social media dataset, and then on 5-fold CV evaluation the MaxEnt sgd classifier with bigrams and 20 topics gives best mean accuracy results. We find that our T2F model outperforms other baselines and prior study approaches on average F1 score and mean accuracy; overall, our framework performs better if we see evaluation measures results, which indicate that topic-oriented features can be leveraged as one of the features representation techniques while classifying the texts. Also with these findings, we prepared a model that paved the way to create topic-oriented features (T2F) representation of content for classification; it can be applied into any text classification context. Furthermore, we have demonstrated that text representation based on LDA topic modeling has more semantic meaning and can improve the classification performance while performing in a semi-supervised manner. Many improvements can be made, such as one can apply this method on medical domain datasets. In the future, we will extend our framework to automatic labeling of data to prepare a labeled dataset to be used in supervised algorithms. We will gather the topic distributions and apply ranking algorithms and analyze the topics in terms of weightage and label the documents, reviews or tweets; this will reduce the cost of human labels and will also remove the need of gathering the labeled datasets, because not every public dataset has labels. Also, while applying classification on the labeled dataset, we will explore some deep learning classifiers such as used by <a class="xref xref-bibr" href="https://scholar.google.com/scholar_lookup?title=Crisislex:%20a%20lexicon%20for%20collecting%20and%20filtering%20microblogged%20communications%20in%20crises&amp;author=Olteanu&amp;publication_year=2014" title="Crisislex: a lexicon for collecting and filtering microblogged communications in crises" data-jats-ref-type="bibr" data-jats-rid="ref-34">Olteanu et al. (2014)</a> and will investigate the impact of these classifiers on classification performance.</p>
      </section>
      <section class="sec" id="supplemental-information">
         <h2 class="heading">Supplemental Information</h2>
         <div class="supplementary-material well well-small" id="supp-1">
<h3 class="heading">Code source files for the experiments</h3>
               
            <div class="object-id article-component-doi">DOI: <a href="https://doi.org/10.7717/peerj-cs.677/supp-1" data-toggle="tooltip" title="Cite this object using this DOI">10.7717/peerj-cs.677/supp-1</a>
</div>
<div><a href="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/Topic_Modelling_Code_Files.rar" class="btn article-supporting-download" data-rel="supplement" download="Topic_Modelling_Code_Files.rar" data-filename="Topic_Modelling_Code_Files.rar"><i class="icon-large icon-download-alt"> </i> Download</a></div>
</div>
         <div class="supplementary-material well well-small" id="supp-2" data-jats-mimetype="text" data-jats-mime-subtype="plain">
<h3 class="heading">Description of code files</h3>
               
            <div class="object-id article-component-doi">DOI: <a href="https://doi.org/10.7717/peerj-cs.677/supp-2" data-toggle="tooltip" title="Cite this object using this DOI">10.7717/peerj-cs.677/supp-2</a>
</div>
<div><a href="https://dfzljdn9uc3pi.cloudfront.net/2021/cs-677/1/Readme_Code_files_Description.txt" class="btn article-supporting-download" data-rel="supplement" download="Readme_Code_files_Description.txt" data-filename="Readme_Code_files_Description.txt"><i class="icon-large icon-download-alt"> </i> Download</a></div>
</div>
      </section>
   </div></main><footer class="back">
      <div class="sec" id="additional-information">
         <h2 class="heading">Additional Information and Declarations</h2>
         <div class="fn-group" data-jats-content-type="competing-interests">
            <h3 class="heading">Competing Interests</h3>
<div class="fn" id="conflict-1" data-jats-fn-type="conflict"><p>The authors declare there are no competing interests.</p></div>
</div>
         <div class="fn-group" data-jats-content-type="author-contributions">
            <h3 class="heading">Author Contributions</h3>
<div class="fn" id="contribution-1" data-jats-fn-type="con"><p><a class="xref xref-contrib" href="#author-1" data-jats-ref-type="contrib" data-jats-rid="author-1">Junaid Abdul Wahid</a> conceived and designed the experiments, performed the experiments, analyzed the data, performed the computation work, prepared figures and/or tables, authored or reviewed drafts of the paper, and approved the final draft.</p></div>
<div class="fn" id="contribution-2" data-jats-fn-type="con"><p><a class="xref xref-contrib" href="#author-2" data-jats-ref-type="contrib" data-jats-rid="author-2">Lei Shi</a> analyzed the data, prepared figures and/or tables, authored or reviewed drafts of the paper, and approved the final draft.</p></div>
<div class="fn" id="contribution-3" data-jats-fn-type="con"><p><a class="xref xref-contrib" href="#author-3" data-jats-ref-type="contrib" data-jats-rid="author-3">Yufei Gao</a> conceived and designed the experiments, performed the experiments, analyzed the data, performed the computation work, prepared figures and/or tables, authored or reviewed drafts of the paper, and approved the final draft.</p></div>
<div class="fn" id="contribution-4" data-jats-fn-type="con"><p><a class="xref xref-contrib" href="#author-4" data-jats-ref-type="contrib" data-jats-rid="author-4">Bei Yang</a> performed the experiments, authored or reviewed drafts of the paper, and approved the final draft.</p></div>
<div class="fn" id="contribution-5" data-jats-fn-type="con"><p><a class="xref xref-contrib" href="#author-5" data-jats-ref-type="contrib" data-jats-rid="author-5">Yongcai Tao</a> analyzed the data, authored or reviewed drafts of the paper, and approved the final draft.</p></div>
<div class="fn" id="contribution-6" data-jats-fn-type="con"><p><a class="xref xref-contrib" href="#author-6" data-jats-ref-type="contrib" data-jats-rid="author-6">Lin Wei</a> analyzed the data, authored or reviewed drafts of the paper, and approved the final draft.</p></div>
<div class="fn" id="contribution-7" data-jats-fn-type="con"><p><a class="xref xref-contrib" href="#author-7" data-jats-ref-type="contrib" data-jats-rid="author-7">Shabir Hussain</a> performed the experiments, prepared figures and/or tables, and approved the final draft.</p></div>
</div>
         <div class="fn-group" data-jats-content-type="other">
            <h3 class="heading">Data Availability</h3>
<div class="fn" id="addinfo-1">
<p>The following information was supplied regarding data availability:</p>
            <p>Source codes are available in the <a class="xref xref-supplementary-material" href="#supplemental-information" data-jats-ref-type="supplementary-material" data-jats-rid="supplemental-information">Supplemental Files</a>.</p>
            <p>We used public datasets:</p>
            <p>- Amazon dataset: <a class="ext-link" href="https://www.kaggle.com/snap/Amazon-fine-food-reviews" data-jats-ext-link-type="uri">https://www.kaggle.com/snap/Amazon-fine-food-reviews</a>.</p>
            <p>- Social media dataset 6 disasters: <a class="ext-link" href="https://github.com/sajao/CrisisLex/tree/master/data/CrisisLexT6/" data-jats-ext-link-type="uri">https://github.com/sajao/CrisisLex/tree/master/data/CrisisLexT6/</a>.</p>
            <p>- Social media remaining one disaster dataset (Resource #2): <a class="ext-link" href="https://crisisnlp.qcri.org/" data-jats-ext-link-type="uri">https://crisisnlp.qcri.org/</a>.</p>
</div>
</div>
      <h3 class="heading">Funding</h3>
<p>This work was supported by the National Key Technologies R&amp;D Program (under grant number 2020YFB1712401, 2018YFB1701401), the Nature Science Foundation of China (grant number 62006210), the major project of Zhengzhou Collaborative Innovation (under grant number 20XTZX-009, 20XTZX-X010), the National Key R&amp;D Program of China 2018 and the Key Scientific and Technological Research Projects in the Henan Province of China under grant number 192102310216, the National Key R&amp;D Program of China (2018******02), and the 2020 Major Project Public Benefit Project in Henan Province (201300210500). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</p>
</div>
      <section class="ref-list-container" id="references"><h2 class="heading">References</h2>
<ul class="ref-list" data-jats-content-type="authoryear">
<li class="ref"><div class="citation" itemprop="citation" itemscope="itemscope" id="ref-1">
<span class="citation-authors-year"><b><span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Alokaili</span> <span class="given-names" itemprop="givenName">A</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Aletras</span> <span class="given-names" itemprop="givenName">N</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Stevenson</span> <span class="given-names" itemprop="givenName">M</span></span>.</b> <b class="year" itemprop="datePublished">2020</b>.</span> <cite class="article-title"><a class="article-title" target="_blank" itemprop="url" href="https://scholar.google.com/scholar_lookup?title=Automatic%20generation%20of%20topic%20labels&amp;author=Alokaili&amp;publication_year=2020">Automatic generation of topic labels</a>.</cite> In: <span itemprop="name"><a class="conf-name" target="_blank" href="https://scholar.google.com/scholar_lookup?title=Proceedings%20of%20the%2043rd%20international%20ACM%20SIGIR%20conference%20on%20research%20and%20development%20in%20information%20retrieval&amp;author=&amp;publication_year=2020">Proceedings of the 43rd international ACM SIGIR conference on research and development in information retrieval</a>.</span><span> <span class="conf-loc">New York</span>. <span class="conf-sponsor">ACM</span>.   <span class="fpage" itemprop="pageStart">1965</span>-<span class="lpage" itemprop="pageEnd">1968</span> </span>
</div></li>
<li class="ref"><div class="citation" itemprop="citation" itemscope="itemscope" id="ref-2">
<span class="citation-authors-year"><b><span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Andoni</span> <span class="given-names" itemprop="givenName">A</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Indyk</span> <span class="given-names" itemprop="givenName">P</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Razenshteyn</span> <span class="given-names" itemprop="givenName">I</span></span>.</b> <b class="year" itemprop="datePublished">2018</b>.</span> <cite class="article-title"><a class="article-title" target="_blank" itemprop="url" href="http://arxiv.org/abs/1806.09823">Approximate nearest neighbor search in high dimensions</a>.</cite> </div></li>
<li class="ref"><div class="citation" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle" id="ref-3">
<span class="citation-authors-year"><b><span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Blei</span> <span class="given-names" itemprop="givenName">DM</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Ng</span> <span class="given-names" itemprop="givenName">AY</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Jordan</span> <span class="given-names" itemprop="givenName">MI</span></span>.</b> <b class="year" itemprop="datePublished">2003</b>.</span> <cite itemprop="name"><a class="article-title" target="_blank" itemprop="url" href="https://scholar.google.com/scholar_lookup?title=Latent%20dirichlet%20allocation&amp;author=Blei&amp;publication_year=2003">Latent dirichlet allocation</a>.</cite> <span><span class="volume" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/PublicationVolume"><span class="source" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/Periodical"><span itemprop="name">The Journal of Machine Learning Research</span></span> <b itemprop="volumeNumber">3</b></span>:<span class="fpage" itemprop="pageStart">993</span>-<span class="lpage" itemprop="pageEnd">1022</span> </span>
</div></li>
<li class="ref"><div class="citation" itemprop="citation" itemscope="itemscope" id="ref-4">
<span class="citation-authors-year"><b><span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Cano Basave</span> <span class="given-names" itemprop="givenName">AE</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">He</span> <span class="given-names" itemprop="givenName">Y</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Xu</span> <span class="given-names" itemprop="givenName">R</span></span>.</b> <b class="year" itemprop="datePublished">2014</b>.</span> <cite class="article-title"><a class="article-title" target="_blank" itemprop="url" href="https://scholar.google.com/scholar_lookup?title=Automatic%20labelling%20of%20topic%20models%20learned%20from%20Twitter%20by%20summarisation&amp;author=Cano%C2%A0Basave&amp;publication_year=2014">Automatic labelling of topic models learned from Twitter by summarisation</a>.</cite> In: <span itemprop="name"><a class="conf-name" target="_blank" href="https://scholar.google.com/scholar_lookup?title=Proceedings%20of%20the%2052nd%20annual%20meeting%20of%20the%20association%20for%20computational%20linguistics%20(Volume%202:%20Short%20Papers)&amp;author=&amp;publication_year=2014">Proceedings of the 52nd annual meeting of the association for computational linguistics (Volume 2: Short Papers)</a>.</span><span> <span class="conf-loc">Baltimore, Maryland</span>. <span class="conf-sponsor">Association for Computational Linguistics</span>.   <span class="fpage" itemprop="pageStart">618</span>-<span class="lpage" itemprop="pageEnd">624</span> </span>
</div></li>
<li class="ref"><div class="citation" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle" id="ref-5">
<span class="citation-authors-year"><b><span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Colace</span> <span class="given-names" itemprop="givenName">F</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">De Santo</span> <span class="given-names" itemprop="givenName">M</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Greco</span> <span class="given-names" itemprop="givenName">L</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Napoletano</span> <span class="given-names" itemprop="givenName">P</span></span>.</b> <b class="year" itemprop="datePublished">2014</b>.</span> <cite itemprop="name"><a class="article-title" target="_blank" itemprop="url" href="https://doi.org/10.1016%2Fj.chb.2013.07.043">Text classification using a few labeled examples</a>.</cite> <span><span class="volume" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/PublicationVolume"><span class="source" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/Periodical"><span itemprop="name">Computers in Human Behavior</span></span> <b itemprop="volumeNumber">30</b></span>:<span class="fpage" itemprop="pageStart">689</span>-<span class="lpage" itemprop="pageEnd">697</span> </span>
</div></li>
<li class="ref"><div class="citation" itemprop="citation" itemscope="itemscope" id="ref-6">
<span class="citation-authors-year"><b><span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Devlin</span> <span class="given-names" itemprop="givenName">J</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Chang</span> <span class="given-names" itemprop="givenName">M-W</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Lee</span> <span class="given-names" itemprop="givenName">K</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Toutanova</span> <span class="given-names" itemprop="givenName">K</span></span>.</b> <b class="year" itemprop="datePublished">2018</b>.</span> <cite class="article-title"><a class="article-title" target="_blank" itemprop="url" href="http://arxiv.org/abs/1810.04805">Bert: pre-training of deep bidirectional transformers for language understanding</a>.</cite> </div></li>
<li class="ref"><div class="citation" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle" id="ref-7">
<span class="citation-authors-year"><b><span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Dietterich</span> <span class="given-names" itemprop="givenName">TG</span></span>.</b> <b class="year" itemprop="datePublished">1998</b>.</span> <cite itemprop="name"><a class="article-title" target="_blank" itemprop="url" href="https://doi.org/10.1162%2F089976698300017197">Approximate statistical tests for comparing supervised classification learning algorithms</a>.</cite> <span><span class="issue" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/PublicationIssue"><span class="volume" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/PublicationVolume"><span class="source" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/Periodical"><span itemprop="name">Neural Computation</span></span> <b itemprop="volumeNumber">10</b></span>(<span itemprop="issueNumber">7</span>)</span>:<span class="fpage" itemprop="pageStart">1895</span>-<span class="lpage" itemprop="pageEnd">1923</span> </span>
</div></li>
<li class="ref"><div class="citation" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle" id="ref-8">
<span class="citation-authors-year"><b><span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Dilawar</span> <span class="given-names" itemprop="givenName">N</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Majeed</span> <span class="given-names" itemprop="givenName">H</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Beg</span> <span class="given-names" itemprop="givenName">MO</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Ejaz</span> <span class="given-names" itemprop="givenName">N</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Muhammad</span> <span class="given-names" itemprop="givenName">K</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Mehmood</span> <span class="given-names" itemprop="givenName">I</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Nam</span> <span class="given-names" itemprop="givenName">Y</span></span>.</b> <b class="year" itemprop="datePublished">2018</b>.</span> <cite itemprop="name"><a class="article-title" target="_blank" itemprop="url" href="https://doi.org/10.3390%2Fapp8091589">Understanding citizen issues through reviews: a step towards data informed planning in smart cities</a>.</cite> <span><span class="issue" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/PublicationIssue"><span class="volume" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/PublicationVolume"><span class="source" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/Periodical"><span itemprop="name">Applied Sciences</span></span> <b itemprop="volumeNumber">8</b></span>(<span itemprop="issueNumber">9</span>)</span>:<span class="fpage" itemprop="pageStart">1589</span> </span>
</div></li>
<li class="ref"><div class="citation" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle" id="ref-9">
<span class="citation-authors-year"><b><span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Elhadad</span> <span class="given-names" itemprop="givenName">MK</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Badran</span> <span class="given-names" itemprop="givenName">KM</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Salama</span> <span class="given-names" itemprop="givenName">GI</span></span>.</b> <b class="year" itemprop="datePublished">2018</b>.</span> <cite itemprop="name"><a class="article-title" target="_blank" itemprop="url" href="https://scholar.google.com/scholar_lookup?title=A%20novel%20approach%20for%20ontology-based%20feature%20vector%20generation%20for%20web%20text%20document%20classification&amp;author=Elhadad&amp;publication_year=2018">A novel approach for ontology-based feature vector generation for web text document classification</a>.</cite> <span><span class="issue" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/PublicationIssue"><span class="volume" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/PublicationVolume"><span class="source" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/Periodical"><span itemprop="name">International Journal of Software Innovation</span></span> <b itemprop="volumeNumber">6</b></span>(<span itemprop="issueNumber">1</span>)</span>:<span class="fpage" itemprop="pageStart">1</span>-<span class="lpage" itemprop="pageEnd">10</span> </span>
</div></li>
<li class="ref"><div class="citation" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle" id="ref-10">
<span class="citation-authors-year"><b><span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Fiok</span> <span class="given-names" itemprop="givenName">K</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Karwowski</span> <span class="given-names" itemprop="givenName">W</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Gutierrez</span> <span class="given-names" itemprop="givenName">E</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Liciaga</span> <span class="given-names" itemprop="givenName">T</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Belmonte</span> <span class="given-names" itemprop="givenName">A</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Capobianco</span> <span class="given-names" itemprop="givenName">R</span></span>.</b> <b class="year" itemprop="datePublished">2021</b>.</span> <cite itemprop="name"><a class="article-title" target="_blank" itemprop="url" href="https://doi.org/10.3390%2Fapp11031294">Automated classification of evidence of respect in the communication through twitter</a>.</cite> <span><span class="issue" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/PublicationIssue"><span class="volume" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/PublicationVolume"><span class="source" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/Periodical"><span itemprop="name">Applied Sciences</span></span> <b itemprop="volumeNumber">11</b></span>(<span itemprop="issueNumber">3</span>)</span>:<span class="fpage" itemprop="pageStart">1294</span> </span>
</div></li>
<li class="ref"><div class="citation" itemprop="citation" itemscope="itemscope" id="ref-11">
<span class="citation-authors-year"><b><span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Geetha</span> <span class="given-names" itemprop="givenName">TVVJ</span></span>.</b> <b class="year" itemprop="datePublished">2020</b>.</span> <cite class="article-title"><a class="article-title" target="_blank" itemprop="url" href="https://scholar.google.com/scholar_lookup?title=Joint%20topical%20word%20embedding%20for%20detecting%20drift%20in%20social%20media%20text&amp;author=Geetha&amp;publication_year=2020">Joint topical word embedding for detecting drift in social media text</a>.</cite> <span>   </span>
</div></li>
<li class="ref"><div class="citation" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle" id="ref-12">
<span class="citation-authors-year"><b><span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Go</span> <span class="given-names" itemprop="givenName">A</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Bhayani</span> <span class="given-names" itemprop="givenName">R</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Huang</span> <span class="given-names" itemprop="givenName">L</span></span>.</b> <b class="year" itemprop="datePublished">2009</b>.</span> <cite itemprop="name"><a class="article-title" target="_blank" itemprop="url" href="https://scholar.google.com/scholar_lookup?title=Twitter%20sentiment%20classification%20using%20distant%20supervision&amp;author=Go&amp;publication_year=2009">Twitter sentiment classification using distant supervision</a>.</cite> <span><span class="issue" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/PublicationIssue"><span class="volume" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/PublicationVolume"><span class="source" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/Periodical"><span itemprop="name">CS224N Project Report, Stanford</span></span> <b itemprop="volumeNumber">1</b></span>(<span itemprop="issueNumber">12</span>)</span>:<span class="fpage" itemprop="pageStart">2009</span> </span>
</div></li>
<li class="ref"><div class="citation" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book" id="ref-13">
<span class="citation-authors-year"><b><span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Greene</span> <span class="given-names" itemprop="givenName">D</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">O’Callaghan</span> <span class="given-names" itemprop="givenName">D</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Cunningham</span> <span class="given-names" itemprop="givenName">P</span></span>.</b> <b class="year" itemprop="datePublished">2014</b>.</span> <cite class="article-title"><a class="article-title" target="_blank" itemprop="url" href="https://doi.org/10.1007%2F978-3-662-44848-9_32">Machine Learning and Knowledge Discovery in Databases. ECML PKDD 2014</a>.</cite> In: <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Calders</span> <span class="given-names" itemprop="givenName">T</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Esposito</span> <span class="given-names" itemprop="givenName">F</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Hüllermeier</span> <span class="given-names" itemprop="givenName">E</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Meo</span> <span class="given-names" itemprop="givenName">R</span></span>, eds. <span itemprop="name"><a class="source" target="_blank" href="https://scholar.google.com/scholar_lookup?title=Lecture%20Notes%20in%20Computer%20Science,%20vol.%208724&amp;author=Calders&amp;publication_year=2014">Lecture Notes in Computer Science, vol. 8724</a>.</span><span>  Berlin, Heidelberg: <span class="publisher">Springer</span>. <span class="fpage" itemprop="pageStart">498</span>-<span class="lpage" itemprop="pageEnd">513</span> </span>
</div></li>
<li class="ref"><div class="citation" itemprop="citation" itemscope="itemscope" id="ref-14">
<span class="citation-authors-year"><b><span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Imran</span> <span class="given-names" itemprop="givenName">M</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Elbassuoni</span> <span class="given-names" itemprop="givenName">S</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Castillo</span> <span class="given-names" itemprop="givenName">C</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Diaz</span> <span class="given-names" itemprop="givenName">F</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Meier</span> <span class="given-names" itemprop="givenName">P</span></span>.</b> <b class="year" itemprop="datePublished">2013</b>.</span> <cite class="article-title"><a class="article-title" target="_blank" itemprop="url" href="https://scholar.google.com/scholar_lookup?title=Practical%20extraction%20of%20disaster-relevant%20information%20from%20social%20media&amp;author=Imran&amp;publication_year=2013">Practical extraction of disaster-relevant information from social media</a>.</cite> In: <span itemprop="name"><a class="conf-name" target="_blank" href="https://scholar.google.com/scholar_lookup?title=Proceedings%20of%20the%2022nd%20international%20conference%20on%20world%20wide%20web&amp;author=&amp;publication_year=2013">Proceedings of the 22nd international conference on world wide web</a>.</span><span>   <span class="fpage" itemprop="pageStart">1021</span>-<span class="lpage" itemprop="pageEnd">1024</span> </span>
</div></li>
<li class="ref"><div class="citation" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle" id="ref-15">
<span class="citation-authors-year"><b><span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Karami</span> <span class="given-names" itemprop="givenName">A</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Shah</span> <span class="given-names" itemprop="givenName">V</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Vaezi</span> <span class="given-names" itemprop="givenName">R</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Bansal</span> <span class="given-names" itemprop="givenName">A</span></span>.</b> <b class="year" itemprop="datePublished">2020</b>.</span> <cite itemprop="name"><a class="article-title" target="_blank" itemprop="url" href="https://doi.org/10.1177%2F0165551519828620">Twitter speaks: a case of national disaster situational awareness</a>.</cite> <span><span class="issue" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/PublicationIssue"><span class="volume" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/PublicationVolume"><span class="source" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/Periodical"><span itemprop="name">Journal of Information Science</span></span> <b itemprop="volumeNumber">46</b></span>(<span itemprop="issueNumber">3</span>)</span>:<span class="fpage" itemprop="pageStart">313</span>-<span class="lpage" itemprop="pageEnd">324</span> </span>
</div></li>
<li class="ref"><div class="citation" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book" id="ref-16">
<span class="citation-authors-year"><b><span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Kim</span> <span class="given-names" itemprop="givenName">C</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Yin</span> <span class="given-names" itemprop="givenName">P</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Soto</span> <span class="given-names" itemprop="givenName">CX</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Blaby</span> <span class="given-names" itemprop="givenName">IK</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Yoo</span> <span class="given-names" itemprop="givenName">S</span></span>.</b> <b class="year" itemprop="datePublished">2018</b>.</span> <cite class="article-title"></cite> <span itemprop="name"><a class="source" target="_blank" href="https://scholar.google.com/scholar_lookup?title=Multimodal%20biological%20analysis%20using%20nlp%20and%20expression%20profile&amp;author=&amp;publication_year=2018">Multimodal biological analysis using nlp and expression profile</a>.</span><span>  Piscataway: <span class="publisher">IEEE</span>. <span class="fpage" itemprop="pageStart">1</span>-<span class="lpage" itemprop="pageEnd">4</span> </span>
</div></li>
<li class="ref"><div class="citation" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle" id="ref-17">
<span class="citation-authors-year"><b><span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Kim</span> <span class="given-names" itemprop="givenName">S</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Park</span> <span class="given-names" itemprop="givenName">H</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Lee</span> <span class="given-names" itemprop="givenName">J</span></span>.</b> <b class="year" itemprop="datePublished">2020</b>.</span> <cite itemprop="name"><a class="article-title" target="_blank" itemprop="url" href="https://doi.org/10.1016%2Fj.eswa.2020.113401">Word2vec-based latent semantic analysis (w2v-lsa) for topic modeling: a study on blockchain technology trend analysis</a>.</cite> <span><span class="volume" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/PublicationVolume"><span class="source" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/Periodical"><span itemprop="name">Expert Systems with Applications</span></span> <b itemprop="volumeNumber">152</b></span>:<span class="fpage" itemprop="pageStart">113401</span> </span>
</div></li>
<li class="ref"><div class="citation" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle" id="ref-18">
<span class="citation-authors-year"><b><span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Kralj Novak</span> <span class="given-names" itemprop="givenName">P</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Smailović</span> <span class="given-names" itemprop="givenName">J</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Sluban</span> <span class="given-names" itemprop="givenName">B</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Mozetič</span> <span class="given-names" itemprop="givenName">I</span></span>.</b> <b class="year" itemprop="datePublished">2015</b>.</span> <cite itemprop="name"><a class="article-title" target="_blank" itemprop="url" href="https://doi.org/10.1371%2Fjournal.pone.0144296">Sentiment of emojis</a>.</cite> <span><span class="issue" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/PublicationIssue"><span class="volume" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/PublicationVolume"><span class="source" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/Periodical"><span itemprop="name">PLOS ONE</span></span> <b itemprop="volumeNumber">10</b></span>(<span itemprop="issueNumber">12</span>)</span>:<span class="elocation-id" itemprop="pageStart">e0144296</span> </span>
</div></li>
<li class="ref"><div class="citation" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle" id="ref-19">
<span class="citation-authors-year"><b><span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Kurnia</span> <span class="given-names" itemprop="givenName">R</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Tangkuman</span> <span class="given-names" itemprop="givenName">Y</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Girsang</span> <span class="given-names" itemprop="givenName">A</span></span>.</b> <b class="year" itemprop="datePublished">2020</b>.</span> <cite itemprop="name"><a class="article-title" target="_blank" itemprop="url" href="https://doi.org/10.30534%2Fijatcse%2F2020%2F90912020">Classification of user comment using word2vec and svm classifier</a>.</cite> <span><span class="volume" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/PublicationVolume"><span class="source" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/Periodical"><span itemprop="name">International Journal of Advanced Trends in Computer Science and Engineering</span></span> <b itemprop="volumeNumber">9</b></span>:<span class="fpage" itemprop="pageStart">643</span>-<span class="lpage" itemprop="pageEnd">648</span> </span>
</div></li>
<li class="ref"><div class="citation" itemprop="citation" itemscope="itemscope" id="ref-20">
<span class="citation-authors-year"><b><span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Kusner</span> <span class="given-names" itemprop="givenName">MJ</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Sun</span> <span class="given-names" itemprop="givenName">Y</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Kolkin</span> <span class="given-names" itemprop="givenName">NI</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Weinberger</span> <span class="given-names" itemprop="givenName">KQ</span></span>.</b> <b class="year" itemprop="datePublished">2015</b>.</span> <cite class="article-title"><a class="article-title" target="_blank" itemprop="url" href="https://scholar.google.com/scholar_lookup?title=From%20word%20embeddings%20to%20document%20distances&amp;author=Kusner&amp;publication_year=2015">From word embeddings to document distances</a>.</cite> In: <span itemprop="name"><a class="conf-name" target="_blank" href="https://scholar.google.com/scholar_lookup?title=Proceedings%20of%20the%2032nd%20international%20conference%20on%20international%20conference%20on%20machine%20learning%20-%20Volume%2037,%20ICML%E2%80%9915&amp;author=&amp;publication_year=2015">Proceedings of the 32nd international conference on international conference on machine learning - Volume 37, ICML’15</a>.</span><span> <span class="conf-sponsor">JMLR.org</span>.   <span class="fpage" itemprop="pageStart">957</span>-<span class="lpage" itemprop="pageEnd">966</span> </span>
</div></li>
<li class="ref"><div class="citation" itemprop="citation" itemscope="itemscope" id="ref-21">
<span class="citation-authors-year"><b><span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Le</span> <span class="given-names" itemprop="givenName">Q</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Mikolov</span> <span class="given-names" itemprop="givenName">T</span></span>.</b> <b class="year" itemprop="datePublished">2014</b>.</span> <cite class="article-title"><a class="article-title" target="_blank" itemprop="url" href="https://scholar.google.com/scholar_lookup?title=Distributed%20representations%20of%20sentences%20and%20documents&amp;author=Le&amp;publication_year=2014">Distributed representations of sentences and documents</a>.</cite> In: <span itemprop="name"><a class="conf-name" target="_blank" href="https://scholar.google.com/scholar_lookup?title=International%20conference%20on%20machine%20learning&amp;author=&amp;publication_year=2014">International conference on machine learning</a>.</span><span> <span class="conf-sponsor">PMLR</span>.   <span class="fpage" itemprop="pageStart">1188</span>-<span class="lpage" itemprop="pageEnd">1196</span> </span>
</div></li>
<li class="ref"><div class="citation" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle" id="ref-22">
<span class="citation-authors-year"><b><span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Li</span> <span class="given-names" itemprop="givenName">L</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Zhang</span> <span class="given-names" itemprop="givenName">Q</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Wang</span> <span class="given-names" itemprop="givenName">X</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Zhang</span> <span class="given-names" itemprop="givenName">J</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Wang</span> <span class="given-names" itemprop="givenName">T</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Gao</span> <span class="given-names" itemprop="givenName">T</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Duan</span> <span class="given-names" itemprop="givenName">W</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Tsoi</span> <span class="given-names" itemprop="givenName">KK</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Wang</span> <span class="given-names" itemprop="givenName">F</span></span>.</b> <b class="year" itemprop="datePublished">2020</b>.</span> <cite itemprop="name"><a class="article-title" target="_blank" itemprop="url" href="https://doi.org/10.1109%2FTCSS.2020.2980007">Characterizing the propagation of situational information in social media during covid-19 epidemic: a case study on weibo</a>.</cite> <span><span class="issue" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/PublicationIssue"><span class="volume" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/PublicationVolume"><span class="source" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/Periodical"><span itemprop="name">IEEE Transactions on Computational Social Systems</span></span> <b itemprop="volumeNumber">7</b></span>(<span itemprop="issueNumber">2</span>)</span>:<span class="fpage" itemprop="pageStart">556</span>-<span class="lpage" itemprop="pageEnd">562</span> </span>
</div></li>
<li class="ref"><div class="citation" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle" id="ref-23">
<span class="citation-authors-year"><b><span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Li</span> <span class="given-names" itemprop="givenName">W</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Suzuki</span> <span class="given-names" itemprop="givenName">E</span></span>.</b> <b class="year" itemprop="datePublished">2021</b>.</span> <cite itemprop="name"><a class="article-title" target="_blank" itemprop="url" href="https://doi.org/10.1016%2Fj.ipm.2021.102592">Adaptive and hybrid context-aware fine-grained word sense disambiguation in topic modeling based document representation</a>.</cite> <span><span class="issue" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/PublicationIssue"><span class="volume" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/PublicationVolume"><span class="source" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/Periodical"><span itemprop="name">Information Processing and Management</span></span> <b itemprop="volumeNumber">58</b></span>(<span itemprop="issueNumber">4</span>)</span>:<span class="fpage" itemprop="pageStart">102592</span> </span>
</div></li>
<li class="ref"><div class="citation" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle" id="ref-24">
<span class="citation-authors-year"><b><span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Liu</span> <span class="given-names" itemprop="givenName">S</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Lee</span> <span class="given-names" itemprop="givenName">K</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Lee</span> <span class="given-names" itemprop="givenName">I</span></span>.</b> <b class="year" itemprop="datePublished">2020</b>.</span> <cite itemprop="name"><a class="article-title" target="_blank" itemprop="url" href="https://doi.org/10.1016%2Fj.knosys.2020.105918">Document-level multi-topic sentiment classification of email data with bilstm and data augmentation</a>.</cite> <span><span class="volume" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/PublicationVolume"><span class="source" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/Periodical"><span itemprop="name">Knowledge-Based Systems</span></span> <b itemprop="volumeNumber">197</b></span>:<span class="fpage" itemprop="pageStart">105918</span> </span>
</div></li>
<li class="ref"><div class="citation" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle" id="ref-25">
<span class="citation-authors-year"><b><span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Luo</span> <span class="given-names" itemprop="givenName">X</span></span>.</b> <b class="year" itemprop="datePublished">2021</b>.</span> <cite itemprop="name"><a class="article-title" target="_blank" itemprop="url" href="https://doi.org/10.1016%2Fj.aej.2021.02.009">Efficient english text classification using selected machine learning techniques</a>.</cite> <span><span class="issue" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/PublicationIssue"><span class="volume" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/PublicationVolume"><span class="source" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/Periodical"><span itemprop="name">AlexandRia Engineering Journal</span></span> <b itemprop="volumeNumber">60</b></span>(<span itemprop="issueNumber">3</span>)</span>:<span class="fpage" itemprop="pageStart">3401</span>-<span class="lpage" itemprop="pageEnd">3409</span> </span>
</div></li>
<li class="ref"><div class="citation" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle" id="ref-26">
<span class="citation-authors-year"><b><span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Masood</span> <span class="given-names" itemprop="givenName">MA</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Abbasi</span> <span class="given-names" itemprop="givenName">RA</span></span>.</b> <b class="year" itemprop="datePublished">2021</b>.</span> <cite itemprop="name"><a class="article-title" target="_blank" itemprop="url" href="https://doi.org/10.1016%2Fj.joi.2020.101121">Using graph embedding and machine learning to identify rebels on twitter</a>.</cite> <span><span class="issue" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/PublicationIssue"><span class="volume" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/PublicationVolume"><span class="source" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/Periodical"><span itemprop="name">Journal of Informetrics</span></span> <b itemprop="volumeNumber">15</b></span>(<span itemprop="issueNumber">1</span>)</span>:<span class="fpage" itemprop="pageStart">101121</span> </span>
</div></li>
<li class="ref"><div class="citation" itemprop="citation" itemscope="itemscope" id="ref-27">
<span class="citation-authors-year"><b><span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">McAuley</span> <span class="given-names" itemprop="givenName">JJ</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Leskovec</span> <span class="given-names" itemprop="givenName">J</span></span>.</b> <b class="year" itemprop="datePublished">2013</b>.</span> <cite class="article-title"><a class="article-title" target="_blank" itemprop="url" href="https://scholar.google.com/scholar_lookup?title=From%20amateurs%20to%20connoisseurs:%20modeling%20the%20evolution%20of%20user%20expertise%20through%20online%20reviews&amp;author=McAuley&amp;publication_year=2013">From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews</a>.</cite> In: <span itemprop="name"><a class="conf-name" target="_blank" href="https://scholar.google.com/scholar_lookup?title=Proceedings%20of%20the%2022nd%20international%20conference%20on%20World%20Wide%20Web&amp;author=&amp;publication_year=2013">Proceedings of the 22nd international conference on World Wide Web</a>.</span><span>   <span class="fpage" itemprop="pageStart">897</span>-<span class="lpage" itemprop="pageEnd">908</span> </span>
</div></li>
<li class="ref"><div class="citation" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle" id="ref-28">
<span class="citation-authors-year"><b><span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">McNemar</span> <span class="given-names" itemprop="givenName">Q</span></span>.</b> <b class="year" itemprop="datePublished">1947</b>.</span> <cite itemprop="name"><a class="article-title" target="_blank" itemprop="url" href="https://doi.org/10.1007%2FBF02295996">Note on the sampling error of the difference between correlated proportions or percentages</a>.</cite> <span><span class="issue" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/PublicationIssue"><span class="volume" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/PublicationVolume"><span class="source" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/Periodical"><span itemprop="name">Psychometrika</span></span> <b itemprop="volumeNumber">12</b></span>(<span itemprop="issueNumber">2</span>)</span>:<span class="fpage" itemprop="pageStart">153</span>-<span class="lpage" itemprop="pageEnd">157</span> </span>
</div></li>
<li class="ref"><div class="citation" itemprop="citation" itemscope="itemscope" id="ref-29">
<span class="citation-authors-year"><b><span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Meng</span> <span class="given-names" itemprop="givenName">Y</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Zhang</span> <span class="given-names" itemprop="givenName">Y</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Huang</span> <span class="given-names" itemprop="givenName">J</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Xiong</span> <span class="given-names" itemprop="givenName">C</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Ji</span> <span class="given-names" itemprop="givenName">H</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Zhang</span> <span class="given-names" itemprop="givenName">C</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Han</span> <span class="given-names" itemprop="givenName">J</span></span>.</b> <b class="year" itemprop="datePublished">2020</b>.</span> <cite class="article-title"><a class="article-title" target="_blank" itemprop="url" href="http://arxiv.org/abs/2010.07245">Text classification using label names only: a language model self-training approach</a>.</cite> </div></li>
<li class="ref"><div class="citation" itemprop="citation" itemscope="itemscope" id="ref-30">
<span class="citation-authors-year"><b><span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Mitroi</span> <span class="given-names" itemprop="givenName">M</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Truic</span> <span class="given-names" itemprop="givenName">C-O</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Apostol</span> <span class="given-names" itemprop="givenName">E-S</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Florea</span> <span class="given-names" itemprop="givenName">AM</span></span>.</b> <b class="year" itemprop="datePublished">2020</b>.</span> <cite class="article-title"><a class="article-title" target="_blank" itemprop="url" href="https://scholar.google.com/scholar_lookup?title=Sentiment%20analysis%20using%20topic-document%20embeddings&amp;author=Mitroi&amp;publication_year=2020">Sentiment analysis using topic-document embeddings</a>.</cite> In: <span itemprop="name"><a class="conf-name" target="_blank" href="https://scholar.google.com/scholar_lookup?title=2020%20IEEE%2016th%20international%20conference%20on%20intelligent%20computer%20communication%20and%20processing%20(ICCP)&amp;author=&amp;publication_year=2020">2020 IEEE 16th international conference on intelligent computer communication and processing (ICCP)</a>.</span><span> <span class="conf-loc">Piscataway</span>. <span class="conf-sponsor">IEEE</span>.   <span class="fpage" itemprop="pageStart">75</span>-<span class="lpage" itemprop="pageEnd">82</span> </span>
</div></li>
<li class="ref"><div class="citation" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle" id="ref-31">
<span class="citation-authors-year"><b><span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Mutanga</span> <span class="given-names" itemprop="givenName">MB</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Abayomi</span> <span class="given-names" itemprop="givenName">A</span></span>.</b> <b class="year" itemprop="datePublished">2020</b>.</span> <cite itemprop="name"><a class="article-title" target="_blank" itemprop="url" href="https://scholar.google.com/scholar_lookup?title=Tweeting%20on%20covid-19%20pandemic%20in%20south%20africa:%20Lda-based%20topic%20modelling%20approach&amp;author=Mutanga&amp;publication_year=2020">Tweeting on covid-19 pandemic in south africa: Lda-based topic modelling approach</a>.</cite> <span><span class="source" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/Periodical"><span itemprop="name">African Journal of Science, Technology, Innovation and Development</span></span>   <span class="comment">Epub ahead of print Oct 20 2020</span></span>
</div></li>
<li class="ref"><div class="citation" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle" id="ref-32">
<span class="citation-authors-year"><b><span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Nam</span> <span class="given-names" itemprop="givenName">M</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Lee</span> <span class="given-names" itemprop="givenName">E</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Shin</span> <span class="given-names" itemprop="givenName">J</span></span>.</b> <b class="year" itemprop="datePublished">2015</b>.</span> <cite itemprop="name"><a class="article-title" target="_blank" itemprop="url" href="https://doi.org/10.9717%2Fkmms.2015.18.11.1391">A method for user sentiment classification using instagram hashtags</a>.</cite> <span><span class="issue" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/PublicationIssue"><span class="volume" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/PublicationVolume"><span class="source" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/Periodical"><span itemprop="name">Journal of Korea Multimedia Society</span></span> <b itemprop="volumeNumber">18</b></span>(<span itemprop="issueNumber">11</span>)</span>:<span class="fpage" itemprop="pageStart">1391</span>-<span class="lpage" itemprop="pageEnd">1399</span> </span>
</div></li>
<li class="ref"><div class="citation" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book" id="ref-33">
<span class="citation-authors-year"><b><span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Niraula</span> <span class="given-names" itemprop="givenName">N</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Banjade</span> <span class="given-names" itemprop="givenName">R</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Ştefănescu</span> <span class="given-names" itemprop="givenName">D</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Rus</span> <span class="given-names" itemprop="givenName">V</span></span>.</b> <b class="year" itemprop="datePublished">2013</b>.</span> <cite class="article-title"><a class="article-title" target="_blank" itemprop="url" href="https://doi.org/10.1007%2F978-3-642-39593-2_17">Experiments with Semantic Similarity Measures Based on LDA and LSA</a>.</cite> In: <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Dediu</span> <span class="given-names" itemprop="givenName">AH</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Martn-Vide</span> <span class="given-names" itemprop="givenName">C</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Mitkov</span> <span class="given-names" itemprop="givenName">R</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Truthe</span> <span class="given-names" itemprop="givenName">B</span></span>, eds. <span itemprop="name"><a class="source" target="_blank" href="https://scholar.google.com/scholar_lookup?title=Statistical%20Language%20and%20Speech%20Processing.%20SLSP%202013.%20Lecture%20Notes%20in%20Computer%20Science,%20vol,%207978&amp;author=Dediu&amp;publication_year=2013">Statistical Language and Speech Processing. SLSP 2013. Lecture Notes in Computer Science, vol, 7978</a>.</span><span>  Berlin, Heidelberg: <span class="publisher">Springer</span>.  </span>
</div></li>
<li class="ref"><div class="citation" itemprop="citation" itemscope="itemscope" id="ref-34">
<span class="citation-authors-year"><b><span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Olteanu</span> <span class="given-names" itemprop="givenName">A</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Castillo</span> <span class="given-names" itemprop="givenName">C</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Diaz</span> <span class="given-names" itemprop="givenName">F</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Vieweg</span> <span class="given-names" itemprop="givenName">S</span></span>.</b> <b class="year" itemprop="datePublished">2014</b>.</span> <cite class="article-title"><a class="article-title" target="_blank" itemprop="url" href="https://scholar.google.com/scholar_lookup?title=Crisislex:%20a%20lexicon%20for%20collecting%20and%20filtering%20microblogged%20communications%20in%20crises&amp;author=Olteanu&amp;publication_year=2014">Crisislex: a lexicon for collecting and filtering microblogged communications in crises</a>.</cite> In: <span itemprop="name"><a class="conf-name" target="_blank" href="https://scholar.google.com/scholar_lookup?title=Proceedings%20of%20the%20international%20AAAI%20conference%20on%20web%20and%20social%20media,%20volume%208&amp;author=&amp;publication_year=2014">Proceedings of the international AAAI conference on web and social media, volume 8</a>.</span><span>    </span>
</div></li>
<li class="ref"><div class="citation" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle" id="ref-35">
<span class="citation-authors-year"><b><span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Pavlinek</span> <span class="given-names" itemprop="givenName">M</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Podgorelec</span> <span class="given-names" itemprop="givenName">V</span></span>.</b> <b class="year" itemprop="datePublished">2017</b>.</span> <cite itemprop="name"><a class="article-title" target="_blank" itemprop="url" href="https://doi.org/10.1016%2Fj.eswa.2017.03.020">Text classification method based on self-training and lda topic models</a>.</cite> <span><span class="volume" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/PublicationVolume"><span class="source" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/Periodical"><span itemprop="name">Expert Systems with Applications</span></span> <b itemprop="volumeNumber">80</b></span>:<span class="fpage" itemprop="pageStart">83</span>-<span class="lpage" itemprop="pageEnd">93</span> </span>
</div></li>
<li class="ref"><div class="citation" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle" id="ref-36">
<span class="citation-authors-year"><b><span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Rangel</span> <span class="given-names" itemprop="givenName">F</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Rosso</span> <span class="given-names" itemprop="givenName">P</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Verhoeven</span> <span class="given-names" itemprop="givenName">B</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Daelemans</span> <span class="given-names" itemprop="givenName">W</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Potthast</span> <span class="given-names" itemprop="givenName">M</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Stein</span> <span class="given-names" itemprop="givenName">B</span></span>.</b> <b class="year" itemprop="datePublished">2016</b>.</span> <cite itemprop="name"><a class="article-title" target="_blank" itemprop="url" href="https://scholar.google.com/scholar_lookup?title=Overview%20of%20the%204th%20author%20profiling%20task%20at%20pan%202016:%20cross-genre%20evaluations&amp;author=Rangel&amp;publication_year=2016">Overview of the 4th author profiling task at pan 2016: cross-genre evaluations</a>.</cite> <span><span class="volume" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/PublicationVolume"><span class="source" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/Periodical"><span itemprop="name">Working Notes Papers of the CLEF</span></span> <b itemprop="volumeNumber">2016</b></span>:<span class="fpage" itemprop="pageStart">750</span>-<span class="lpage" itemprop="pageEnd">784</span> </span>
</div></li>
<li class="ref"><div class="citation" itemprop="citation" itemscope="itemscope" id="ref-37">
<span class="citation-authors-year"><b><span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Rousseau</span> <span class="given-names" itemprop="givenName">F</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Kiagias</span> <span class="given-names" itemprop="givenName">E</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Vazirgiannis</span> <span class="given-names" itemprop="givenName">M</span></span>.</b> <b class="year" itemprop="datePublished">2015</b>.</span> <cite class="article-title"><a class="article-title" target="_blank" itemprop="url" href="https://scholar.google.com/scholar_lookup?title=Text%20categorization%20as%20a%20graph%20classification%20problem&amp;author=Rousseau&amp;publication_year=2015">Text categorization as a graph classification problem</a>.</cite> In: <span itemprop="name"><a class="conf-name" target="_blank" href="https://scholar.google.com/scholar_lookup?title=Proceedings%20of%20the%2053rd%20annual%20meeting%20of%20the%20association%20for%20computational%20linguistics%20and%20the%207th%20international%20joint%20conference%20on%20natural%20language%20processing%20(Volume%201:%20Long%20Papers)&amp;author=&amp;publication_year=2015">Proceedings of the 53rd annual meeting of the association for computational linguistics and the 7th international joint conference on natural language processing (Volume 1: Long Papers)</a>.</span><span>   <span class="fpage" itemprop="pageStart">1702</span>-<span class="lpage" itemprop="pageEnd">1712</span> </span>
</div></li>
<li class="ref"><div class="citation" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle" id="ref-38">
<span class="citation-authors-year"><b><span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Shen</span> <span class="given-names" itemprop="givenName">J</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Ma</span> <span class="given-names" itemprop="givenName">MD</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Xiang</span> <span class="given-names" itemprop="givenName">R</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Lu</span> <span class="given-names" itemprop="givenName">Q</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Vallejos</span> <span class="given-names" itemprop="givenName">EP</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Xu</span> <span class="given-names" itemprop="givenName">G</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Huang</span> <span class="given-names" itemprop="givenName">C-R</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Long</span> <span class="given-names" itemprop="givenName">Y</span></span>.</b> <b class="year" itemprop="datePublished">2020</b>.</span> <cite itemprop="name"><a class="article-title" target="_blank" itemprop="url" href="https://doi.org/10.1016%2Fj.knosys.2019.105004">Dual memory network model for sentiment analysis of review text</a>.</cite> <span><span class="volume" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/PublicationVolume"><span class="source" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/Periodical"><span itemprop="name">Knowledge-Based Systems</span></span> <b itemprop="volumeNumber">188</b></span>:<span class="fpage" itemprop="pageStart">105004</span> </span>
</div></li>
<li class="ref"><div class="citation" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle" id="ref-49">
<span class="citation-authors-year"><b><span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Škrlj</span> <span class="given-names" itemprop="givenName">B</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Martinc</span> <span class="given-names" itemprop="givenName">M</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Kralj</span> <span class="given-names" itemprop="givenName">J</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Lavra</span> <span class="given-names" itemprop="givenName">N</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Pollak</span> <span class="given-names" itemprop="givenName">S</span></span>.</b> <b class="year" itemprop="datePublished">2021</b>.</span> <cite itemprop="name"><a class="article-title" target="_blank" itemprop="url" href="https://doi.org/10.1016%2Fj.csl.2020.101104">tax2vec: constructing interpretable features from taxonomies for short text classification</a>.</cite> <span><span class="volume" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/PublicationVolume"><span class="source" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/Periodical"><span itemprop="name">Computer Speech &amp; Language</span></span> <b itemprop="volumeNumber">65</b></span>:<span class="fpage" itemprop="pageStart">101104</span> </span>
</div></li>
<li class="ref"><div class="citation" itemprop="citation" itemscope="itemscope" id="ref-39">
<span class="citation-authors-year"><b><span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Sokolova</span> <span class="given-names" itemprop="givenName">M</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Huang</span> <span class="given-names" itemprop="givenName">K</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Matwin</span> <span class="given-names" itemprop="givenName">S</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Ramisch</span> <span class="given-names" itemprop="givenName">J</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Sazonova</span> <span class="given-names" itemprop="givenName">V</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Black</span> <span class="given-names" itemprop="givenName">R</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Orwa</span> <span class="given-names" itemprop="givenName">C</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Ochieng</span> <span class="given-names" itemprop="givenName">S</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Sambuli</span> <span class="given-names" itemprop="givenName">N</span></span>.</b> <b class="year" itemprop="datePublished">2016</b>.</span> <cite class="article-title"><a class="article-title" target="_blank" itemprop="url" href="http://arxiv.org/abs/1608.02519">Topic modelling and event identification from Twitter textual data</a>.</cite> </div></li>
<li class="ref"><div class="citation" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle" id="ref-40">
<span class="citation-authors-year"><b><span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Spina</span> <span class="given-names" itemprop="givenName">G</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Casale</span> <span class="given-names" itemprop="givenName">P</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Albert</span> <span class="given-names" itemprop="givenName">PS</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Alison</span> <span class="given-names" itemprop="givenName">J</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Garcia-Aymerich</span> <span class="given-names" itemprop="givenName">J</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Clarenbach</span> <span class="given-names" itemprop="givenName">CF</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Costello</span> <span class="given-names" itemprop="givenName">RW</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Hernandes</span> <span class="given-names" itemprop="givenName">NA</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Leuppi</span> <span class="given-names" itemprop="givenName">JD</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Mesquita</span> <span class="given-names" itemprop="givenName">R</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Singh</span> <span class="given-names" itemprop="givenName">SJ</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Smeenk</span> <span class="given-names" itemprop="givenName">FW</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Tal-Singer</span> <span class="given-names" itemprop="givenName">R</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Wouters</span> <span class="given-names" itemprop="givenName">EF</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Spruit</span> <span class="given-names" itemprop="givenName">MA</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">den Brinker</span> <span class="given-names" itemprop="givenName">AC</span></span>.</b> <b class="year" itemprop="datePublished">2021</b>.</span> <cite itemprop="name"><a class="article-title" target="_blank" itemprop="url" href="https://doi.org/10.1016%2Fj.compbiomed.2021.104322">Nighttime features derived from topic models for classification of patients with COPD</a>.</cite> <span><span class="volume" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/PublicationVolume"><span class="source" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/Periodical"><span itemprop="name">Computers in Biology and Medicine</span></span> <b itemprop="volumeNumber">132</b></span>:<span class="fpage" itemprop="pageStart">104322</span> </span>
</div></li>
<li class="ref"><div class="citation" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle" id="ref-41">
<span class="citation-authors-year"><b><span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Sriurai</span> <span class="given-names" itemprop="givenName">W</span></span>.</b> <b class="year" itemprop="datePublished">2011</b>.</span> <cite itemprop="name"><a class="article-title" target="_blank" itemprop="url" href="https://scholar.google.com/scholar_lookup?title=Improving%20text%20categorization%20by%20using%20a%20topic%20model&amp;author=Sriurai&amp;publication_year=2011">Improving text categorization by using a topic model</a>.</cite> <span><span class="issue" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/PublicationIssue"><span class="volume" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/PublicationVolume"><span class="source" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/Periodical"><span itemprop="name">Advanced Computing</span></span> <b itemprop="volumeNumber">2</b></span>(<span itemprop="issueNumber">6</span>)</span>:<span class="fpage" itemprop="pageStart">21</span> </span>
</div></li>
<li class="ref"><div class="citation" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book" id="ref-42">
<span class="citation-authors-year"><b><span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Tomašev</span> <span class="given-names" itemprop="givenName">N</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Buza</span> <span class="given-names" itemprop="givenName">K</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Marussy</span> <span class="given-names" itemprop="givenName">K</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Kis</span> <span class="given-names" itemprop="givenName">PB</span></span>.</b> <b class="year" itemprop="datePublished">2015</b>.</span> <cite class="article-title"><a class="article-title" target="_blank" itemprop="url" href="https://scholar.google.com/scholar_lookup?title=Hubness-Aware%20classification&amp;author=Toma%C5%A1ev&amp;publication_year=2015">Hubness-Aware classification</a>.</cite> In: <span itemprop="name"><a class="source" target="_blank" href="https://scholar.google.com/scholar_lookup?title=Instance%20selection%20and%20feature%20construction:%20survey%20and%20extensions%20to%20time-series&amp;author=&amp;publication_year=2015">Instance selection and feature construction: survey and extensions to time-series</a>.</span><span>  <span class="fpage" itemprop="pageStart">231</span>-<span class="lpage" itemprop="pageEnd">262</span> </span>
</div></li>
<li class="ref"><div class="citation" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle" id="ref-43">
<span class="citation-authors-year"><b><span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Ullah</span> <span class="given-names" itemprop="givenName">MA</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Marium</span> <span class="given-names" itemprop="givenName">SM</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Begum</span> <span class="given-names" itemprop="givenName">SA</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Dipa</span> <span class="given-names" itemprop="givenName">NS</span></span>.</b> <b class="year" itemprop="datePublished">2020</b>.</span> <cite itemprop="name"><a class="article-title" target="_blank" itemprop="url" href="https://doi.org/10.1016%2Fj.icte.2020.07.003">An algorithm and method for sentiment analysis using the text and emoticon</a>.</cite> <span><span class="issue" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/PublicationIssue"><span class="volume" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/PublicationVolume"><span class="source" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/Periodical"><span itemprop="name">ICT Express</span></span> <b itemprop="volumeNumber">6</b></span>(<span itemprop="issueNumber">4</span>)</span>:<span class="fpage" itemprop="pageStart">357</span>-<span class="lpage" itemprop="pageEnd">360</span> </span>
</div></li>
<li class="ref"><div class="citation" itemprop="citation" itemscope="itemscope" id="ref-44">
<span class="citation-authors-year"><b><span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Wan</span> <span class="given-names" itemprop="givenName">X</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Wang</span> <span class="given-names" itemprop="givenName">T</span></span>.</b> <b class="year" itemprop="datePublished">2016</b>.</span> <cite class="article-title"><a class="article-title" target="_blank" itemprop="url" href="https://scholar.google.com/scholar_lookup?title=Automatic%20labeling%20of%20topic%20models%20using%20text%20summaries&amp;author=Wan&amp;publication_year=2016">Automatic labeling of topic models using text summaries</a>.</cite> In: <span itemprop="name"><a class="conf-name" target="_blank" href="https://scholar.google.com/scholar_lookup?title=Proceedings%20of%20the%2054th%20annual%20meeting%20of%20the%20association%20for%20computational%20linguistics%20(Volume%201:%20Long%20Papers)&amp;author=&amp;publication_year=2016">Proceedings of the 54th annual meeting of the association for computational linguistics (Volume 1: Long Papers)</a>.</span><span>   <span class="fpage" itemprop="pageStart">2297</span>-<span class="lpage" itemprop="pageEnd">2305</span> </span>
</div></li>
<li class="ref"><div class="citation" itemprop="citation" itemscope="itemscope" id="ref-45">
<span class="citation-authors-year"><b><span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Wang</span> <span class="given-names" itemprop="givenName">C</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Paisley</span> <span class="given-names" itemprop="givenName">J</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Blei</span> <span class="given-names" itemprop="givenName">D</span></span>.</b> <b class="year" itemprop="datePublished">2011</b>.</span> <cite class="article-title"><a class="article-title" target="_blank" itemprop="url" href="https://scholar.google.com/scholar_lookup?title=Online%20variational%20inference%20for%20the%20hierarchical%20dirichlet%20process&amp;author=Wang&amp;publication_year=2011">Online variational inference for the hierarchical dirichlet process</a>.</cite> In: <span itemprop="name"><a class="conf-name" target="_blank" href="https://scholar.google.com/scholar_lookup?title=Proceedings%20of%20the%20fourteenth%20international%20conference%20on%20artificial%20intelligence%20and%20statistics&amp;author=&amp;publication_year=2011">Proceedings of the fourteenth international conference on artificial intelligence and statistics</a>.</span><span> <span class="conf-sponsor">JMLR Workshop and Conference Proceedings</span>.   <span class="fpage" itemprop="pageStart">752</span>-<span class="lpage" itemprop="pageEnd">760</span> </span>
</div></li>
<li class="ref"><div class="citation" itemprop="citation" itemscope="itemscope" id="ref-46">
<span class="citation-authors-year"><b><span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Xie</span> <span class="given-names" itemprop="givenName">P</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Xing</span> <span class="given-names" itemprop="givenName">EP</span></span>.</b> <b class="year" itemprop="datePublished">2013</b>.</span> <cite class="article-title"></cite> <span class="source">Integrating document clustering and topic modeling</span>. </div></li>
<li class="ref"><div class="citation" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle" id="ref-47">
<span class="citation-authors-year"><b><span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Yun</span> <span class="given-names" itemprop="givenName">J</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Geum</span> <span class="given-names" itemprop="givenName">Y</span></span>.</b> <b class="year" itemprop="datePublished">2020</b>.</span> <cite itemprop="name"><a class="article-title" target="_blank" itemprop="url" href="https://doi.org/10.1016%2Fj.cie.2020.106636">Automated classification of patents: a topic modeling approach</a>.</cite> <span><span class="volume" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/PublicationVolume"><span class="source" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/Periodical"><span itemprop="name">Computers &amp; Industrial Engineering</span></span> <b itemprop="volumeNumber">147</b></span>:<span class="fpage" itemprop="pageStart">106636</span> </span>
</div></li>
<li class="ref"><div class="citation" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle" id="ref-48">
<span class="citation-authors-year"><b><span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Zhao</span> <span class="given-names" itemprop="givenName">X</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Wang</span> <span class="given-names" itemprop="givenName">D</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Zhao</span> <span class="given-names" itemprop="givenName">Z</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Liu</span> <span class="given-names" itemprop="givenName">W</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Lu</span> <span class="given-names" itemprop="givenName">C</span></span>, <span class="name" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span class="surname" itemprop="familyName">Zhuang</span> <span class="given-names" itemprop="givenName">F</span></span>.</b> <b class="year" itemprop="datePublished">2021</b>.</span> <cite itemprop="name"><a class="article-title" target="_blank" itemprop="url" href="https://doi.org/10.1016%2Fj.ipm.2020.102455">A neural topic model with word vectors and entity vectors for short texts</a>.</cite> <span><span class="issue" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/PublicationIssue"><span class="volume" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/PublicationVolume"><span class="source" itemprop="isPartOf" itemscope="itemscope" itemtype="http://schema.org/Periodical"><span itemprop="name">Information Processing &amp; Management</span></span> <b itemprop="volumeNumber">58</b></span>(<span itemprop="issueNumber">2</span>)</span>:<span class="fpage" itemprop="pageStart">102455</span> </span>
</div></li>
</ul></section>
   </footer></article>
            </div>

            <div id="related-research"></div>

            <!-- annotations -->
            <ul class="nav nav-tabs annotation-tabs-nav">
                <li class="active"><a href="#questions" data-toggle="tab"><i class="icon-comments"></i> Questions
                        <span class="annotation-counter annotation-counter-questioning"></span></a></li>
                <li><a href="#links" data-toggle="tab"><i class="icon-link"></i> Links
                        <span class="annotation-counter annotation-counter-linking"></span></a></li>
            </ul>

            <div class="tab-content annotation-tab-content">
                <div class="tab-pane active" id="questions">
                    <div class="annotations" id="questions" data-target="articles/cs-677" data-counts="1">
    <div class="row-fluid row-article-item-section">
        <div class="span1 article-main-left-span1">&nbsp;</div>
        <div class="span11 article-item-section-content">
            
            <div>
                <a rel="nofollow" class="annotation-loader"
                   href="/questions/index.html?target=articles/cs-677&amp;_sort=score">Questions</a>
            </div>

                            <a class="btn btn-primary annotation-create-button add-annotation"
                   id="annotation-create-question"
                   data-toggle="annotation-form"
                   data-target="#annotation-question-create-container"
                   rel="nofollow"
                   href="/questions.form?format=html&amp;target=articles/cs-677&amp;_counts=1"><i class="icon-plus"></i> Ask a question</a>
                <div class="help-block annotation-learn-more"><a href="/contributions/about/" target="_blank">Learn more about Q&amp;A</a></div>
                <div class="annotation-form-container"
                     id="annotation-question-create-container"></div>
                    </div>
    </div>
</div>
                </div>

                <div class="tab-pane" id="links">
                    <div class="annotations" id="links" data-target="articles/cs-677" data-counts="1">
    <div class="row-fluid row-article-item-section">
        <div class="span1 article-main-left-span1">&nbsp;</div>
        <div class="span11 article-item-section-content">
            
            <div>
                <a rel="nofollow" class="annotation-loader"
                   href="/links/index.html?target=articles/cs-677&amp;_sort=score">Links</a>
            </div>

            <a class="btn btn-primary annotation-create-button add-annotation"
               id="annotation-create-link"
               data-toggle="annotation-form"
               data-target="#annotation-link-create-container"
               rel="nofollow"
               href="/links.form?format=html&amp;target=articles/cs-677&amp;_counts=1"><i class="icon-plus"></i> Add a link</a>
            <div class="annotation-form-container"
                 id="annotation-link-create-container"></div>
        </div>
    </div>
</div>
                </div>
            </div>

            <div class="hidden-desktop" id="mobile-featured-jobs"></div>
        </div>

        <!-- Right sidebar -->
        <div class="span3 offset1 article-sidebar">
                <div id="article-sidebar-main-content" class="mt-4" data-todo-href="/todos/59166/">
                    <div class="dimensions-stats-container visible-desktop">
            <span class="__dimensions_badge_embed__" data-doi="10.7717/peerj-cs.677" data-hide-zero-citations="true" data-legend="always" data-style="small_circle"></span>
        </div>
    
    
        <div class="row-fluid item-action-buttons article-sidebar-item visible-desktop">
            <div class="span12">

                
                                                                <div data-clone="#expertrxiv-related" data-source="/expertrxiv/related?subjectIds=100,110,111&amp;subjects=Artificial%20Intelligence,%20Data%20Mining%20and%20Machine%20Learning,%20Data%20Science"></div>
                    
                                
                                                                                                                        <div class="article-ctas">
                    <div id="download-modal-trigger" class="js-download-modal-trigger btn btn-article btn-download btn-success mb-3  ">
    Download
</div>                    <!--<div class="content-cta-intro-text">Want alerts from articles like this?</div>-->
<div class="content-alert-link-btn content-alert-link" data-href="/content-alert/?aid=59166">
    <div class="content-alert-button-label">
        <i class="icon-envelope btn-content-alert-icon"></i>
        Content <div class="content-alert-btn-lastword">Alert</div>
    </div>
    <div class="content-alert-button-loading" style="display:none;"><i class="icon-spin icon-spinner"></i> Loading...</div>
</div>
    <div class="content-cta-help-text">
        Just enter your email
    </div>
                <div>
                                
            </div>
        </div>
    
    
                
        
        <nav class="article-sidebar-block visible-desktop">
        <div class="sidebar-heading">
            <i class="icon-wrench"></i> Tools & info
        </div>
        <ul class="nav nav-list article-item-metrics-counts" data-src="/articles/cs-677/counter/">
                            <li>
                    <a href="/articles/cs-677/reviews/"
                       rel="version-history">Peer Review history</a>
                </li>
            
                            
                                                        <li><a href="/articles/cs-677/citations/" data-toggle="modal" data-target="#citing-modal">See citing articles <span class="metric-counter citation-item-count">11</span></a></li>
                            
            
            <li><a href="#questions">Ask questions
                    <span class="metric-counter annotation-counter-questioning"></span></a></li>

            <li><a href="#links">Add links
                    <span class="metric-counter annotation-counter-linking"></span></a></li>

                            <li class="article-item-metrics-count"><a data-toggle="modal" href="#metricsModal">Visitors <span class="metric-counter" data-count="visitors">&nbsp;</span> <span class="pull-right metric-counter-details-cta">click for details</span></a></li>
    <li class="article-item-metrics-count"><a data-toggle="modal" href="#metricsModal">Views <span class="metric-counter" data-count="views-html">&nbsp;</span></a></li>
    <li class="article-item-metrics-count"><a data-toggle="modal" href="#metricsModal">Downloads <span class="metric-counter" data-count="views-pdf">&nbsp;</span></a></li>

                            <li><a id="item-flag-button" data-toggle="modal" href="#flagModal">Report problem with article</a></li>
                    </ul>
    </nav>

        <span class="visible-desktop"></span>

    <div id="related-research-sidebar visible-desktop"></div>

</div>
<nav class="article-sidebar-block follow visible-desktop">
            <div class="sidebar-heading">
            <i class="icon-list-ul"></i> Outline
        </div>
        <div class="article-navigation"></div>
            
        
                                            <div class="mt-5">
            <div id="peerj-vue-user-impact-widget"
                 class="mt-6"
                 data-min-cite="5"
                 data-hide-title="1"
                 data-sticky-editor="1"
                 data-editor="83772"
                 data-section=""
                 data-subject="[&quot;artificial-intelligence&quot;,&quot;data-mining-and-machine-learning&quot;,&quot;data-science&quot;]"
                 data-query="{&quot;journal&quot;:&quot;cs&quot;,&quot;key&quot;:&quot;cs-677&quot;,&quot;relatedAuthors&quot;:1,&quot;randomize&quot;:1}"
            ></div>
        </div>
        
    <div id="top-return" class="top-return">
        <i class="icon-arrow-up"></i> Return to top
    </div>    
</nav>

<div class="subjects-navigation visible-desktop"></div>

        </div>
    </div>

        
<style>
    .modal-loading-container{
        display:flex;
        justify-content:center;
        color:#999;
        padding:3rem;
    }
</style>

<div id="download-article-modal" class="modal hide fade peer-review-article" style="">

    <div class="modal-header d-flex" style="justify-content: space-between;">
        <h3 style="color: #000000">Download article</h3>
        <button type="button" class="close" style="color: #000000; font-size: 16px" data-dismiss="modal" aria-hidden="true">&times;</button>
    </div>

    <div class="modal-body">
        <div id="download-article-modal-loading" class="modal-loading-container" style="display:none;">
            <i class="icon-spin icon-3x icon-spinner"></i>
        </div>
        <div id="download-article-modal-body">
                    <div id="download-modal-buttons-container">
        <div class="download-modal-article-title">Topic2features: a novel framework to classify noisy and sparse textual data using LDA topic distributions</div>
            <div class="mt-2 download-buttons">
                                                                                <a target="_blank" download data-format="PDF" data-download-confirm-text="PDF downloading" href="https://peerj.com/articles/cs-677.pdf" target="_blank" class="btn btn-primary js-download-btn btn-block btn-large mb-2 "><i class="icon-cloud-download mr-1"></i> PDF (1.8MB)</a>
                                                    <a target="_blank" data-download-confirm-text="Mendeley opened" href="http://www.mendeley.com/import/?doi=10.7717/peerj-cs.677" class="btn btn-primary js-download-btn btn-block btn-large mb-2"><i class="icon-cloud-download mr-1"></i> Save to Mendeley</a>
                                    <a target="_blank" data-download-confirm-text="Readcube article opened" href="http://www.readcube.com/articles/10.7717/peerj-cs.677" class="btn btn-primary js-download-btn btn-block btn-large mb-2"><i class="icon-cloud-download mr-1"></i> Read in ReadCube</a>
                                                    <a target="_blank" data-format="RIS" data-download-confirm-text="RIS file downloaded" href="https://peerj.com/articles/cs-677.ris" class="btn btn-primary js-download-btn btn-block btn-large mb-2 "><i class="icon-cloud-download mr-1"></i> RIS</a>
                    <a target="_blank" data-format="XML" data-download-confirm-text="XML file downloaded" href="https://peerj.com/articles/cs-677.xml" class="btn btn-primary js-download-btn btn-block btn-large mb-2 "><i class="icon-cloud-download mr-1"></i> XML</a>
                    <a target="_blank" data-format="BibText" data-download-confirm-text="BibText file downloaded" href="https://peerj.com/articles/cs-677.bib" class="btn btn-primary js-download-btn btn-block btn-large mb-2 "><i class="icon-cloud-download mr-1"></i> BibTeX</a>
                
            </div>
        </div>

        <div id="download-modal-downloading-message" style="display:none;">
            <div class="text-center pt-4 pb-4">
                <div>
                    <strong>Your download will start in a moment...</strong>
                </div>
                <div class="btn btn-secondary mt-4 js-close-download-modal">Close</div>
            </div>
        </div>
        <div id="download-modal-signup-container" style="display:none;">
                            
<div class="download-modal-cta-container">

    <div class="download-modal-confirm">
        <div class="download-modal-confirm-title">
            <i class="icon-tickcircle downloaded-tick"></i> <span class="download-modal-confirm-title-text"></span>
            <i class="icon-chevron-down show-download-link"></i>
        </div>
        <a class="article-modal-download-url" href=""></a>
    </div>

    
    <div class="download-modal-cta-subtitle-small mt-2 mb-4 text-center">
        Subscribe for subject updates
    </div>

            <div class="section-subscribe-container mb-2" style="display: flex;justify-content:center;">
            <div>
                <input type="text" placeholder="Email address" name="email" value="" class="form-control" id="download-subscribe-email">
            </div>
            <div class="ml-1">
                <select name="freq" class="form-control" style="width: 100%;" id="download-subscribe-freq">
                    <option value="weekly">Weekly</option>
                    <option value="daily">Daily</option>                    
                </select>
            </div>
        </div>
    
    <div id="download-subscribe-error-container" class="mb-2 text-center text-error" style="display:none;"></div>

                
    <button class="btn btn-primary btn-block btn-large mb-2 btn-modal-cta"
            style="display: block;"
            id="download-subscribe-submit"
            data-url="/content-alert/download-subscribe?aid=59166"
            data-signed-in=""
            data-section-name="">
        Subscribe
    </button>

    <a href="#" class="btn btn-block btn-link btn-large btn-modal-close js-close-download-modal mb-2">
        Close
    </a>

</div>

<script>
    (function(){
        $('#download-subscribe-submit').click(function(){

            var button = $(this);
            var url = button.data('url');
            if(button.attr('disabled')) return;

            $.get(url, function(response){

                if(!response.token){
                    errorContainer.html('Server error, you have not been subscribed').show();
                    button.html('Subscribe').removeAttr('disabled');
                    return;
                }

                var errorContainer = $('#download-subscribe-error-container');
                errorContainer.html('').hide();
                button.html('<i class="icon-spin icon-spinner"></i>').attr('disabled', true);

                var signedIn = button.data('signed-in');
                var sectionName = button.data('section-name');
                var data = {
                    _token: response.token
                };

                if(!signedIn) {
                    var email = $('#download-subscribe-email').val();
                    data.email = email;
                    data.freq = $('download-subscribe-freq').val();
                }

                $.ajax({
                    url: url,
                    method: 'POST',
                    data: data
                }).success(function(response){
                    button.hide();
                    $('.js-close-download-modal').trigger('click');

                    PeerJ.Tools.ToastNotifications.add({
                        type: 'success',
                        title: 'Subscribed',
                        text: sectionName ? 'You subscribed to ' + sectionName : 'You subscribed to this article\'s subjects'
                    });

                }).error(function(response){
                    if(response.responseJSON && response.responseJSON.errors){
                        errorContainer.html(response.responseJSON.errors[0]).show();
                    }
                }).complete(function(){
                    button.html('Subscribe').removeAttr('disabled');
                });

            });
        });

    }());
</script>
                    </div>        
            </div>
    </div>

    <div class="modal-footer" style="display:none;">
        <div class="pull-right">
                    </div>

                    <span class="submit-copy submit-copy-btn btn cancel pull-left" id="modal-cancel" data-dismiss="modal">
                Cancel
            </span>
            </div>
</div>

        <div id="ajax-form"></div>

    <!-- Flag Modal -->
        <div id="flagModal" class="legacy-b2-wrap modal hide" style="max-height:none">
      <div class="modal-header" style="text-align: center">
        <button type="button" class="close" data-dismiss="modal" aria-hidden="true">&times;</button>
        <h3 class="slim">Report a problem</h3>
      </div>

      <form id="article-flag-form"
          data-href="/issues/cs-677/flag/"
          method="post">

          <div class="modal-body" style="max-height:350px;overflow-y:auto">
              <div class="alert alert-info">
                    <p><strong>Common use cases</strong><br>
                    Typos, corrections needed, missing information, abuse, etc
                    </p>

                    <p><strong>Our promise</strong><br>
                    PeerJ promises to address all issues as quickly and professionally as possible. We
                    thank you in advance for your patience and understanding.
                    </p>
              </div>

                <div id="flag-modal-result" style="margin-left:45px;">

                                            <div>
                            <label><strong>Type of problem</strong></label>
                            <p>
                            <select id="moderation_flag_category" name="moderation_flag[category]" class="span4"><option value="typo">Typo</option><option value="metadata">Missing or incorrect metadata</option><option value="quality">Quality: PDF, figure, table, or data quality</option><option value="download">Download issues</option><option value="abuse">Abusive behavior</option><option value="misconduct">Research misconduct</option><option value="other">Other issue not listed above</option></select>
                            
                            </p>
                         </div>
                        <div>
                            <label><strong>Details</strong> <i class="icon-large icon-question-sign" title="Please be as detailed as possible within the 500 character limit. Any details you provide will not be shown publicly." data-toggle="tooltip"></i></label>
                            <div>
                                <textarea id="moderation_flag_detail" name="moderation_flag[detail]" required="required" maxlength="500" class="span4" placeholder="Enter any details about this issue. Kept confidential with PeerJ staff." rows="5" data-counter-target="#flag-counter"></textarea>
                                
                                <div style="margin:10px 0 0 0; color:#777777; float: left; display: block"><span id="flag-counter" class="label">500</span> characters remaining</div>
                            </div>
                         </div>
                        
                                    </div>

          </div>
        </form>
        <div id="flag-modal-footer" class="modal-footer">
        <button class="btn" data-dismiss="modal" aria-hidden="true">Cancel</button>
        <input type="submit" class="btn btn-success save-flag-btn" value="Send report">
        </div>
</div>

    <!-- Follow Publication Modal -->
        <div id="followModal" class="modal hide" style="max-height:none">
      <div class="modal-header" style="text-align:center">
        <button type="button" class="close" data-dismiss="modal" aria-hidden="true">&times;</button>
                    <h3 class="slim" id="followModalLabel">Follow this publication for updates</h3>
              </div>

    <div>
        <div class="modal-body" style="max-height:350px;overflow-y:auto">
            <div class="row-fluid" style="margin-bottom: 15px">
                <div class="span1">
                    <i class="icon-large icon-bullhorn"></i>
                </div>
                <div class="span11">
                    "Following" is like subscribing to any updates related to a publication.
                    These updates will appear in your home dashboard each time you visit PeerJ.
                </div>
            </div>

            <div class="row-fluid">
                <div class="span1">
                    <i class="icon-large icon-envelope"></i>
                </div>
                <div class="span11">
                    <p>
                    You can also choose to receive updates via daily or weekly email digests.
                    If you are following multiple publications then we will send you
                    no more than one email per day or week based on your preferences.
                    </p>
                    <p>
                    <em>Note: You are now also subscribed to the subject areas of this publication</em>
                    and will receive updates in the daily or weekly email digests if turned on.
                    You can <a href="/settings/details">add specific subject areas</a> through your profile settings.
                    </p>
                </div>
            </div>

                     <hr>
                <div id="follow-modal-result" style="margin-left:-40px;padding-top:7px;">
                                    </div>

          </div>

        </div>

        <div id="follow-modal-footer" class="modal-footer">
            <button class="btn" data-dismiss="modal" aria-hidden="true">Close</button>
        </div>
    </div>

    <!-- Unfollow Publication Modal -->
    <div id="unfollowModal" class="modal hide">
    <div class="modal-header">
        <button type="button" class="close" data-dismiss="modal" aria-hidden="true">&times;</button>
        <h3>Change notification settings or unfollow</h3>
    </div>

    <form id="article-unfollow-form"
      data-href="/follow/publication/cs-677/1/"
      method="put" class="form-horizontal">


        <div id="unfollow-form-load-result" class="modal-body" data-href="/follow/publication/cs-677/edit/" style="max-height:350px;overflow-y:auto">
            <p>Loading ...</p>
        </div>

    </form>
        <div class="modal-footer">
            <button class="btn follow-close-btn" data-dismiss="modal" aria-hidden="true">Close</button>
            <input type="submit" class="btn btn-success update-follow-btn" value="Update">
        </div>
</div>

    <!-- Metrics Modal -->
    <div id="metricsModal" class="modal hide">
    <div class="modal-body" style="max-height:330px;overflow-y:auto">

        <div class="row-fluid">
            <div class="span12">
                <p class="leadh2">Usage since published - updated daily</p>
            </div>
        </div>

        <div class="row-fluid">
                            <div class="span8">
                                        <h3 style="margin:30px 0 10px 0">Top referrals <small>unique visitors</small></h3>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <div class="row-fluid" style="font-size: 16px;  color: #444; border-bottom: 1px solid #ccc; margin-bottom: 5px;">
                            <div class="span8" style="min-height:0">
                                                                    From bookmark or typed URL
                                                            </div>
                            <div class="span3" style="text-align:right;min-height:0">2,311</div>
                        </div>
                                            <div class="row-fluid" style="font-size: 16px;  color: #444; border-bottom: 1px solid #ccc; margin-bottom: 5px;">
                            <div class="span8" style="min-height:0">
                                                                    Google search
                                                            </div>
                            <div class="span3" style="text-align:right;min-height:0">242</div>
                        </div>
                                            <div class="row-fluid" style="font-size: 16px;  color: #444; border-bottom: 1px solid #ccc; margin-bottom: 5px;">
                            <div class="span8" style="min-height:0">
                                                                    Twitter
                                                            </div>
                            <div class="span3" style="text-align:right;min-height:0">16</div>
                        </div>
                                            <div class="row-fluid" style="font-size: 16px;  color: #444; border-bottom: 1px solid #ccc; margin-bottom: 5px;">
                            <div class="span8" style="min-height:0">
                                                                    Yahoo search
                                                            </div>
                            <div class="span3" style="text-align:right;min-height:0">1</div>
                        </div>
                                                        </div>
            
            <div class="span4" style="overflow-x:hidden;">
                <h3 style="margin-bottom:10px">Share this publication</h3>

                                    
    
                        <ul class="unstyled">
    <li>
        <a class="pj-socialism tw-soc" href="http://twitter.com/share?url&#x3D;https&#x25;3A&#x25;2F&#x25;2Fpeerj.com&#x25;2Farticles&#x25;2Fcs-677&#x25;2F&amp;via&#x3D;PeerJCompSci&amp;text&#x3D;Topics&#x25;20vectors&#x25;20for&#x25;20classification&amp;related&#x3D;" target="_blank" onclick="window.open(this.href, 'popupwindow', 'width=500,height=500,scrollbars,resizable'); return false;">X</a>
    </li>
    <li>
        <a class="pj-socialism fb-soc" href="http://www.facebook.com/sharer.php?u&#x3D;https&#x25;3A&#x25;2F&#x25;2Fpeerj.com&#x25;2Farticles&#x25;2Fcs-677&#x25;2F" target="_blank" onclick="window.open(this.href, 'popupwindow', 'width=500,height=500,scrollbars,resizable'); return false;">Facebook</a>
    </li>
    <li>
        <a class="pj-socialism em-soc" href="mailto:?Subject&#x3D;Relevant&#x25;20research&#x25;20paper&#x25;20in&#x25;20PeerJ&#x25;20Computer&#x25;20Science&amp;Body&#x3D;Topic2features&#x25;3A&#x25;20a&#x25;20novel&#x25;20framework&#x25;20to&#x25;20classify&#x25;20noisy&#x25;20and&#x25;20sparse&#x25;20textual&#x25;20data&#x25;20using&#x25;20LDA&#x25;20topic&#x25;20distributions&#x25;20https&#x25;3A&#x25;2F&#x25;2Fpeerj.com&#x25;2Farticles&#x25;2Fcs-677&#x25;2F" target="_blank" onclick="window.open(this.href, 'popupwindow', 'width=500,height=500,scrollbars,resizable'); return false;">Email</a>
    </li>
</ul>                
                <h3 style="margin-bottom:10px;margin-top:10px">Metrics</h3>

                <!-- Altmetric -->
                <div class="altmetric-embed" data-badge-popover="right"
                     data-link-target="_blank" data-doi="10.7717/peerj-cs.677"></div>
            </div>
        </div>

    </div>

    <div class="modal-footer">
        <button class="btn" data-dismiss="modal" aria-hidden="true">Close</button>
    </div>
</div>

    <!-- Wiki Modal -->
    
    <!-- Links Modal -->
    <div class="modal hide fade" id="article-links-modal">
    <div class="modal-header">
        <a rel="nofollow" data-dismiss="modal" aria-hidden="true" class="close">&times;</a>

        <h3 class="modal-title">Links</h3>
    </div>

    <div class="modal-body"></div>

    <div class="modal-footer">
        <a rel="nofollow" href="/links.form?target=articles/cs-677" class="btn btn-primary">Add a link</a>
        <button class="btn follow-close-btn" data-dismiss="modal" aria-hidden="true">Close</button>
    </div>
</div>

    <!-- Citing Modal -->
    <div id="citing-modal" class="modal hide">
    <div class="modal-header">
        <button type="button" class="close" data-dismiss="modal" aria-hidden="true">&times;</button>
        <h2 class="slim"><i class="icon-copy"></i> Articles citing this paper</h2>
    </div>
  <div class="modal-body">Loading citing articles… <i class="icon icon-spinner icon-spin"></i></div>
</div>

    <!-- Graphical abstract modal -->
    

        </div>

        
                <div id="push"></div>

    </div>
</div>
        <div id="vue-peerj-core-app"
     data-betaTesting="1"
     data-isDarkTheme="false"
     data-mercure="https://sse.peerj.com/.well-known/mercure"
     data-userRoleData="{&quot;isAdmin&quot;:false,&quot;isStaff&quot;:false,&quot;isAimsAdmin&quot;:false,&quot;_roles&quot;:[],&quot;_me&quot;:[]}"
     data-api="https://peerj.com/api/v2"
     data-imagePrefix="https://d2pdyyx74uypu5.cloudfront.net/"
     data-groupFilesPrefix="https://group-files.peerj.com/"
     data-groupFilesRoot=""
     data-userImagePrefix="https://s3.amazonaws.com/peerj_prod_upload/images/profile"
     data-articleBasePrefix="https://dfzljdn9uc3pi.cloudfront.net/"
     data-recaptchaKey="6LcklyQUAAAAAGWmGpOk76ha4H0b229a5GSVahJr"
>
</div>
            <header id="header-skeleton" class="px-sm text-left shadow-sm v-sheet theme--light v-toolbar v-toolbar--flat v-app-bar v-app-bar--fixed" data-booted="true" style="height: 75px; margin-top: 0px; transform: translateY(0px); left: 0px; right: 0px; background: #fff; color: #FFF"><div class="v-toolbar__content" style="height: 75px;"><button type="button" class="v-app-bar__nav-icon v-btn v-btn--icon v-btn--round theme--light v-size--default"><span class="v-btn__content"><i aria-hidden="true" aria-haspopup="true" aria-expanded="false" class="v-icon notranslate mdi mdi-view-dashboard theme--light" style="color: #FFF"></i><span class="v-tooltip"></span></span></button>

            <div class="d-flex"><div>   </div></div></div></header>





    <div class="item-top-navbar">
    <div class="item-top-navbar-inner">
        <div class="container-fluid">
            <div class="row-fluid">
                <div class="span12">
                       <div class="item-metrics-counts-top-nav article-item-metrics-counts">
                                                                                                        <span class="article-item-metrics-count visible-all">
                                        <span data-count="citations">11</span>
                                        <span class="article-item-metrics-label">Citations</span>
                                    </span>
                                
                            <span class="article-item-metrics-count">
                                <span data-count="views-html">&nbsp;</span>
                                <span class="article-item-metrics-label">Views</span>
                            </span>

                            <span class="article-item-metrics-count">
                                <span data-count="views-pdf">&nbsp;</span>
                                <span class="article-item-metrics-label">Downloads</span>
                            </span>
                       </div>
                </div>
            </div>
        </div>
    </div>
</div>




<div id="alerts" class="legacy-b2-wrap" data-async-alerts="/alerts/"></div>

            <script src="/js/8d39319-874fe15.js"></script>
        <script src="https://cdn.peerj.com/4a8db25/webpack/runtime.d6592c11.js"></script><script src="https://cdn.peerj.com/4a8db25/webpack/177.c072f5d5.js"></script><script src="https://cdn.peerj.com/4a8db25/webpack/310.819618fc.js"></script><script src="https://cdn.peerj.com/4a8db25/webpack/peerj-app.275d00b6.js"></script>


    <script src="/js/5d3c493-193ec0b.js"></script>

    <script src="/js/c1dacd9-99843f6.js"></script>
        <!--[if gt IE 8]><!-->
        <script src="/assets/js/highlight/highlight.pack.js"></script>

                <script>
            (function(){

                function initTweets(){
                    //Get count
                    var tweetCountUrl = '/articles/cs-677/tweet-count/';
                    $.get(tweetCountUrl, function(response){
                        if(response.count){
                            $('#tweet-count-container').html('View ' + response.count + ' post' + (response.count > 1 ? 's' : ''));
                            $('#btn-view-tweets').fadeIn(200);
                        }
                    });

                    //Get first page
                    $('.tweet-items').html('Loading...');
                    var tweetsPageUrl = '/articles/cs-677/tweets/';
                    $.get(tweetsPageUrl, function(response){
                        if(response.html){
                            $('.tweet-items').html(response.html);
                            $("html, body").animate({scrollTop: 0}, 500);
                        }
                    });
                }

                setTimeout(initTweets, 2500);

            })();
        </script>

                
        <script>
            $(function () {
                // syntax highlighting for code blocks
                $("pre > code").each(function() {
                    var node = $(this);

                    var language;

                    // JATS >=1.1
                    language = node.data('jats-language');

                    if (!language) {
                        // JATS <1.1
                        language = node.data('jats-preformat-type');

                        // ignore default 'code' type
                        if (language === 'code') {
                            language = null;
                        }
                    }

                    if (language) {
                        node.addClass('language-' + language);
                    }

                    hljs.highlightBlock(this);
                });
            });
        </script>
    <!--<![endif]-->

    <script>
        //initialise the follow button
        $(function() {
            PeerJ.Event.Follow.init();
        });

        //Show citations modal if query param exists
        var urlParams = new URLSearchParams(window.location.search);
        if(urlParams.has('citations')){
            $('#citing-modal').modal('show');
        }

    </script>

        
    
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        messageStyle: "none",
        imageFont: null,
        "CommonHTML": {
            linebreaks: { automatic: true },
            scale: 95
        },
        "HTML-CSS": {
            linebreaks: { automatic: true },
            scale: 90
        },
        menuSettings: {
            zoom: "Click"
        }
    });

    MathJax.Ajax.config.root = "/bundles/peerjmathjax/MathJax/";
</script>

<script src="/bundles/peerjmathjax/MathJax/MathJax.js?config=TeX-MML-AM_HTMLorMML,Safe&noContrib"></script>

    <script defer src='https://js.trendmd.com/trendmd.min.js' data-trendmdconfig='{"journal_id":"52926","element":"#related-research"}'></script>
    <script defer src='https://js.trendmd.com/trendmd.min.js' data-trendmdconfig='{"journal_id":"52926","element":"#related-research-sidebar"}'></script>
    <script async src="https://badge.dimensions.ai/badge.js" charset="utf-8"></script>

<div class="legacy-b2-wrap">
    <div id="content-alert-container"></div>
    <div id="toast-container"></div>

        <link rel="dns-prefetch" href="https://d2pdyyx74uypu5.cloudfront.net/">
    <link rel="dns-prefetch" href="http://static.peerj.com/">
<link rel="dns-prefetch" href="https://doi.org">

    
    </div>
</body>
</html>
