"""
ë…¼ë¬¸ ë¦¬ë·° ë° ì‚¬ìš©ì ìƒí˜¸ì‘ìš© ì—ì´ì „íŠ¸ ëª¨ë“ˆ
ë…¼ë¬¸ì„ ê²€í† í•˜ê³  ì‚¬ìš©ìì™€ì˜ ìƒí˜¸ì‘ìš©ì„ ê´€ë¦¬í•˜ëŠ” í†µí•© ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤.
"""

import os
import re
import json
from typing import Dict, Any, List, Optional, Tuple, Union
from pydantic import BaseModel, Field
from datetime import datetime

from langchain_core.runnables import RunnableConfig
from langchain.schema import HumanMessage, AIMessage
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain.output_parsers import PydanticOutputParser

from config.settings import OUTPUT_DIR
from utils.logger import logger
from models.paper import Paper
from models.state import PaperWorkflowState
from agents.base import BaseAgent


class UserFeedback(BaseModel):
    """ì‚¬ìš©ì í”¼ë“œë°± í˜•ì‹"""
    feedback_text: str = Field(description="ì‚¬ìš©ì í”¼ë“œë°± í…ìŠ¤íŠ¸")
    timestamp: str = Field(description="í”¼ë“œë°± ì‹œê°„")
    is_positive: Optional[bool] = Field(description="ê¸ì •ì  í”¼ë“œë°± ì—¬ë¶€", default=None)
    tags: List[str] = Field(description="í”¼ë“œë°± íƒœê·¸", default_factory=list)


class FeedbackAnalysis(BaseModel):
    """í”¼ë“œë°± ë¶„ì„ ê²°ê³¼ í˜•ì‹"""
    is_positive: bool = Field(description="ê¸ì •ì  í”¼ë“œë°± ì—¬ë¶€")
    sentiment_score: float = Field(description="ê°ì • ì ìˆ˜ (-1.0 ~ 1.0)")
    main_points: List[str] = Field(description="ì£¼ìš” ìš”ì ")
    action_items: List[str] = Field(description="í•„ìš”í•œ ì¡°ì¹˜ í•­ëª©")
    priority: str = Field(description="ìš°ì„ ìˆœìœ„ (ë†’ìŒ, ì¤‘ê°„, ë‚®ìŒ)")


class ProgressUpdate(BaseModel):
    """ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸ í˜•ì‹"""
    current_stage: str = Field(description="í˜„ì¬ ë‹¨ê³„")
    progress_percentage: float = Field(description="ì§„í–‰ë¥  (%)")
    completed_tasks: List[str] = Field(description="ì™„ë£Œëœ ì‘ì—…")
    pending_tasks: List[str] = Field(description="ëŒ€ê¸° ì¤‘ì¸ ì‘ì—…")
    estimated_completion: Optional[str] = Field(description="ì˜ˆìƒ ì™„ë£Œ ì‹œê°„", default=None)
    issues: List[str] = Field(description="í˜„ì¬ ì´ìŠˆ", default_factory=list)


class PaperReview(BaseModel):
    """ë…¼ë¬¸ ë¦¬ë·° ê²°ê³¼ í˜•ì‹"""
    paper_title: str = Field(description="ë¦¬ë·°í•œ ë…¼ë¬¸ ì œëª©")
    overall_score: int = Field(description="ì „ì²´ í‰ê°€ ì ìˆ˜ (1-10)")
    strengths: List[str] = Field(description="ì¥ì ")
    weaknesses: List[str] = Field(description="ì•½ì ")
    improvement_suggestions: List[str] = Field(description="ê°œì„  ì œì•ˆ")
    section_feedback: Dict[str, str] = Field(description="ì„¹ì…˜ë³„ í”¼ë“œë°±")
    structural_comments: str = Field(description="êµ¬ì¡°ì  ì˜ê²¬")
    language_comments: str = Field(description="ì–¸ì–´ì  ì˜ê²¬")


class ReviewAction(BaseModel):
    """ë¦¬ë·° ì¡°ì¹˜ ì‚¬í•­ í˜•ì‹"""
    action_type: str = Field(description="ì¡°ì¹˜ ìœ í˜• (ìˆ˜ì •, ì¶”ê°€, ì‚­ì œ, ì¬êµ¬ì„± ë“±)")
    section: Optional[str] = Field(description="ê´€ë ¨ ì„¹ì…˜", default=None)
    description: str = Field(description="ì¡°ì¹˜ ì„¤ëª…")
    priority: str = Field(description="ìš°ì„ ìˆœìœ„ (ë†’ìŒ, ì¤‘ê°„, ë‚®ìŒ)")
    rationale: str = Field(description="ì¡°ì¹˜ì˜ ê·¼ê±°")


class ReviewAgent(BaseAgent[Dict[str, Any]]):
    """ë…¼ë¬¸ ë¦¬ë·° ë° ì‚¬ìš©ì ìƒí˜¸ì‘ìš© í†µí•© ì—ì´ì „íŠ¸"""

    def __init__(
        self,
        name: str = "ë¦¬ë·° ë° ìƒí˜¸ì‘ìš© ì—ì´ì „íŠ¸",
        description: str = "ë…¼ë¬¸ ë¦¬ë·° ë° ì‚¬ìš©ì í”¼ë“œë°± ê´€ë¦¬",
        verbose: bool = False
    ):
        """
        ReviewAgent ì´ˆê¸°í™”

        Args:
            name (str, optional): ì—ì´ì „íŠ¸ ì´ë¦„. ê¸°ë³¸ê°’ì€ "ë¦¬ë·° ë° ìƒí˜¸ì‘ìš© ì—ì´ì „íŠ¸"
            description (str, optional): ì—ì´ì „íŠ¸ ì„¤ëª…. ê¸°ë³¸ê°’ì€ "ë…¼ë¬¸ ë¦¬ë·° ë° ì‚¬ìš©ì í”¼ë“œë°± ê´€ë¦¬"
            verbose (bool, optional): ìƒì„¸ ë¡œê¹… í™œì„±í™” ì—¬ë¶€. ê¸°ë³¸ê°’ì€ False
        """
        super().__init__(name, description, verbose=verbose)
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(OUTPUT_DIR, exist_ok=True)
        
        # í”„ë¡¬í”„íŠ¸ ì´ˆê¸°í™”
        self._init_prompts()
        
        # í”¼ë“œë°± ì €ì¥ì†Œ ì´ˆê¸°í™”
        self.feedback_history = []
        
        # ë¦¬ë·° ì €ì¥ì†Œ ì´ˆê¸°í™”
        self.review_history = []
        
        # ì§„í–‰ ìƒí™© ì´ˆê¸°í™”
        self.current_progress = None
        
        logger.info(f"{self.name} ì´ˆê¸°í™” ì™„ë£Œ")

    def _init_prompts(self) -> None:
        """í”„ë¡¬í”„íŠ¸ì™€ ì²´ì¸ ì´ˆê¸°í™”"""
        # í”¼ë“œë°± ë¶„ì„ íŒŒì„œ ì´ˆê¸°í™”
        self.feedback_analysis_parser = PydanticOutputParser(pydantic_object=FeedbackAnalysis)
        
        # ë…¼ë¬¸ ë¦¬ë·° íŒŒì„œ ì´ˆê¸°í™”
        self.paper_review_parser = PydanticOutputParser(pydantic_object=PaperReview)
        
        # ë¦¬ë·° ì¡°ì¹˜ íŒŒì„œ ì´ˆê¸°í™”
        self.review_action_parser = PydanticOutputParser(pydantic_object=ReviewAction)
        
        # í”¼ë“œë°± ë¶„ì„ ì²´ì¸ ì´ˆê¸°í™”
        self.feedback_analysis_chain = LLMChain(
            llm=self.llm,
            prompt=PromptTemplate(
                template="""ì‚¬ìš©ìê°€ ì œê³µí•œ í”¼ë“œë°±ì„ ë¶„ì„í•´ ì£¼ì„¸ìš”.
                
                í”¼ë“œë°±:
                {feedback}
                
                ë‹¤ìŒ í•­ëª©ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:
                1. ì´ í”¼ë“œë°±ì´ ì „ë°˜ì ìœ¼ë¡œ ê¸ì •ì ì¸ì§€ ë¶€ì •ì ì¸ì§€ (is_positive)
                2. -1.0ë¶€í„° 1.0 ì‚¬ì´ì˜ ê°ì • ì ìˆ˜ (sentiment_score)
                3. í”¼ë“œë°±ì—ì„œ ì–¸ê¸‰ëœ ì£¼ìš” ìš”ì  ëª©ë¡ (main_points)
                4. í•„ìš”í•œ ì¡°ì¹˜ í•­ëª© ëª©ë¡ (action_items)
                5. ì¡°ì¹˜ì˜ ìš°ì„ ìˆœìœ„ (ë†’ìŒ, ì¤‘ê°„, ë‚®ìŒ) (priority)
                
                {format_instructions}
                """,
                input_variables=["feedback", "format_instructions"],
            ),
            verbose=self.verbose
        )
        
        # ë…¼ë¬¸ ë¦¬ë·° ì²´ì¸ ì´ˆê¸°í™”
        self.paper_review_chain = LLMChain(
            llm=self.llm,
            prompt=PromptTemplate(
                template="""ë‹¤ìŒ ë…¼ë¬¸ì„ ì² ì €íˆ ê²€í† í•˜ê³  ì¢…í•©ì ì¸ í•™ìˆ  ë¦¬ë·°ë¥¼ ì œê³µí•´ ì£¼ì„¸ìš”.
                
                ë…¼ë¬¸ ì œëª©: {paper_title}
                
                ë…¼ë¬¸ ë‚´ìš©:
                {paper_content}
                
                ë‹¤ìŒ í•­ëª©ì„ í¬í•¨í•œ ì² ì €í•œ í•™ìˆ  ë¦¬ë·°ë¥¼ ì‘ì„±í•´ ì£¼ì„¸ìš”:
                1. ì „ì²´ í‰ê°€ ì ìˆ˜ (1-10)
                2. ì£¼ìš” ì¥ì  ëª©ë¡
                3. ì£¼ìš” ì•½ì  ëª©ë¡
                4. êµ¬ì²´ì ì¸ ê°œì„  ì œì•ˆ ëª©ë¡
                5. ì£¼ìš” ì„¹ì…˜ë³„ í”¼ë“œë°±
                6. êµ¬ì¡°ì  ì˜ê²¬ (ë…¼ë¬¸ êµ¬ì„±, íë¦„, ë…¼ë¦¬ì  ì¼ê´€ì„±)
                7. ì–¸ì–´ì  ì˜ê²¬ (ëª…í™•ì„±, ê°„ê²°ì„±, í•™ìˆ ì  í‘œí˜„)
                
                ë¦¬ë·°ëŠ” ê°ê´€ì ì´ê³  ê±´ì„¤ì ì´ì–´ì•¼ í•˜ë©°, ë…¼ë¬¸ì˜ í•™ìˆ ì  ê°€ì¹˜ë¥¼ í–¥ìƒì‹œí‚¤ëŠ” ë° ë„ì›€ì´ ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
                
                {format_instructions}
                """,
                input_variables=["paper_title", "paper_content", "format_instructions"],
            ),
            verbose=self.verbose
        )
        
        # ë¦¬ë·° ì¡°ì¹˜ ì²´ì¸ ì´ˆê¸°í™”
        self.review_action_chain = LLMChain(
            llm=self.llm,
            prompt=PromptTemplate(
                template="""ë…¼ë¬¸ ë¦¬ë·° ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ êµ¬ì²´ì ì¸ ì¡°ì¹˜ ì‚¬í•­ì„ ì œì•ˆí•´ ì£¼ì„¸ìš”.
                
                ë…¼ë¬¸ ì œëª©: {paper_title}
                ë¦¬ë·° ê²°ê³¼:
                {review_result}
                
                ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ê°€ì¥ ì¤‘ìš”í•œ ì¡°ì¹˜ ì‚¬í•­ì„ ì œì•ˆí•´ ì£¼ì„¸ìš”:
                1. ì¡°ì¹˜ ìœ í˜• (ìˆ˜ì •, ì¶”ê°€, ì‚­ì œ, ì¬êµ¬ì„± ë“±)
                2. ê´€ë ¨ ì„¹ì…˜ (í•´ë‹¹ë˜ëŠ” ê²½ìš°)
                3. ìƒì„¸í•œ ì¡°ì¹˜ ì„¤ëª…
                4. ìš°ì„ ìˆœìœ„ (ë†’ìŒ, ì¤‘ê°„, ë‚®ìŒ)
                5. ì´ ì¡°ì¹˜ê°€ í•„ìš”í•œ ê·¼ê±°
                
                {format_instructions}
                """,
                input_variables=["paper_title", "review_result", "format_instructions"],
            ),
            verbose=self.verbose
        )
        
        # ì§„í–‰ ìƒí™© ìƒì„± ì²´ì¸ ì´ˆê¸°í™”
        self.progress_update_chain = LLMChain(
            llm=self.llm,
            prompt=PromptTemplate(
                template="""í˜„ì¬ ì›Œí¬í”Œë¡œìš° ìƒíƒœë¥¼ ë¶„ì„í•˜ê³  ì‚¬ìš©ìì—ê²Œ ì í•©í•œ ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸ë¥¼ ìƒì„±í•´ ì£¼ì„¸ìš”.
                
                ì›Œí¬í”Œë¡œìš° ìƒíƒœ:
                {workflow_state}
                
                ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸ë¥¼ ìƒì„±í•´ ì£¼ì„¸ìš”:
                1. í˜„ì¬ ì§„í–‰ ì¤‘ì¸ ë‹¨ê³„
                2. í˜„ì¬ ì§„í–‰ë¥  (%)
                3. ì™„ë£Œëœ ì‘ì—… ëª©ë¡
                4. ëŒ€ê¸° ì¤‘ì¸ ì‘ì—… ëª©ë¡
                5. ì˜ˆìƒ ì™„ë£Œ ì‹œê°„ (ìˆëŠ” ê²½ìš°)
                6. í˜„ì¬ ì´ìŠˆ ëª©ë¡ (ìˆëŠ” ê²½ìš°)
                
                ì—…ë°ì´íŠ¸ëŠ” ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ì‘ì„±í•´ ì£¼ì„¸ìš”.
                """,
                input_variables=["workflow_state"],
            ),
            verbose=self.verbose
        )
        
        logger.debug("ë¦¬ë·° ë° ìƒí˜¸ì‘ìš© ì—ì´ì „íŠ¸ í”„ë¡¬í”„íŠ¸ ë° ì²´ì¸ ì´ˆê¸°í™” ì™„ë£Œ")

    def collect_feedback(self, feedback_text: str) -> UserFeedback:
        """
        ì‚¬ìš©ì í”¼ë“œë°±ì„ ìˆ˜ì§‘í•©ë‹ˆë‹¤.

        Args:
            feedback_text (str): ì‚¬ìš©ì í”¼ë“œë°± í…ìŠ¤íŠ¸

        Returns:
            UserFeedback: ìˆ˜ì§‘ëœ í”¼ë“œë°±
        """
        logger.info("ì‚¬ìš©ì í”¼ë“œë°± ìˆ˜ì§‘ ì¤‘...")
        
        try:
            # í”¼ë“œë°± ë¶„ì„
            format_instructions = self.feedback_analysis_parser.get_format_instructions()
            
            result = self.feedback_analysis_chain.invoke({
                "feedback": feedback_text,
                "format_instructions": format_instructions
            })
            
            analysis = self.feedback_analysis_parser.parse(result["text"])
            
            # í”¼ë“œë°± íƒœê·¸ ì¶”ì¶œ
            tags = []
            if "ìˆ˜ì •" in feedback_text or "ë³€ê²½" in feedback_text or "ê°œì„ " in feedback_text:
                tags.append("ìˆ˜ì •_ìš”ì²­")
            if "ì§ˆë¬¸" in feedback_text or "ê¶ê¸ˆ" in feedback_text or "ì–´ë–»ê²Œ" in feedback_text:
                tags.append("ì§ˆë¬¸")
            if "ì¢‹ì•„" in feedback_text or "ë§Œì¡±" in feedback_text or "í›Œë¥­" in feedback_text:
                tags.append("ê¸ì •_í‰ê°€")
            if "ë‚˜ì˜" in feedback_text or "ë¶ˆë§Œ" in feedback_text or "ì‹¤ë§" in feedback_text:
                tags.append("ë¶€ì •_í‰ê°€")
            
            # ì‚¬ìš©ì í”¼ë“œë°± ê°ì²´ ìƒì„±
            user_feedback = UserFeedback(
                feedback_text=feedback_text,
                timestamp=datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                is_positive=analysis.is_positive,
                tags=tags
            )
            
            # í”¼ë“œë°± ì €ì¥
            self.feedback_history.append(user_feedback)
            
            # ìƒíƒœ ì—…ë°ì´íŠ¸
            current_feedback_count = len(self.feedback_history)
            self.update_state({
                "last_feedback": user_feedback.dict(),
                "feedback_count": current_feedback_count,
                "feedback_analysis": analysis.dict()
            })
            
            logger.info(f"í”¼ë“œë°± ìˆ˜ì§‘ ì™„ë£Œ: {'ê¸ì •ì ' if analysis.is_positive else 'ë¶€ì •ì '} í”¼ë“œë°±, {len(tags)}ê°œ íƒœê·¸")
            return user_feedback
            
        except Exception as e:
            logger.error(f"í”¼ë“œë°± ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ í”¼ë“œë°± ë°˜í™˜
            default_feedback = UserFeedback(
                feedback_text=feedback_text,
                timestamp=datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                tags=["ì²˜ë¦¬_ì˜¤ë¥˜"]
            )
            
            # í”¼ë“œë°± ì €ì¥
            self.feedback_history.append(default_feedback)
            
            return default_feedback

    def analyze_feedback(self, feedback: UserFeedback) -> FeedbackAnalysis:
        """
        ìˆ˜ì§‘ëœ í”¼ë“œë°±ì„ ë¶„ì„í•©ë‹ˆë‹¤.

        Args:
            feedback (UserFeedback): ë¶„ì„í•  í”¼ë“œë°±

        Returns:
            FeedbackAnalysis: í”¼ë“œë°± ë¶„ì„ ê²°ê³¼
        """
        logger.info(f"í”¼ë“œë°± ë¶„ì„ ì¤‘: {feedback.feedback_text[:50]}...")
        
        try:
            # í”¼ë“œë°± ë¶„ì„
            format_instructions = self.feedback_analysis_parser.get_format_instructions()
            
            result = self.feedback_analysis_chain.invoke({
                "feedback": feedback.feedback_text,
                "format_instructions": format_instructions
            })
            
            analysis = self.feedback_analysis_parser.parse(result["text"])
            
            logger.info(f"í”¼ë“œë°± ë¶„ì„ ì™„ë£Œ: ê°ì • ì ìˆ˜ {analysis.sentiment_score}, ìš°ì„ ìˆœìœ„ {analysis.priority}")
            return analysis
            
        except Exception as e:
            logger.error(f"í”¼ë“œë°± ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ ë¶„ì„ ê²°ê³¼ ë°˜í™˜
            return FeedbackAnalysis(
                is_positive=False,
                sentiment_score=0.0,
                main_points=["ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ"],
                action_items=["í”¼ë“œë°± ë‹¤ì‹œ ë¶„ì„"],
                priority="ì¤‘ê°„"
            )

    def generate_progress_update(self, workflow_state: PaperWorkflowState) -> ProgressUpdate:
        """
        í˜„ì¬ ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

        Args:
            workflow_state (PaperWorkflowState): í˜„ì¬ ì›Œí¬í”Œë¡œìš° ìƒíƒœ

        Returns:
            ProgressUpdate: ìƒì„±ëœ ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
        """
        logger.info("ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸ ìƒì„± ì¤‘...")
        
        try:
            # í˜„ì¬ ë‹¨ê³„ ê²°ì •
            current_stage = "ì´ˆê¸°í™”"
            progress_percentage = 0.0
            completed_tasks = []
            pending_tasks = ["ì—°êµ¬", "ì‘ì„±", "í¸ì§‘"]
            issues = []
            
            if workflow_state.error:
                issues.append(workflow_state.error)
            
            status = workflow_state.status
            
            if status == "initialized":
                current_stage = "ì´ˆê¸°í™”"
                progress_percentage = 10.0
                completed_tasks = ["ì´ˆê¸°í™”"]
                pending_tasks = ["ì—°êµ¬", "ì‘ì„±", "í¸ì§‘"]
            elif status == "research_completed":
                current_stage = "ì—°êµ¬ ì™„ë£Œ"
                progress_percentage = 30.0
                completed_tasks = ["ì´ˆê¸°í™”", "ì—°êµ¬"]
                pending_tasks = ["ì‘ì„±", "í¸ì§‘"]
            elif status == "writing_completed":
                current_stage = "ì‘ì„± ì™„ë£Œ"
                progress_percentage = 60.0
                completed_tasks = ["ì´ˆê¸°í™”", "ì—°êµ¬", "ì‘ì„±"]
                pending_tasks = ["í¸ì§‘"]
            elif status == "editing_completed":
                current_stage = "í¸ì§‘ ì™„ë£Œ"
                progress_percentage = 100.0
                completed_tasks = ["ì´ˆê¸°í™”", "ì—°êµ¬", "ì‘ì„±", "í¸ì§‘"]
                pending_tasks = []
            
            # ì˜ˆìƒ ì™„ë£Œ ì‹œê°„ ê³„ì‚° (ê°„ë‹¨í•œ ì¶”ì •)
            estimated_completion = None
            if progress_percentage < 100.0:
                remaining_percentage = 100.0 - progress_percentage
                # ëŒ€ëµì ìœ¼ë¡œ 10%ë‹¹ 5ë¶„ ì†Œìš”ëœë‹¤ê³  ê°€ì •
                remaining_minutes = int(remaining_percentage / 10.0 * 5)
                
                if remaining_minutes > 0:
                    current_time = datetime.now()
                    estimated_time = current_time.replace(
                        minute=current_time.minute + remaining_minutes,
                        second=0
                    )
                    estimated_completion = estimated_time.strftime("%H:%M")
            
            # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸ ê°ì²´ ìƒì„±
            progress_update = ProgressUpdate(
                current_stage=current_stage,
                progress_percentage=progress_percentage,
                completed_tasks=completed_tasks,
                pending_tasks=pending_tasks,
                estimated_completion=estimated_completion,
                issues=issues
            )
            
            # ìƒíƒœ ì €ì¥
            self.current_progress = progress_update
            
            logger.info(f"ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸ ìƒì„± ì™„ë£Œ: {current_stage}, {progress_percentage}% ì™„ë£Œ")
            return progress_update
            
        except Exception as e:
            logger.error(f"ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ ì—…ë°ì´íŠ¸ ë°˜í™˜
            return ProgressUpdate(
                current_stage="ì•Œ ìˆ˜ ì—†ìŒ",
                progress_percentage=0.0,
                completed_tasks=[],
                pending_tasks=["ì—°êµ¬", "ì‘ì„±", "í¸ì§‘"],
                issues=["ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ"]
            )

    def format_progress_message(self, progress: ProgressUpdate) -> str:
        """
        ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸ë¥¼ ì‚¬ìš©ì ì¹œí™”ì ì¸ ë©”ì‹œì§€ë¡œ í¬ë§·íŒ…í•©ë‹ˆë‹¤.

        Args:
            progress (ProgressUpdate): ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸

        Returns:
            str: í¬ë§·íŒ…ëœ ë©”ì‹œì§€
        """
        message = f"## í˜„ì¬ ì§„í–‰ ìƒí™©: {progress.current_stage}

"
        message += f"ì „ì²´ ì§„í–‰ë¥ : **{progress.progress_percentage:.1f}%**

"
        
        message += "### ì™„ë£Œëœ ì‘ì—…:
"
        for task in progress.completed_tasks:
            message += f"- âœ… {task}
"
        
        message += "
### ëŒ€ê¸° ì¤‘ì¸ ì‘ì—…:
"
        for task in progress.pending_tasks:
            message += f"- â³ {task}
"
        
        if progress.estimated_completion:
            message += f"
ì˜ˆìƒ ì™„ë£Œ ì‹œê°„: **{progress.estimated_completion}**
"
        
        if progress.issues:
            message += "
### í˜„ì¬ ì´ìŠˆ:
"
            for issue in progress.issues:
                message += f"- âš ï¸ {issue}
"
        
        return message

    def get_feedback_history(self) -> List[Dict[str, Any]]:
        """
        í”¼ë“œë°± íˆìŠ¤í† ë¦¬ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.

        Returns:
            List[Dict[str, Any]]: í”¼ë“œë°± íˆìŠ¤í† ë¦¬ ëª©ë¡
        """
        return [feedback.dict() for feedback in self.feedback_history]

    def review_paper(self, paper: Paper) -> PaperReview:
        """
        ë…¼ë¬¸ì„ ê²€í† í•˜ê³  ì¢…í•©ì ì¸ í”¼ë“œë°±ì„ ì œê³µí•©ë‹ˆë‹¤.

        Args:
            paper (Paper): ê²€í† í•  ë…¼ë¬¸

        Returns:
            PaperReview: ë…¼ë¬¸ ë¦¬ë·° ê²°ê³¼
        """
        logger.info(f"ë…¼ë¬¸ '{paper.title}' ê²€í†  ì¤‘...")
        
        try:
            # ë…¼ë¬¸ ì „ì²´ ë‚´ìš© ìƒì„±
            paper_content = f"# {paper.title}

"
            
            for section in paper.sections:
                paper_content += f"## {section.title}

{section.content}

"
            
            # ì°¸ê³  ë¬¸í—Œ ì„¹ì…˜ ì¶”ê°€
            if paper.references:
                paper_content += "## ì°¸ê³  ë¬¸í—Œ

"
                for i, ref in enumerate(paper.references, 1):
                    authors = ", ".join(ref.authors) if ref.authors else "ì•Œ ìˆ˜ ì—†ìŒ"
                    paper_content += f"{i}. {ref.title}. {authors}. {ref.year}. {ref.source}.
"
            
            # ë…¼ë¬¸ ë¦¬ë·° ìˆ˜í–‰
            format_instructions = self.paper_review_parser.get_format_instructions()
            
            result = self.paper_review_chain.invoke({
                "paper_title": paper.title,
                "paper_content": paper_content,
                "format_instructions": format_instructions
            })
            
            # ê²°ê³¼ íŒŒì‹±
            review = self.paper_review_parser.parse(result["text"])
            
            # ë¦¬ë·° ì €ì¥
            self.review_history.append(review)
            
            # ìƒíƒœ ì—…ë°ì´íŠ¸
            self.update_state({
                "last_review": review.dict(),
                "review_count": len(self.review_history)
            })
            
            logger.info(f"ë…¼ë¬¸ '{paper.title}' ê²€í†  ì™„ë£Œ: í‰ê°€ ì ìˆ˜ {review.overall_score}/10")
            return review
            
        except Exception as e:
            logger.error(f"ë…¼ë¬¸ ê²€í†  ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ ë¦¬ë·° ë°˜í™˜
            default_review = PaperReview(
                paper_title=paper.title,
                overall_score=5,
                strengths=["ë¦¬ë·° ì¤‘ ì˜¤ë¥˜ ë°œìƒ"],
                weaknesses=["ê²€í† ë¥¼ ì™„ë£Œí•  ìˆ˜ ì—†ìŒ"],
                improvement_suggestions=["ì‹œìŠ¤í…œ ì˜¤ë¥˜ë¥¼ í™•ì¸í•˜ì„¸ìš”"],
                section_feedback={},
                structural_comments="ê²€í†  ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                language_comments="ê²€í†  ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            )
            
            return default_review

    def suggest_review_actions(self, paper: Paper, review: PaperReview) -> List[ReviewAction]:
        """
        ë¦¬ë·° ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ êµ¬ì²´ì ì¸ ì¡°ì¹˜ ì‚¬í•­ì„ ì œì•ˆí•©ë‹ˆë‹¤.

        Args:
            paper (Paper): ê²€í† ëœ ë…¼ë¬¸
            review (PaperReview): ë…¼ë¬¸ ë¦¬ë·° ê²°ê³¼

        Returns:
            List[ReviewAction]: ì œì•ˆëœ ì¡°ì¹˜ ì‚¬í•­ ëª©ë¡
        """
        logger.info(f"ë…¼ë¬¸ '{paper.title}'ì— ëŒ€í•œ ì¡°ì¹˜ ì‚¬í•­ ì œì•ˆ ì¤‘...")
        
        try:
            # ë¦¬ë·° ê²°ê³¼ ì¤€ë¹„
            review_result = json.dumps(review.dict(), ensure_ascii=False)
            
            # ì¡°ì¹˜ ì‚¬í•­ ì œì•ˆ ìˆ˜í–‰
            format_instructions = self.review_action_parser.get_format_instructions()
            
            actions = []
            
            # ì£¼ìš” ì•½ì ì— ëŒ€í•œ ì¡°ì¹˜ ì‚¬í•­ ìƒì„±
            for weakness in review.weaknesses[:3]:  # ìƒìœ„ 3ê°œ ì•½ì ë§Œ ì²˜ë¦¬
                result = self.review_action_chain.invoke({
                    "paper_title": paper.title,
                    "review_result": f"ì•½ì : {weakness}
{review_result}",
                    "format_instructions": format_instructions
                })
                
                # ê²°ê³¼ íŒŒì‹±
                action = self.review_action_parser.parse(result["text"])
                actions.append(action)
            
            logger.info(f"ë…¼ë¬¸ '{paper.title}'ì— ëŒ€í•œ {len(actions)}ê°œ ì¡°ì¹˜ ì‚¬í•­ ì œì•ˆ ì™„ë£Œ")
            return actions
            
        except Exception as e:
            logger.error(f"ì¡°ì¹˜ ì‚¬í•­ ì œì•ˆ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ ì¡°ì¹˜ ì‚¬í•­ ë°˜í™˜
            return [
                ReviewAction(
                    action_type="ê²€í† ",
                    section=None,
                    description="ì¡°ì¹˜ ì‚¬í•­ ì œì•ˆ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                    priority="ë†’ìŒ",
                    rationale="ì‹œìŠ¤í…œ ì˜¤ë¥˜ë¥¼ í•´ê²°í•˜ì„¸ìš”."
                )
            ]

    def format_review_report(self, review: PaperReview, actions: List[ReviewAction] = None) -> str:
        """
        ë…¼ë¬¸ ë¦¬ë·° ê²°ê³¼ì™€ ì¡°ì¹˜ ì‚¬í•­ì„ ì‚¬ìš©ì ì¹œí™”ì ì¸ ë³´ê³ ì„œë¡œ í¬ë§·íŒ…í•©ë‹ˆë‹¤.

        Args:
            review (PaperReview): ë…¼ë¬¸ ë¦¬ë·° ê²°ê³¼
            actions (List[ReviewAction], optional): ì œì•ˆëœ ì¡°ì¹˜ ì‚¬í•­ ëª©ë¡

        Returns:
            str: í¬ë§·íŒ…ëœ ë¦¬ë·° ë³´ê³ ì„œ
        """
        report = f"# ë…¼ë¬¸ ë¦¬ë·° ë³´ê³ ì„œ: {review.paper_title}

"
        report += f"## ì „ì²´ í‰ê°€

"
        report += f"**ì ìˆ˜**: {review.overall_score}/10

"
        
        report += "## ì¥ì 

"
        for strength in review.strengths:
            report += f"- âœ“ {strength}
"
        
        report += "
## ì•½ì 

"
        for weakness in review.weaknesses:
            report += f"- âœ— {weakness}
"
        
        report += "
## ê°œì„  ì œì•ˆ

"
        for suggestion in review.improvement_suggestions:
            report += f"- ğŸ’¡ {suggestion}
"
        
        if review.section_feedback:
            report += "
## ì„¹ì…˜ë³„ í”¼ë“œë°±

"
            for section, feedback in review.section_feedback.items():
                report += f"### {section}

{feedback}

"
        
        report += f"## êµ¬ì¡°ì  ì˜ê²¬

{review.structural_comments}

"
        report += f"## ì–¸ì–´ì  ì˜ê²¬

{review.language_comments}

"
        
        if actions:
            report += "## ê¶Œì¥ ì¡°ì¹˜ ì‚¬í•­

"
            for i, action in enumerate(actions, 1):
                report += f"### ì¡°ì¹˜ {i}: {action.action_type}

"
                if action.section:
                    report += f"**ê´€ë ¨ ì„¹ì…˜**: {action.section}

"
                report += f"**ì„¤ëª…**: {action.description}

"
                report += f"**ìš°ì„ ìˆœìœ„**: {action.priority}

"
                report += f"**ê·¼ê±°**: {action.rationale}

"
        
        return report

    def run(
        self, 
        input_data: Dict[str, Any], 
        config: Optional[RunnableConfig] = None
    ) -> Dict[str, Any]:
        """
        ë¦¬ë·° ë° ìƒí˜¸ì‘ìš© ì—ì´ì „íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.

        Args:
            input_data (Dict[str, Any]): ì…ë ¥ ë°ì´í„°
                - action: ì‹¤í–‰í•  ì•¡ì…˜ (collect_feedback, generate_progress_update, review_paper)
                - feedback_text: ì‚¬ìš©ì í”¼ë“œë°± í…ìŠ¤íŠ¸ (collect_feedback ì•¡ì…˜ì— í•„ìš”)
                - workflow_state: ì›Œí¬í”Œë¡œìš° ìƒíƒœ (generate_progress_update ì•¡ì…˜ì— í•„ìš”)
                - paper: ê²€í† í•  ë…¼ë¬¸ (review_paper ì•¡ì…˜ì— í•„ìš”)
            config (Optional[RunnableConfig], optional): ì‹¤í–‰ êµ¬ì„±

        Returns:
            Dict[str, Any]: ì‹¤í–‰ ê²°ê³¼
        """
        logger.info("ë¦¬ë·° ë° ìƒí˜¸ì‘ìš© ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘...")
        
        try:
            action = input_data.get("action", "")
            
            if action == "collect_feedback":
                feedback_text = input_data.get("feedback_text", "")
                if not feedback_text:
                    raise ValueError("í”¼ë“œë°± í…ìŠ¤íŠ¸ê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                
                feedback = self.collect_feedback(feedback_text)
                analysis = self.analyze_feedback(feedback)
                
                return {
                    "success": True,
                    "action": "collect_feedback",
                    "feedback": feedback.dict(),
                    "analysis": analysis.dict()
                }
                
            elif action == "generate_progress_update":
                workflow_state = input_data.get("workflow_state")
                if not workflow_state:
                    raise ValueError("ì›Œí¬í”Œë¡œìš° ìƒíƒœê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                
                progress = self.generate_progress_update(workflow_state)
                message = self.format_progress_message(progress)
                
                return {
                    "success": True,
                    "action": "generate_progress_update",
                    "progress": progress.dict(),
                    "message": message
                }
                
            elif action == "review_paper":
                paper = input_data.get("paper")
                if not paper:
                    raise ValueError("ê²€í† í•  ë…¼ë¬¸ì´ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                
                review = self.review_paper(paper)
                actions = self.suggest_review_actions(paper, review)
                report = self.format_review_report(review, actions)
                
                return {
                    "success": True,
                    "action": "review_paper",
                    "review": review.dict(),
                    "actions": [action.dict() for action in actions],
                    "report": report
                }
                
            else:
                raise ValueError(f"ì§€ì›ë˜ì§€ ì•ŠëŠ” ì•¡ì…˜: {action}")
                
        except Exception as e:
            logger.error(f"ë¦¬ë·° ë° ìƒí˜¸ì‘ìš© ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            
            return {
                "success": False,
                "error": str(e),
                "action": input_data.get("action", "unknown")
            }
